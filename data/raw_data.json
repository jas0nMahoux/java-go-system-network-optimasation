[
    {
        "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
        "title": "Racine",
        "shortDescription": "Racine de l'abre des connaissances",
        "description": "",
        "linkedConcepts": [],
        "flashcards": [],
        "base": true,
        "atomic": false
    },
    {
        "id": "8b9b4ca8-2a9a-4af3-96cf-7aabd0fc88ea",
        "title": "Concept supprimé",
        "shortDescription": "",
        "description": "",
        "linkedConcepts": [],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a1786998-f5b9-49ba-95c3-fa9c14e40413",
        "title": "AWS Lambda",
        "shortDescription": "",
        "description": "---\nid: 574373b1-97bf-4179-87b9-88dc8fc613cf\n---\n# Rapidement c'est quoi❓\n\nAWS Lambda est un service [[Function as a Service (FaaS)]] d'[[AWS]].  Il permet d'exécuter du code sans gérer d'infrastructure serveur.  Vous fournissez le code, et [[AWS]] s'occupe du reste.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAWS Lambda est un service de calcul sans serveur qui permet aux développeurs d'exécuter du code en réponse à des événements sans provisionner ou gérer des serveurs.  Vous écrivez votre code (fonctions) dans plusieurs langages supportés ([[Node.js]], [[Python]], [[Java]], [[C#]], [[Go]], [[Ruby]], etc.), le déployez sur [[AWS]], et Lambda s'occupe de l'exécution, du scaling automatique et de la facturation uniquement en fonction de l'utilisation effective.  Chaque fonction est déclenchée par un événement, tel qu'une modification dans un [[Bucket S3]] , une requête [[API Gateway]], une entrée dans une file [[SQS]], ou un évènement planifié avec [[CloudWatch Events]].\n\nLambda gère automatiquement le scaling : si plusieurs événements se produisent simultanément, Lambda lance plusieurs instances de votre fonction pour gérer la charge.  L'inverse est également vrai : si aucune requête n'est effectuée, aucune ressource n'est consommée et vous ne payez rien.  La gestion des ressources (mémoire, temps d'exécution, etc.) est définie lors de la configuration de la fonction.  Lambda propose également des fonctionnalités avancées comme les versions, les alias, les couches (pour partager du code commun entre plusieurs fonctions) et l'intégration avec d'autres services [[AWS]].  Le monitoring et le logging sont intégrés via [[CloudWatch]].\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Sans serveur (Serverless):** Pas besoin de gérer d'infrastructure, ce qui réduit considérablement le coût et la complexité.\n* **Scaling automatique:** Lambda s'adapte automatiquement à la demande, garantissant la disponibilité et la performance.\n* **Facturation à l'utilisation:** Vous ne payez que pour le temps d'exécution effectif de votre code.\n* **Intégration avec l'écosystème [[AWS]]:**  S'intègre facilement avec de nombreux autres services [[AWS]], permettant de créer des applications complexes et robustes.\n* **Langages multiples supportés:** Large choix de langages de programmation pour développer vos fonctions.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Durée d'exécution limitée:**  Les fonctions Lambda ont une durée d'exécution maximale (variable selon la configuration).  Les tâches longues doivent être traitées différemment (par exemple, en utilisant des files d'attente et des fonctions plus courtes).\n* **Débogage plus complexe:** Le débogage peut être plus difficile que dans une application traditionnelle, nécessitant des outils et des techniques spécifiques.\n* **Cold starts:** La première exécution d'une fonction peut prendre un peu plus de temps (cold start), ce qui peut affecter les performances pour les requêtes occasionnelles.\n* **Verrouillage fournisseur:**  Le code est exécuté sur l'infrastructure AWS, ce qui crée une dépendance envers ce fournisseur.\n* **Gestion des états:** La persistance des données entre les exécutions de fonctions nécessite l'utilisation de services externes comme [[DynamoDB]].\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n[[MOC_Dev]] [[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "f9aee61a-9901-45a2-b522-c3dd3d9f0f52",
        "title": "Certification Java 17 - Accès aux Bases de Données avec JDBC",
        "shortDescription": "",
        "description": "---\nid: 8b4f3380-cc59-43fe-baca-4e83b06bb405\n---\n## **11.1. Connexion à une base de données (`DriverManager`, `DataSource`)**\n\nJDBC (**Java Database Connectivity**) permet à une application Java de se connecter à une base de données.\n\n### **1. Chargement du driver JDBC**\n\n\uD83D\uDCCC **Depuis Java 6, le chargement est automatique si le driver est dans le classpath.**\n\n```java\nClass.forName(\"org.postgresql.Driver\"); // PostgreSQL\nClass.forName(\"com.mysql.cj.jdbc.Driver\"); // MySQL\n```\n\n\uD83D\uDCCC **Plus besoin de `Class.forName()` avec JDBC 4.0+.**\n\n---\n\n### **2. Connexion avec `DriverManager`**\n\n```java\nimport java.sql.*;\n\npublic class ConnexionJDBC {\n    public static void main(String[] args) {\n        String url = \"jdbc:mysql://localhost:3306/ma_base\";\n        String user = \"root\";\n        String password = \"password\";\n\n        try (Connection conn = DriverManager.getConnection(url, user, password)) {\n            System.out.println(\"Connexion réussie !\");\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **Utilisation d’un `try-with-resources` pour fermer automatiquement la connexion.**\n\n---\n\n### **3. Connexion avec `DataSource` (Meilleure Pratique)**\n\n\uD83D\uDCCC **`DataSource` permet une gestion optimisée des connexions.**\n\n```java\nimport javax.sql.DataSource;\nimport com.mysql.cj.jdbc.MysqlDataSource;\n\npublic class ConnexionDataSource {\n    public static void main(String[] args) throws Exception {\n        MysqlDataSource ds = new MysqlDataSource();\n        ds.setURL(\"jdbc:mysql://localhost:3306/ma_base\");\n        ds.setUser(\"root\");\n        ds.setPassword(\"password\");\n\n        try (Connection conn = ds.getConnection()) {\n            System.out.println(\"Connexion réussie !\");\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **Utilisé dans les serveurs d’application avec un pool de connexions.**\n\n---\n\n## **11.2. Exécution de requêtes (`Statement`, `PreparedStatement`, `CallableStatement`)**\n\n### **1. Requête avec `Statement` (⚠ Vulnérable aux injections SQL)**\n\n```java\ntry (Connection conn = DriverManager.getConnection(url, user, password);\n     Statement stmt = conn.createStatement()) {\n\n    ResultSet rs = stmt.executeQuery(\"SELECT * FROM utilisateurs\");\n\n    while (rs.next()) {\n        System.out.println(rs.getString(\"nom\"));\n    }\n}\n```\n\n\uD83D\uDCCC **⚠ Éviter `Statement` pour les requêtes contenant des entrées utilisateur (risque d’injection SQL).**\n\n---\n\n### **2. Requête sécurisée avec `PreparedStatement`**\n\n```java\nString sql = \"SELECT * FROM utilisateurs WHERE email = ?\";\ntry (PreparedStatement pstmt = conn.prepareStatement(sql)) {\n    pstmt.setString(1, \"user@mail.com\");\n    ResultSet rs = pstmt.executeQuery();\n\n    while (rs.next()) {\n        System.out.println(rs.getString(\"nom\"));\n    }\n}\n```\n\n\uD83D\uDCCC **Sécurise la requête en empêchant les injections SQL.**\n\n---\n\n### **3. Insertion avec `PreparedStatement`**\n\n```java\nString sql = \"INSERT INTO utilisateurs (nom, email) VALUES (?, ?)\";\ntry (PreparedStatement pstmt = conn.prepareStatement(sql)) {\n    pstmt.setString(1, \"Alice\");\n    pstmt.setString(2, \"alice@mail.com\");\n    pstmt.executeUpdate(); // Exécute l’insertion\n}\n```\n\n\uD83D\uDCCC **`executeUpdate()` pour `INSERT`, `UPDATE`, `DELETE`.**\n\n---\n\n### **4. Appel d’une procédure stockée avec `CallableStatement`**\n\n```java\nString sql = \"{call ajouter_utilisateur(?, ?)}\";\ntry (CallableStatement cstmt = conn.prepareCall(sql)) {\n    cstmt.setString(1, \"Alice\");\n    cstmt.setString(2, \"alice@mail.com\");\n    cstmt.execute();\n}\n```\n\n\uD83D\uDCCC **Utilisé pour exécuter des procédures stockées SQL.**\n\n---\n\n## **11.3. Gestion des transactions (`commit`, `rollback`)**\n\nPar défaut, **chaque requête est validée (`commit`) automatiquement**.  \n\uD83D\uDCCC **Pour gérer manuellement une transaction, on désactive l’auto-commit.**\n\n---\n\n### **1. Début d’une transaction (`setAutoCommit(false)`)**\n\n```java\ntry (Connection conn = DriverManager.getConnection(url, user, password)) {\n    conn.setAutoCommit(false); // Désactive l’auto-commit\n\n    try (PreparedStatement pstmt1 = conn.prepareStatement(\"INSERT INTO comptes VALUES (?, ?)\");\n         PreparedStatement pstmt2 = conn.prepareStatement(\"INSERT INTO transactions VALUES (?, ?)\")) {\n\n        pstmt1.setInt(1, 1);\n        pstmt1.setDouble(2, 1000.00);\n        pstmt1.executeUpdate();\n\n        pstmt2.setInt(1, 1);\n        pstmt2.setDouble(2, -500.00);\n        pstmt2.executeUpdate();\n\n        conn.commit(); // Valide la transaction\n    } catch (SQLException e) {\n        conn.rollback(); // Annule toutes les opérations\n        e.printStackTrace();\n    }\n}\n```\n\n\uD83D\uDCCC **Si une erreur survient, `rollback()` annule les modifications.**\n\n---\n\n## **Résumé**\n\n✅ **Connexion JDBC : `DriverManager` (basique), `DataSource` (optimisé, recommandé).**  \n✅ **Exécution de requêtes :**\n\n- `Statement` (⚠ à éviter pour les entrées utilisateur).\n- `PreparedStatement` (sécurisé contre les injections SQL).\n- `CallableStatement` (appelle une procédure stockée).  \n    ✅ **Gestion des transactions : `commit`, `rollback`, `setAutoCommit(false)`.**\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "8e5aa410-7105-45e7-b5bc-f1300195e660",
        "title": "Analog.js",
        "shortDescription": "",
        "description": "---\nid: 4775911f-b142-4a2e-8954-bb74d1475de6\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nAnalogJs est un [[méta-framework]] pour [[Angular]] qui ajoute des fonctionnalités comme le routage automatique, le rendu côté serveur, et la génération de sites statiques. Il simplifie le développement en intégrant des outils modernes comme [[Vite]] et [[Vitest]].\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAnalogJs étend [[Angular]] avec des fonctionnalités pratiques :\n\n- **Routage basé sur le système de fichiers** : Les routes sont automatiquement générées à partir de la structure des fichiers.\n- **Rendu côté serveur ([[Server Side Rendering (SSR)]])** et **génération de sites statiques** ([[Server Side Generation (SSG)]]) : Permet d’améliorer le SEO et la vitesse de chargement.\n- **Support Markdown** : Permet d'utiliser des fichiers Markdown comme contenu.\n- **Routes API intégrées** : Crée facilement des routes API dans la même application.\n- **Structure simplifiée des composants** : Un seul fichier par composant, contrairement à l'approche Angular traditionnelle avec plusieurs fichiers.\n\nAnalogJs utilise Vite pour la compilation rapide et Vitest pour les tests, offrant une expérience moderne et rapide.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Simplification du routage** : Grâce au routage basé sur le système de fichiers.\n- **Rendu côté serveur et sites statiques** : Améliore la performance et le SEO.\n- **Support Markdown** : Idéal pour créer du contenu rapidement.\n- **Structure de composants simplifiée** : Un fichier par composant pour plus de clarté.\n- **Intégration de [[Vite]] et [[Vitest]]** : Développement rapide et tests efficaces.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Dépendance à [[Angular]]** : Nécessite [[Angular]], ce qui peut être contraignant.\n- **Moins mature** : Moins de documentation et de communauté par rapport à [[Nuxt.js]] ou [[Next.js]].\n- **Courbe d'apprentissage** : Complexe pour les débutants Angular ou SSR.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[JavaScript]] [[Typescript]]",
        "linkedConcepts": [
            {
                "id": "8b9b4ca8-2a9a-4af3-96cf-7aabd0fc88ea",
                "title": "Concept supprimé",
                "shortDescription": "",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": false,
                "atomic": false
            }
        ],
        "flashcards": [
            {
                "id": "2357fd18-4044-4819-b507-38b3de710a5b",
                "front": "Comment Analog.js simplifie-t-il le routage dans une application Angular ?\n\nExpliquez le concept et donnez un exemple.",
                "back": "Analog.js utilise le système de fichiers pour définir le routage. La structure des dossiers détermine les routes.  Par exemple, un fichier `src/pages/contact.tsx` créera automatiquement la route `/contact`.  Cela élimine la configuration manuelle des routes dans un fichier de configuration séparé.",
                "easeFactor": 2.5,
                "interval": 10,
                "repetitions": 1,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-02T19:50:36.99",
                "nextReviewDate": "2025-04-02T20:00:54.792",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            },
            {
                "id": "2796aeef-70ba-4a24-b154-8e8e08460546",
                "front": "Quels sont les avantages principaux de l'utilisation du SSR (Server Side Rendering) et du SSG (Static Site Generation) avec Analog.js ?",
                "back": "Le SSR améliore le SEO en rendant le contenu côté serveur, ce qui permet aux moteurs de recherche d'indexer plus facilement le contenu. Le SSG génère un site statique, offrant des performances optimales en réduisant le temps de chargement initial et en améliorant l'expérience utilisateur.",
                "easeFactor": 2.65,
                "interval": 1,
                "repetitions": 0,
                "lapses": 0,
                "state": "GRADUATED",
                "createdDate": "2025-04-02T19:50:36.99",
                "nextReviewDate": "2025-04-03T19:50:57.496",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            },
            {
                "id": "5ded5f16-2c3c-4eb3-8c78-2f518d42a947",
                "front": "Analog.js utilise Vite et Vitest.  Quel est le rôle de chaque outil dans le processus de développement ?",
                "back": "Vite est un outil de build qui accélère considérablement le processus de compilation et de développement. Vitest est un framework de test unitaire qui permet d'écrire et d'exécuter des tests unitaires rapidement et efficacement.",
                "easeFactor": 2.5,
                "interval": 1,
                "repetitions": 0,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-02T19:50:36.99",
                "nextReviewDate": "2025-04-02T19:52:00.408",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            }
        ],
        "base": false,
        "atomic": false
    },
    {
        "id": "dd0c0816-84ee-4e93-991a-8f8964cb56ec",
        "title": "Anglais - mot et expression",
        "shortDescription": "",
        "description": "---\nid: 7d823355-dc92-4f2a-ae2c-e655a70688b1\n---\ngibberish: gibberish\nYou are talking gibberish: Tu dis n'importe quoi\ngrasshopper: sauterelle\nkneehigh to a grasshopper: haut comme trois pomme",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "56e1c640-ad12-4cc9-8546-43e7a58f1e9a",
        "title": "Annotation (java)",
        "shortDescription": "",
        "description": "---\nid: 3822ed8e-7f6c-4ff8-a60e-b547afc6523d\n---\n# Rapidement c'est quoi❓\n\nLes annotations [[Java]] sont des métadonnées qui fournissent des informations supplémentaires sur le code sans affecter son exécution. Elles sont utilisées pour annoter des classes, méthodes, champs, etc.,  guidant le compilateur, les outils d'exécution ou d'autres processus, comme [[Aspect Oriented Programming.md]].\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nEn [[Java]], les annotations sont des balises placées avant les éléments de code (classes, méthodes, champs, etc.). Elles sont définies à l'aide de l'annotation `@interface`.  Elles ne modifient pas le comportement du code en lui-même, mais fournissent des informations contextuelles pour différents outils et processus.\n\n**Structure d'une annotation:**\n\nUne annotation est définie avec le mot clé `@interface` suivi du nom de l'annotation.  Elle peut contenir des éléments (attributs) avec des valeurs par défaut ou non.  Par exemple :\n\n```java\n@Retention(RetentionPolicy.RUNTIME)\n@Target(ElementType.METHOD)\npublic @interface MyAnnotation {\n    String value() default \"default value\";\n    int number() default 0;\n}\n```\n\nDans cet exemple :\n\n* `@Retention(RetentionPolicy.RUNTIME)` spécifie que l'annotation sera disponible au runtime (l'exécution du programme).  Il existe d'autres valeurs possibles: `SOURCE` (disponible uniquement à la compilation) et `CLASS` (disponible à la compilation et au chargement de la classe). Il faut savoir qu'il y a très peu d'intérêt d'utiliser autres chose de RUNTIME car c'est la seule valeur qui conserve l'annotation au runtime, et qui permet donc de faire des traitements.\n* `@Target(ElementType.METHOD)` indique que cette annotation ne peut être appliquée qu'aux méthodes.  D'autres valeurs possibles pour `ElementType` incluent `TYPE`, `FIELD`, `CONSTRUCTOR`, `PARAMETER`, etc.\n* `String value() default \"default value\";` définit un attribut `value` de type String avec une valeur par défaut.\n* `int number() default 0;` définit un attribut `number` de type int avec une valeur par défaut.\n\nL'annotation est ensuite utilisée dans le code ainsi :\n\n```java\n@MyAnnotation(value = \"hello\", number = 5)\npublic void myMethod() {\n  // ...\n}\n```\n\nLe compilateur, les outils (frameworks, IDEs) ou le code au runtime peuvent alors interpréter ces informations pour effectuer différentes actions. Par exemple, un framework pourrait utiliser une annotation pour injecter des dépendances ou un outil de test pour identifier les méthodes à tester.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Métaprogrammation:** Permet d'ajouter des informations au code sans le modifier directement, améliorant la lisibilité et la maintenabilité.\n* **Réduction de la redondance:**  Evite la duplication de code en centralisant les informations dans les annotations.\n* **Extensibilité:** Facilite l'ajout de fonctionnalités sans modifier le code source existant.\n* **Framework-agnostique:**  Les annotations peuvent être utilisées par différents frameworks et outils.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité potentielle:** Une sur-utilisation des annotations peut rendre le code difficile à comprendre.\n* **Dépendances:**  Le code qui utilise les annotations peut dépendre de la présence de certains outils ou frameworks.\n* **Performances:**  Le traitement des annotations au runtime peut avoir un impact sur les performances, bien que généralement négligeable.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "744b0bb3-e2f9-44bd-badb-57383ee57ed2",
        "title": "Ansible Vault",
        "shortDescription": "",
        "description": "---\nid: ae62d225-067f-4a01-9d22-52fdabf93106\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nAnsible Vault est un outil d'[[Ansible]] qui permet de chiffrer et protéger des données sensibles dans des fichiers, comme des mots de passe ou des clés API, afin de les utiliser dans des playbooks Ansible sans exposer ces informations en texte clair\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAnsible Vault chiffre des fichiers ou des chaînes de caractères, les rendant illisibles sans un mot de passe spécifique. Les principales commandes sont :\n\n- **`ansible-vault create`** : Crée un fichier chiffré à partir de zéro.\n- **`ansible-vault encrypt`** : Chiffre un fichier existant.\n- **`ansible-vault decrypt`** : Déchiffre un fichier pour le rendre lisible.\n- **`ansible-vault edit`** : Permet de modifier un fichier chiffré sans le déchiffrer manuellement.\n- **`ansible-vault encrypt_string`** : Chiffre une chaîne de caractères (ex. un mot de passe) pour l'inclure dans un fichier ou un playbook.\n\nIl est aussi possible de gérer plusieurs fichiers Vault avec l'option **`-vault-id`**, permettant de spécifier différents mots de passe pour différents environnements. L'option **`-ask-vault-pass`** permet de saisir le mot de passe manuellement à l'exécution.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Sécurisation des données sensibles** : Protège efficacement les informations sensibles en les chiffrant.\n- **Facilité d'intégration avec [[Ansible]]** : Fonctionne de manière fluide avec les playbooks Ansible.\n- **Prise en charge de plusieurs fichiers Vault** : Permet de gérer différents environnements de manière sécurisée avec **`-vault-id`**.\n- **Chiffrement granulaire** : Possibilité de chiffrer uniquement des valeurs spécifiques avec **`encrypt_string`**.\n- **Interface simple** : Utilisation en ligne de commande intuitive pour créer, modifier ou déchiffrer des fichiers.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Gestion des mots de passe** : Si le mot de passe Vault est perdu ou compromis, l'accès aux données chiffrées devient impossible.\n- **Dépendance aux mots de passe** : Chaque fichier chiffré nécessite un mot de passe pour y accéder, ce qui peut devenir contraignant dans des environnements complexes.\n- **Pas de solution native pour le partage sécurisé** : Le partage des fichiers Vault entre plusieurs utilisateurs nécessite une gestion manuelle des mots de passe, ce qui peut être source d’erreurs.\n- **Performance** : Bien que les fichiers chiffrés soient légers, l'utilisation répétée de commandes de chiffrement/déchiffrement peut affecter les performances dans des environnements de grande échelle.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Python]] [[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d5cddd3c-a911-4b5f-9b0a-1ee9e69b5ae6",
        "title": "Apache Apisix",
        "shortDescription": "",
        "description": "---\nid: 82d7deb1-0645-4023-8a4c-7c1e96d022f5\n---\n# Rapidement c'est quoi❓\n\nApache APISIX est une [[API Gateway]] open-source, légère et performante, conçue pour les environnements cloud natifs.  Elle permet de gérer, router et sécuriser le trafic vers vos [[Micros services]] et APIs.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nApache APISIX est une passerelle d'API dynamique et haute performance, écrite en [[Lua]] et basée sur [[Nginx]].  Elle se distingue par son architecture entièrement basée sur le plugin, ce qui permet une extensibilité et une personnalisation exceptionnelles.  Au lieu de reconfigurer le serveur à chaque changement, APISIX utilise une architecture de données dynamique,  mettant à jour ses routes et ses configurations en temps réel sans nécessiter de redémarrage.\n\nSes fonctionnalités clés incluent :\n\n* **Routage dynamique et gestion des routes:**  APISIX permet de définir des routes pour diriger le trafic vers différents services backend en fonction de critères comme l'hôte, l'URL, les en-têtes HTTP, etc.  Ces routes peuvent être modifiées dynamiquement sans interruption de service.\n* **Gestion de la sécurité:**  Intègre des mécanismes de sécurité robustes tels que l'authentification, l'autorisation (via des plugins), le WAF (Web Application Firewall) et la protection contre les DDoS.\n* **Gestion du trafic:**  Offre des fonctionnalités de gestion du trafic avancées comme le [[load balancing]], le [[circuit breaker]] et la limitation de débit.\n* **Plugins extensibles:**  Son architecture plug-in permet d'étendre ses fonctionnalités à l'infini.  Des plugins sont disponibles pour la gestion des logs, la surveillance, l'intégration avec des services de monitoring, etc.\n* **Gestion des métadonnées:**  Permet de stocker et de gérer des métadonnées associées aux routes et aux services.\n* **Compatibilité [[Kubernetes]]:**  APISIX s'intègre bien avec Kubernetes et d'autres orchestrateurs de conteneurs.\n\nContrairement aux passerelles API traditionnelles qui nécessitent des redémarrages pour mettre à jour la configuration, APISIX offre une gestion dynamique, permettant des mises à jour en temps réel et une haute disponibilité.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Haute performance et faible latence:**  APISIX est connu pour sa performance exceptionnelle.\n* **Extensibilité grâce à l'architecture plug-in:**  Permet d'ajouter facilement de nouvelles fonctionnalités.\n* **Gestion dynamique de la configuration:**  Pas de temps d'arrêt lors des mises à jour.\n* **Open-source et communauté active:**  Bénéficie d'un support communautaire important.\n* **Intégration avec [[Kubernetes]] et d'autres outils cloud natifs.**\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage potentiellement raide:**  La maîtrise complète de l'utilisation des plugins peut demander un certain temps.\n* **Dépendance à [[Lua]]:**  Nécessite une certaine familiarité avec le langage Lua pour développer des plugins personnalisés.\n* **La documentation peut parfois manquer de clarté pour certains aspects avancés.**\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "8b9b4ca8-2a9a-4af3-96cf-7aabd0fc88ea",
                "title": "Concept supprimé",
                "shortDescription": "",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": false,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "eb8de89e-4a18-43d3-8bd0-33475992f124",
        "title": "Apache Karaf (OSGi)",
        "shortDescription": "",
        "description": "---\nid: ef4589e3-be7d-49b4-bb8f-550ea8a049d0\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓blabla\n\nKaraf est un conteneur d'application léger basé sur [[Open Service Gateway initiative (OSGi)]], permettant de déployer, gérer et configurer des applications [[Open Service Gateway initiative (OSGi)]] de manière simplifiée, avec des fonctionnalités avancées comme la gestion dynamique des configurations, le déploiement à chaud et l'intégration avec divers outils.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nApache Karaf est un conteneur d'application permettant de gérer des applications [[Open Service Gateway initiative (OSGi)]]. Il offre plusieurs fonctionnalités supplémentaires par rapport aux autres implémentations [[Open Service Gateway initiative (OSGi)]], telles que :\n\n- **Console Interactive** : Une interface en ligne de commande pour gérer les bundles, services et configurations.\n- **Karaf Features** : Permet l'installation de groupes de bundles et configurations d'un coup.\n- **Support Maven** : Déploiement direct de bundles depuis un dépôt Maven.\n- **Blueprints ([[Apache Aries]])** : Configuration déclarative des services [[Open Service Gateway initiative (OSGi)]] via des fichiers XML.\n- **Gestion Dynamique des Configurations** : Permet de modifier les configurations en direct sans redémarrer l'application.\n- **Hot Deployment** : Déploiement et mise à jour des bundles sans redémarrage du serveur.\n- **Intégration avec des frameworks** : Intégration facile avec des outils comme [[Apache Camel]], [[ActiveMQ]] et [[CXF]] pour les services d'intégration, la messagerie et les services web.\n- **Gestion de Clusters** : Avec [[Karaf Cellar]], permet de gérer et synchroniser des clusters [[Open Service Gateway initiative (OSGi)]].\n- **Sécurisation des configurations** : [[Karaf Vault]] protège les informations sensibles dans les fichiers de configuration.\n- **[[JMX]] et Monitoring** : Surveillance des services via l'intégration avec [[JMX]] et [[Jolokia]].\n- **Commandes Personnalisées** : Création de commandes personnalisées pour automatiser les tâches courantes.\n- **Support [[Java EE]] et [[Micros services]]** : Permet de déployer des applications [[Java EE]] et de supporter des architectures [[Micros services]] grâce à son modèle modulaire.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Console interactive** : Facilité de gestion des applications via une interface simple.\n- **Hot Deployment** : Mise à jour des applications sans perturber le service, idéal pour des environnements de production.\n- **Intégration avec des outils tiers** : Connexions prêtes à l'emploi avec des technologies comme [[Apache Camel]],[[ ActiveMQ]], et [[CXF]].\n- **Gestion dynamique des configurations** : Modifications à la volée sans redémarrage nécessaire, simplifiant l'administration.\n- **Blueprints** : Approche déclarative facilitant la gestion des services [[Open Service Gateway initiative (OSGi)]], similaire à [[Spring Framework]].\n- **Support de [[Java EE]] et des [[Micros services]]** : Permet de déployer des applications de grande échelle de manière modulaire.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité pour les débutants** : L'usage d'[[Open Service Gateway initiative (OSGi)]] et de Karaf peut être déroutant pour les nouveaux utilisateurs.\n- **Configuration initiale** : La configuration des features et des bundles peut être complexe et nécessite une bonne maîtrise de l'environnement.\n- **Performance** : L'usage intensif de bundles et de services peut parfois entraîner une surcharge dans des applications très petites ou simples.\n- **Dépendance au modèle OSGi** : Certains développeurs préféreront des alternatives plus simples à OSGi pour des applications ne nécessitant pas un modèle aussi modulaire.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Java]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "75728b98-3ac9-4c30-b578-92cf0f33c975",
        "title": "Apache Lucene",
        "shortDescription": "",
        "description": "---\nid: 73e4d839-b181-4a74-b4d5-439c03d44a43\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nApache Lucene est un framework [[Java]] destiné à l'indexation et à la recherche de texte, permettant de gérer efficacement de grandes quantités de données pour créer des moteurs de recherche performants.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nApache Lucene fournit des outils pour indexer des documents et effectuer des recherches rapides sur des grandes bases de données textuelles. Il permet de créer des moteurs de recherche en offrant des fonctionnalités comme :\n\n- **Indexation** : Création d'index inversés pour une recherche rapide.\n- **Recherche textuelle** : Recherche basée sur des mots-clés, phrases, ou expressions régulières.\n- **Performance** : Optimisation des recherches avec des structures de données adaptées. Des outils comme **[[Elasticsearch]]** et **[[Apache Solr]]** utilisent Lucene pour faciliter l'intégration et l'utilisation dans des environnements de production à grande échelle.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Haute performance** : Très rapide pour la recherche et l'indexation sur de grandes quantités de données.\n- **Flexibilité** : Offre des options avancées pour affiner les recherches (poids, synonymes, requêtes booléennes).\n- **Écosystème riche** : Utilisé par des outils comme [[Elasticsearch]] et [[Solr]], ce qui le rend encore plus accessible pour des cas d’usage complexes.\n- **Support de plusieurs formats** : Peut indexer des fichiers texte, XML, JSON, etc.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité d'intégration** : Peut être difficile à configurer et à intégrer directement dans des projets sans outils supplémentaires.\n- **Consommation mémoire** : L'indexation et la recherche sur de très grandes bases de données peuvent nécessiter des ressources importantes.\n- **Pas de GUI natif** : Ne propose pas d'interface graphique de gestion, nécessitant souvent des outils externes comme Solr ou Elasticsearch pour faciliter l'utilisation.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Java]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "555847cc-90e9-4281-9f5f-ca65cb84ef39",
        "title": "ArgoCD",
        "shortDescription": "",
        "description": "---\nid: fc23560f-daa5-461d-8a6b-7215c2cf2657\n---\n# Rapidement c'est quoi❓\n\nArgo CD est un outil de gestion de configuration [[GitOps]] pour [[Kubernetes]].  Il synchronise l'état déclaré de votre infrastructure dans un dépôt [[Git]] avec l'état réel de votre cluster [[Kubernetes]].\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nArgo CD est un système de déploiement et de gestion continue basé sur le principe [[GitOps]].  Il fonctionne en surveillant un dépôt [[Git]] spécifié pour les modifications apportées à des manifestes [[Kubernetes]] .  Lorsqu'une modification est détectée, Argo CD compare l'état souhaité (défini dans le dépôt Git) à l'état actuel du cluster [[Kubernetes]].  Il effectue ensuite les actions nécessaires pour synchroniser ces deux états, en appliquant les modifications, créant, mettant à jour ou supprimant les ressources [[Kubernetes]].  Cela permet un déploiement automatisé, fiable et traçable des applications sur [[Kubernetes]].\n\nArgo CD utilise un \"Declarative Configuration\" : l'état souhaité du cluster est entièrement défini dans des fichiers de configuration versionnés dans un dépôt [[Git]] (généralement avec un système de branchement [[Git]] pour gérer les déploiements et les rollbacks).  Cela facilite le suivi des changements, la collaboration et l'auditabilité.  La visualisation de l'état du déploiement, ainsi que l'historique des modifications et des éventuels échecs, est un aspect central de la plateforme.\n\nIl ne se limite pas aux manifestes [[Kubernetes]] ; il peut gérer d'autres ressources en utilisant des mécanismes d'extensions (comme les applications [[Helm]]).  L'automatisation est poussée, avec la possibilité de configurer des notifications et des alertes lors des événements importants.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* [[**GitOps]]:**  Adopte une approche [[GitOps]], offrant tous les avantages de la gestion de version, de la collaboration et de l'auditabilité.\n* **Automatisation:**  Automatise complètement le processus de déploiement et de gestion des applications [[Kubernetes]].\n* **Observabilité:**  Fournit une interface utilisateur pour surveiller l'état des déploiements et l'historique des changements.\n* **Fiabilité:**  Minimise les risques d'erreurs manuelles et assure la cohérence entre l'état souhaité et l'état réel.\n* **Rollbacks faciles:**  Permet de revenir facilement à des versions précédentes grâce à l'historique [[Git]].\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité initiale:**  La configuration et l'intégration initiale peuvent être complexes pour les utilisateurs non familiers avec [[Kubernetes]] et [[GitOps]].\n* **Dépendance à Git:**  Une dépendance totale à un système de gestion de versions [[Git]] est nécessaire.\n* **Gestion des secrets:**  La gestion des secrets nécessite une configuration supplémentaire et une intégration avec des solutions de gestion des secrets.\n* **Surveillance accrue nécessaire:**  Même avec l'automatisation, la surveillance du système reste cruciale pour identifier et résoudre les problèmes.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "0e691bd0-f951-4184-b231-57171dea0300",
        "title": "Aspect Oriented Programming (AOP)",
        "shortDescription": "",
        "description": "---\nid: 648c597b-2bb8-47b8-8dbb-1ea43bf23d4c\n---\n# **Rapidement, c'est quoi ? ❓**\n\nL'Aspect Oriented Programming (AOP) est une technique de programmation qui permet de séparer les préoccupations transversales (cross-cutting concerns) du code principal.  Elle vise à améliorer la modularité et la maintenabilité du code en regroupant des fonctionnalités qui affectent plusieurs parties du programme, mais qui ne sont pas directement liées à la logique métier principale.  Imaginez des aspects comme la journalisation, la sécurité ou la gestion des transactions, qui traversent plusieurs modules.  AOP permet de les gérer séparément.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nAOP introduit le concept d'**aspects**, qui sont des modules contenant du code qui s'exécute à des points spécifiques du programme, appelés **points de jonction** (join points). Ces points de jonction sont généralement des événements tels que l'appel d'une méthode, la création d'un objet ou l'exécution d'une exception.\n\nUn aspect est défini par un ensemble de points de jonction et d'**avis** (advices). Un avis est un bloc de code qui s'exécute avant, après ou autour d'un point de jonction.  On peut ainsi ajouter des fonctionnalités sans modifier le code principal.\n\n**Exemple concret ([[Java]] avec [[Spring AOP]]):**\n\nImaginons une méthode `processOrder()` qui gère le traitement d'une commande.  On veut ajouter une journalisation avant et après son exécution.  Avec AOP, on peut créer un aspect sans modifier `processOrder()` :\n\n```java\n@Aspect\npublic class LoggingAspect {\n\n    @Before(\"execution(* com.example.OrderService.processOrder(..))\")\n    public void beforeProcessOrder(JoinPoint joinPoint) {\n        System.out.println(\"Avant traitement de la commande: \" + joinPoint.getSignature());\n    }\n\n    @After(\"execution(* com.example.OrderService.processOrder(..))\")\n    public void afterProcessOrder(JoinPoint joinPoint) {\n        System.out.println(\"Après traitement de la commande: \" + joinPoint.getSignature());\n    }\n}\n```\n\nCe code utilise Spring AOP.  `@Aspect` indique qu'il s'agit d'un aspect.  `@Before` et `@After` définissent les avis qui s'exécutent avant et après l'exécution de `processOrder()`.  `execution(* com.example.OrderService.processOrder(..))` est un pointcut (expression qui définit les points de jonction).\n\nL'implémentation d'AOP varie selon les langages et les frameworks.  Certains langages ont des fonctionnalités intégrées, tandis que d'autres utilisent des frameworks spécifiques ([[Spring AOP]] en [[Java]], AspectJ, etc.).  Le mécanisme sous-jacent implique souvent la modification du code bytecode (transformation du code compilé) pour injecter le code des aspects aux points de jonction.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n- **Modularité et maintenabilité:** Sépare les préoccupations transversales du code principal, facilitant la maintenance et la compréhension du code.\n- **Réutilisabilité:** Les aspects peuvent être réutilisés dans différents modules.\n- **Réduction de la duplication de code:** Évite la redondance de code pour des fonctionnalités transversales.\n- **Amélioration de la lisibilité:** Le code principal reste focalisé sur la logique métier.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n- **Complexité:**  AOP peut introduire une complexité supplémentaire, surtout pour des projets de petite taille.  La compréhension du mécanisme et des points de jonction peut nécessiter une courbe d'apprentissage.\n- **Débogage:** Le débogage peut être plus difficile car le code est dispersé entre les aspects et le code principal.\n- **Performances:**  L'ajout d'aspects peut avoir un impact léger sur les performances, bien que souvent négligeable.\n- **Difficulté de test:** Tester les aspects isolément peut être complexe.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d7d701db-d6e0-42c9-8931-bdada3b40dda",
        "title": "AspectJ",
        "shortDescription": "",
        "description": "---\nid: 0a9b351a-7625-4e02-a252-3dff5766d3e2\n---\n# **Rapidement, c'est quoi ? ❓**\n\nAspectJ est une extension du langage [[Java]] qui permet la [[Aspect Oriented Programming (AOP)]].  Il offre un moyen de modulariser les préoccupations transversales (cross-cutting concerns) comme la journalisation, la gestion des transactions, ou la sécurité, en les séparant du code principal de l'application.  Cela améliore la lisibilité, la maintenabilité et la réutilisabilité du code.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nAspectJ permet d'ajouter du code (appelé *aspects*) à des points spécifiques dans l'exécution d'un programme [[Java]], sans modifier le code source existant.  Ces points sont définis par des *pointcuts*, qui sont des expressions qui sélectionnent des joint points (join points).  Un joint point représente un point d'exécution dans le programme, comme l'appel d'une méthode, la création d'un objet, ou le lancement d'une exception.\n\nLes aspects sont définis dans des fichiers séparés et contiennent des *advice*, qui sont des blocs de code exécutés avant, après, ou autour d'un joint point sélectionné par le pointcut.  AspectJ utilise un processus de compilation séparé pour tisser (weave) les aspects dans le code Java.\n\n**Exemple:** Imaginons que l'on veuille logger chaque appel de méthode d'une classe `UserService`.  Avec AspectJ, on pourrait définir un aspect comme suit :\n\n```java\npublic aspect UserServiceLogger {\n    pointcut logMethodCall(): call(* com.example.UserService.*(..));\n\n    before(): logMethodCall() {\n        System.out.println(\"Appel de méthode : \" + thisJoinPoint.getSignature());\n    }\n}\n```\n\nCe code définit un pointcut `logMethodCall()` qui sélectionne tous les appels de méthode de la classe `com.example.UserService`.  L'advice `before()` est exécuté avant chaque appel de méthode sélectionné, et affiche un message de log dans la console.  `thisJoinPoint` est une variable spéciale qui fournit des informations sur le joint point courant.\n\nAspectJ supporte plusieurs types d'advice : `before`, `after`, `after returning`, `after throwing`, et `around`.  L'advice `around` permet de contrôler entièrement l'exécution d'un joint point.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Séparation des préoccupations:** Améliore la modularité et la lisibilité du code en séparant les préoccupations transversales du code principal.\n* **Réutilisabilité:** Les aspects peuvent être réutilisés dans différentes parties de l'application ou même dans d'autres applications.\n* **Maintenance simplifiée:** Les modifications des préoccupations transversales n'impliquent pas de modifier le code principal.\n* **Aspect non invasif:**  On peut ajouter des fonctionnalités sans modifier le code source existant.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage:** La programmation orientée aspect peut avoir une courbe d'apprentissage raide, surtout pour les développeurs qui ne sont pas familiers avec ce paradigme.\n* **Débogage:** Le débogage peut être plus complexe que dans le code [[Java]] standard, car il faut comprendre l'interaction entre les aspects et le code principal.\n* **Performance:** L'ajout d'aspects peut avoir un impact sur les performances, bien que cela soit généralement négligeable.\n* **Complexité potentielle:**  Une mauvaise utilisation des aspects peut conduire à un code plus complexe et difficile à maintenir.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "8b9b4ca8-2a9a-4af3-96cf-7aabd0fc88ea",
                "title": "Concept supprimé",
                "shortDescription": "",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": false,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "314398fc-a56e-435e-b0bd-8438fd066367",
        "title": "Astro Starlight",
        "shortDescription": "",
        "description": "---\nid: 3076a9fe-0aeb-4998-b3f7-43f4cb759043\n---\n# Rapidement c'est quoi❓\n\nAstro Starlight est un générateur de sites web statiques, spécifiquement conçu pour créer des documentations, similaire à [[VitePress]] ou [[Docusaurus]].  Il utilise [[Astro]], un framework de sites web rapides et performants.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAstro Starlight est un thème (ou un ensemble de composants et de configurations) pour le framework [[Astro]]. Il fournit une structure de base et des composants pré-construits pour faciliter la création de sites de documentation.  Contrairement à une solution comme [[VitePress]] qui est une application complète, Starlight se base sur la flexibilité d'[[Astro]], permettant une plus grande personnalisation tout en conservant une structure claire pour la documentation.  Il gère typiquement la navigation, la mise en forme du code, la recherche et d'autres fonctionnalités courantes des sites de documentation.  On écrit le contenu de la documentation généralement en [[Markdown]], qui est ensuite traité par [[Astro]] pour générer le site web statique final.  Cela permet un workflow rapide, une mise à jour facile et un excellent SEO.  La performance est un point fort grâce à l'utilisation d'[[Astro]], qui est connu pour générer des sites légers et rapides à charger.  L'utilisateur final a la possibilité de personnaliser profondément le thème en modifiant les fichiers de configuration et les composants intégrés.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Performance:**  Grâce à [[Astro]], les sites générés sont rapides et légers.\n* **Personnalisation:**  Offre une grande flexibilité pour adapter le thème à ses propres besoins et design.\n* **Basé sur Astro:** Bénéficie de l'écosystème et des avantages d'[[Astro]] (performance, simplicité).\n* **Intégration [[Markdown]]:**  Simple et efficace pour la création du contenu.\n* **Structure claire:**  Fournit une base solide et bien organisée pour la documentation.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Potentiellement plus complexe à mettre en place que [[VitePress]]:**  Nécessite une compréhension de base d'[[Astro]].\n* **Moins de fonctionnalités \"out-of-the-box\":** Par rapport à une solution plus intégrée comme [[VitePress]], il faut potentiellement plus de configuration pour obtenir des fonctionnalités avancées.\n* **Dépendance à [[Astro]]:**  La connaissance d'[[Astro]] est nécessaire pour une utilisation et personnalisation efficace.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "5f1e2ec9-364e-4ce4-9afe-b92ff447af3f",
        "title": "Azure Active Directory",
        "shortDescription": "",
        "description": "---\nid: 90178cba-c2e7-4de7-a92f-4d570dc3b732\n---\n## Rapidement, c'est quoi ? ❓\n\nAzure Active Directory (Azure AD) est le service d'annuaire cloud de Microsoft. Il fournit une identité et une [[Identify Access Manager (IAM)]] pour les applications et les ressources cloud, permettant l'authentification et l'autorisation des utilisateurs et des applications.  Il peut également être intégré avec des annuaires locaux (via Azure AD Connect).\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAzure AD est un annuaire basé sur le cloud qui gère les identités d'utilisateurs et d'applications.  Il permet :\n\n* **Authentification unique (SSO):**  Les utilisateurs peuvent accéder à plusieurs applications avec les mêmes identifiants.\n* **Gestion des accès basée sur les rôles [[Role Based Access Control (RBAC)]]:** Contrôle fin des permissions pour les utilisateurs et les groupes.\n* **Gestion des identités:** Création, modification et suppression de comptes utilisateurs et groupes.\n* **Intégration avec des applications SaaS:**  Accès simple aux applications cloud basées sur le cloud.\n* **Intégration avec des applications locales:** Via Azure AD Connect, les identités locales peuvent être synchronisées avec Azure AD.\n* **Authentification multi-facteur (MFA):**  Améliore la sécurité en exigeant plusieurs méthodes d'authentification.\n* **Protection contre les menaces:** Surveillance et détection des activités suspectes.\n* **Gestion des appareils:** Contrôle et gestion des appareils accédant aux ressources.\n* **Conditionnel Access:**  Définit des politiques d'accès basées sur des conditions (emplacement, appareil, etc.).\n\n\n**Exemple d'intégration avec une application:** Une application web peut utiliser l'authentification Azure AD pour vérifier l'identité des utilisateurs avant de leur accorder l'accès.  Cela se fait généralement via les protocoles OAuth 2.0 et OpenID Connect.\n\n**Exemple de configuration (schématique):**  Pour intégrer une application web avec Azure AD, il faut enregistrer l'application dans Azure AD, obtenir un ID d'application et un secret client, puis configurer l'application pour qu'elle utilise ces informations pour authentifier les utilisateurs via Azure AD.  La configuration précise dépend du type d'application et des bibliothèques utilisées.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Intégration avec l'écosystème Microsoft:**  Fonctionne parfaitement avec d'autres services Microsoft cloud.\n* **Fonctionnalités robustes de sécurité:**  Offre des mécanismes de sécurité avancés.\n* **Scalabilité et fiabilité:**  Conçu pour gérer des millions d'utilisateurs et d'applications.\n* **Gestion centralisée des identités:**  Simplifie la gestion des utilisateurs et des accès.\n* **Bonne documentation et support:** Microsoft fournit une documentation complète et un support technique.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Coût:** Peut être coûteux pour les grandes organisations avec un grand nombre d'utilisateurs.\n* **Complexité:**  La configuration et la gestion d'Azure AD peuvent être complexes pour les utilisateurs inexpérimentés.\n* **Dépendance à Microsoft:**  Les organisations sont dépendantes de Microsoft pour le service.\n* **Problèmes de performance possibles:**  Des problèmes de performance peuvent survenir en cas de forte demande.\n* **Intégration avec des systèmes non-Microsoft:**  Peut nécessiter des efforts supplémentaires pour intégrer des systèmes non-Microsoft.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]\n\n**Note concernant la proposition initiale de fédérer avec [[Keycloak]]:**  Bien que possible, fédérer Azure AD avec Keycloak ajoute une couche de complexité.  Cela peut être utile dans certains scénarios (par exemple, pour centraliser la gestion des identités pour des applications multiples, ou pour ajouter des fonctionnalités spécifiques offertes par Keycloak), mais il est important de considérer les implications sur la complexité de la gestion et la sécurité globale.  Un choix direct d'Azure AD pour l'authentification est souvent plus simple et plus intégré.\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "78fcdf93-fb9e-4ab7-9121-ad92a35dbae7",
        "title": "Behaviour Driven Developpement (BDD)",
        "shortDescription": "",
        "description": "---\nid: f580a39e-f8d4-4c10-b007-25b2f99064b9\n---\n# Rapidement c'est quoi❓\n\nLe Behaviour Driven Development (BDD) est une approche de développement logiciel qui étend le [[Test Driven Developpement (TDD)]] en mettant l'accent sur la collaboration entre les développeurs, les testeurs et les clients.  Il se concentre sur le comportement du logiciel du point de vue de l'utilisateur.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe BDD est une technique de développement logiciel agile qui utilise des exemples concrets pour définir et vérifier le comportement souhaité du logiciel.  Au lieu de se concentrer uniquement sur des tests unitaires techniques comme le [[Test Driven Developpement (TDD)]], le BDD définit les exigences et les tests à partir du point de vue de l'utilisateur final ou d'un autre intervenant (par exemple, un analyste métier).  Ces exigences sont exprimées sous forme de scénarios écrits dans un langage compréhensible par tous (par exemple, Given-When-Then, ([[Gherkin]])), facilitant ainsi la communication et la collaboration entre les parties prenantes.\n\nLe processus BDD implique généralement les étapes suivantes :\n\n1. **Définir les comportements attendus:**  Les équipes identifient les fonctionnalités et les comportements attendus du logiciel à l'aide d'exemples concrets.  Ces exemples sont souvent écrits en utilisant le format Given-When-Then (ou un format similaire).  *Given* décrit le contexte initial, *When* décrit l'action effectuée, et *Then* décrit le résultat attendu.\n\n2. **Automatiser les tests:**  Les exemples de comportements sont ensuite traduits en tests automatisés.  Ces tests vérifient que le logiciel se comporte comme attendu.  Des frameworks BDD comme [[Cucumber]], [[SpecFlow]], ou [[Behat]] sont souvent utilisés pour faciliter l'automatisation des tests à partir de la spécification écrite en langage naturel.\n\n3. **Développer le logiciel:**  Le développement du logiciel se fait itérativement, en commençant par les fonctionnalités décrites par les exemples de comportement.  Les tests automatisés servent de guide pour le développement et permettent de valider que chaque itération répond aux exigences.\n\nEn essence, le BDD favorise une compréhension partagée des exigences entre les développeurs, les testeurs et les clients, réduisant ainsi les malentendus et les erreurs.  Il permet une documentation vivante et exécutable du comportement du logiciel.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Collaboration améliorée:**  Facilite la communication et la collaboration entre les équipes techniques et les clients grâce à un langage commun.\n* **Documentation vivante et exécutable:**  Les exemples de comportement servent de documentation claire et concise, qui est automatiquement vérifiée par les tests.\n* **Réduction des erreurs:**  La spécification précise des comportements permet de détecter et de corriger les erreurs plus tôt dans le cycle de développement.\n* **Tests plus compréhensibles:** Les tests sont écrits dans un langage naturel et facilement compréhensibles par tous, pas seulement les développeurs.\n* **Amélioration de la qualité du logiciel:**  Les tests automatisés assurent une meilleure qualité du logiciel.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:**  La mise en place de BDD peut nécessiter une courbe d'apprentissage pour les équipes non familiarisées avec cette approche.\n* **Surcoût potentiel:**  L'écriture des exemples de comportement et l'automatisation des tests peuvent prendre du temps et nécessiter des ressources supplémentaires, surtout au début.\n* **Maintenance des tests:**  La maintenance des tests automatisés peut être chronophage si le logiciel évolue rapidement.\n* **Dépendance aux frameworks:**  Le choix et la maîtrise d'un framework BDD sont essentiels pour une implémentation réussie.\n* **Peut être inadéquat pour certains projets:**  Le BDD n'est pas toujours la meilleure approche pour tous les projets, notamment les projets très petits ou ceux avec des exigences très fluctuantes.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "7e46e637-b644-45d4-887e-b929589b9fa3",
        "title": "Bento grid",
        "shortDescription": "",
        "description": "---\nid: 1734446d-b56f-421d-847e-74616d8b5715\n---\n# Rapidement c'est quoi❓\n\nBento est une méthode de conception d'interface utilisateur (UI) basée sur un système de grille flexible et adaptable, facilitant la création de mises en page réactives et modulaires.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nBento est une approche de conception UI qui se différencie des systèmes de grille traditionnels en proposant une plus grande flexibilité et modularité.  Au lieu d'une grille fixe et pré-définie, Bento utilise un système de conteneurs \"bentos\" qui peuvent contenir différents éléments UI, et s'adaptent dynamiquement à la taille de l'écran et au contenu.  Chaque bento est un composant indépendant qui peut être réutilisé et combiné avec d'autres pour créer des mises en page complexes.  Le principe repose sur l'utilisation de plusieurs conteneurs (les bentos) de tailles variables, disposés les uns à côté des autres ou les uns au-dessus des autres, en fonction des besoins.  Cela permet de créer des layouts facilement adaptables aux différents appareils (tablettes, smartphones, ordinateurs) sans avoir à écrire du code spécifique pour chaque résolution.  L'avantage clé est la facilité de maintenance et d'évolution du design, car les modifications apportées à un bento impactent uniquement ce dernier, sans nécessiter de réajustement global de la mise en page.  La flexibilité permet aussi de répondre à des changements de contenu sans perturber l'ensemble de l'interface.  Il est souvent implémenté via des frameworks [[CSS]], permettant un contrôle précis du [[Responsive en CSS]].\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Flexibilité et modularité:**  Facilement adaptable aux différents écrans et contenus.  Les modifications sont localisées.\n* **Réutilisabilité des composants:**  Les bentos peuvent être réutilisés dans différentes parties de l'application, réduisant la redondance de code et améliorant la cohérence visuelle.\n* **Maintenance simplifiée:**  Les changements sont moins susceptibles d'avoir des effets inattendus sur le reste de l'interface.\n* **Responsive design facilité:** L'adaptation aux différentes tailles d'écran est intégrée au cœur du système.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité potentielle:** La mise en place peut être plus complexe que des systèmes de grille plus simples, nécessitant une bonne compréhension des concepts.\n* **Courbe d'apprentissage:**  Nécessite de maîtriser les concepts de base de la conception UI et des systèmes de grille avant de pouvoir l'utiliser efficacement.\n* **Manque de standardisation:**  Bento n'est pas un standard officiel, la mise en œuvre peut varier selon les frameworks et les développeurs.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "ca2e037c-2ea7-453f-8814-c90ca0fb317d",
        "title": "Bonne pratiques Astuces Infos SQL",
        "shortDescription": "",
        "description": "---\nid: 9598b636-e6c7-433c-9c84-8d2be81bae62\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n[[MOC_Dev]][[MOC_DevSecOps]]\n\n**Plusieurs bonnes pratiques à mettre en place sur des [[Base de donnée SQL]] :** \n\n- Mettre des [[Index]] sur les [[Primary Key]] et les [[Foreign Key]] & sur les colonnes les plus utilisés (en terme de comparaison mémoire on devrait atteindre une part 40% [[Index]] / 60% data)\n- Eviter au max l'utilisation de fonction dans les requêtes car elles empêchent l'utilisation des index.\n- Regarder les index les moins utilisés = Ils ralentissent l’écriture\n- En fonction du métier, il peut être pertinent de créer des vues ou des partitions pour optimiser les requêtes redondante",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "44c07912-e569-4ffd-afe8-ba9f66a366bb",
        "title": "Bonne pratiques Astuces Infos code",
        "shortDescription": "",
        "description": "---\nid: 25d1a09d-2ccd-4cd5-a763-aa65e2c63372\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n[[MOC_Dev]]\n\n# [[Java]] - Comparaison BigDecimal.\n**Si je veux faire des comparaisons avec des `BigDecimal`.**\n\nOn va préférer cette comparaison : \n\n```java\nsipa2ElementFournisseur.getTauxTva().stripTrailingZeros().equals(fournisseurJSON.getTauxTva())\n```\n\nà celle-ci : \n\n```java\nObjects.equals(sipa2ElementFournisseur.getMontantTtc(), fournisseurJSON.getMontantTtc());\nsipa2ElementFournisseur.getMontantTtc().equals(fournisseurJSON.getMontantTtc()));\n```\n\nParce qu’on peut avoir des problèmes d’arrondis (si j’ai 0 et 0.0 le `Objects.equals()` renvoie faux).\n\nA noter que `stripTrailingZeros()` renvoi la notation scientifique de la valeur en string. Donc avec la précision sur les chiffres après la virgules.\n\n# [[Java]] - Activer les asserts\nPour pouvoir activer les asserts en java, il faut passer en argument de la JVM **-ea** (Enable Assert)\n\n# Appel en [[Base de donnée]]\n\nFaire très attention aux requêtes qu’on va faire en base.\n\nOn va préférer récupérer toutes les infos dont on a besoin une fois, pour ensuite les passer en paramètre de nos méthodes.\n\nDans des structures imbriquées on peut se retrouver à aller chercher 6 fois la même chose.\n\n# Comparaison de valeur\nToujours mettre en premier dans une comparaison la valeur dont on est sûr !\n```java\n# Mauvais exemple\nexception.getEnumCode().equals(ExceptionTechniqueEnum.CONCEPT_NOT_FOUND.getCode())\n\n# Bon Exemple\nExceptionTechniqueEnum.CONCEPT_NOT_FOUND.getCode().equals(exception.getEnumCode())\n```\nCar dans ce cas exception.getEnumCode() peut être null, ou produire null. ",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "afd4c958-e250-4085-aa53-067aafec3f01",
        "title": "Bonne pratiques Astuces Infos ops",
        "shortDescription": "",
        "description": "---\nid: ddeca416-e229-43bd-9ff3-cf790d5c7db6\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n[[MOC_DevSecOps]]\n# Installation [[WSL]] sans accès au Microsoft Store\n> Si par exemple, il est bloqué par l’ordinateur de la société.\n> \n\n```java\nwsl --update\n// Recherche de mises à jour en cours... Veuillez patienter\n// Erreur : 0x8024500c\n\nwsl --update --web-download\n```",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c8431349-aa03-4939-8097-d26735b0555d",
        "title": "Capture Data Change (CDC)",
        "shortDescription": "",
        "description": "---\nid: 88fa46d4-2deb-41b1-9694-46a255156d83\n---\n# Rapidement c'est quoi❓\n\nCapture Data Change (CDC) est une technique permettant de détecter et de capturer les modifications de données dans une [[Base de donnée]].  Elle est souvent utilisée pour la réplication de données et la synchronisation entre [[Base de donnée]].\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCapture Data Change (CDC) est un mécanisme qui identifie et enregistre les modifications apportées aux données d'une [[Base de donnée]].  Au lieu de copier l'intégralité de la base de données à chaque synchronisation, le CDC ne capture que les changements (insertions, mises à jour, suppressions) survenus depuis la dernière synchronisation.  Ceci améliore considérablement l'efficacité et la performance, notamment pour les bases de données volumineuses.\n\nPlusieurs méthodes existent pour implémenter le CDC :\n\n* **Triggers:** Des déclencheurs (triggers) sont définis sur les tables pour enregistrer chaque modification dans une table de journalisation (log table).  Cette méthode est relativement simple à implémenter mais peut impacter les performances si mal configurée.\n\n* **Log Mining:**  L'extraction d'informations directement depuis les logs de la base de données.  Cette approche est généralement plus performante que les triggers mais plus complexe à mettre en œuvre et dépend fortement du système de gestion de base de données (SGBD).\n\n* **Change Data Capture tools:** Des outils spécialisés (ex: [[Debezium]], [[Maxwell]]) offrent des fonctionnalités avancées de CDC, gérant la complexité de l'extraction et de la transformation des données.  Ils permettent souvent une intégration plus simple avec différents SGBD et technologies.\n\nLes données capturées par le CDC sont généralement stockées dans une table de journalisation ou transmises à un système de traitement en temps réel (streaming) pour diverses applications, comme la réplication vers une base de données secondaire, l'intégration avec des [[Date Warehouse]], la fourniture de données en temps réel pour les applications, etc.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Performance améliorée:** Seules les modifications sont traitées, ce qui rend le processus de synchronisation beaucoup plus rapide et moins gourmand en ressources.\n* **Efficacité accrue:** Réduction du volume de données transférées et traitées.\n* **Scalabilité:**  Adaptable à des bases de données de grandes tailles.\n* **Faible latence:**  Permet de fournir des données presque en temps réel.\n* **Flexibilité:**  Compatible avec diverses technologies et systèmes de bases de données.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité d'implémentation:**  La mise en œuvre peut être complexe, en particulier pour les solutions basées sur le *log mining* ou nécessitant une intégration personnalisée.\n* **Gestion des erreurs:**  Il est crucial de mettre en place une gestion robuste des erreurs pour garantir l'intégrité des données.\n* **Coût:** Les outils CDC commerciaux peuvent engendrer des coûts supplémentaires.\n* **Maintenance:**  Nécessite une maintenance régulière pour garantir la fiabilité et la performance du système.\n* **Dépendance au SGBD:**  La méthode d'implémentation dépend fortement du SGBD utilisé.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "f9bb1ea6-0be5-467a-86e9-1317b9f9e255",
        "title": "Certification Java 17",
        "shortDescription": "",
        "description": "---\nid: cdc0b331-bbe5-4556-ad81-10811ff4073c\n---\nSource de la formation : https://r331.github.io/OCP-Oracle-Certified-Professional-Java-SE-21-1Z0-839-Open-Study-Guide/\n### 1. **[[Certification Java 17 - Concepts de Base en Java]]**\n\n- Types primitifs et classes enveloppes (Wrapper)\n- Opérations arithmétiques et booléennes (promotion de type, casting)\n- Précédence des opérateurs\n- Utilisation de `var` pour l’inférence de type\n\n### 2. **[[Certification Java 17 - Programmation Orientée Objet (OOP)]]**\n\n- Déclaration et instanciation d’objets\n- Cycle de vie des objets (création, références, garbage collection)\n- Encapsulation, immutabilité\n- Héritage, classes abstraites et classes scellées (`sealed`)\n- Polymorphisme, type objet vs type référence\n- Opérateur `instanceof` et pattern matching\n- Interfaces : méthodes `default`, `static`, privées\n- Enums avec champs, méthodes et constructeurs\n\n### 3. **[[Certification Java 17 - Packages et Modules]]**\n\n- Organisation des classes en packages\n- Java Platform Module System (JPMS) : définition de modules, dépendances, services\n\n### 4. **[[Certification Java 17 - Gestion des types Date, Temps, Texte et Numérique]]**\n\n- API `Date-Time` : `LocalDate`, `LocalTime`, `LocalDateTime`, `ZonedDateTime`\n- `Period`, `Duration`, `Instant` pour la gestion des intervalles de temps\n- Classes `String`, `StringBuilder`, `Text Blocks`\n- API Math et `BigDecimal`\n\n### 5. **[[Certification Java 17 - Contrôle du Flux d'Exécution]]**\n\n- Structures de contrôle (`if/else`, `switch`, `while`, `for`, `do-while`)\n- Expressions `switch` et pattern matching\n- Instructions `break`, `continue`\n\n### 6. **[[Certification Java 17 - Gestion des Exceptions]]**\n\n- Utilisation de `try/catch/finally`\n- `try-with-resources`\n- Multi-catch (`catch` de plusieurs exceptions en une seule clause)\n- Exceptions personnalisées (`extends Exception` ou `extends RuntimeException`)\n\n### 7. **[[Certification Java 17 - Collections et Tableaux]]**\n\n- Tableaux (`int[]`, `String[]`)\n- Collections (`List`, `Set`, `Map`, `Deque`)\n- API `SequencedCollection`, `SequencedSet`, `SequencedMap` (Java 21)\n- Manipulations : ajout, suppression, tri\n\n### 8. **[[Certification Java 17 - Streams et Expressions Lambda]]**\n\n- Utilisation des `Stream<T>` et `IntStream`, `DoubleStream`\n- `filter()`, `map()`, `reduce()`, `collect()`\n- Décomposition, concaténation, partitionnement\n- Streams séquentiels et parallèles\n\n### 9. **[[Certification Java 17 - Programmation Concurrente]]**\n\n- Threads (`Runnable`, `Callable`)\n- `ExecutorService`, `ForkJoinPool`\n- Threads virtuels (`Virtual Threads`, `Thread.ofVirtual()`)\n- Verrous (`synchronized`, `Lock`, `ReadWriteLock`)\n- Collections concurrentes et streams parallèles\n\n### 10. **[[Certification Java 17 - Sorties et Fichiers]]**\n\n- Flux (`InputStream`, `OutputStream`, `Reader`, `Writer`)\n- Sérialisation/désérialisation d’objets (`Serializable`)\n- API `java.nio.file` pour la manipulation des fichiers et répertoires\n\n### 11. **[[Certification Java 17 - Accès aux Bases de Données avec JDBC]]**\n\n- Connexion à une base de données (`DriverManager`, `DataSource`)\n- Exécution de requêtes (`Statement`, `PreparedStatement`, `CallableStatement`)\n- Gestion des transactions (`commit`, `rollback`)\n\n### 12. **[[Certification Java 17 - Déploiement et Modules Java]]**\n\n- Compilation et création de JARs (`modulaires` et `non-modulaires`)\n- Images d’exécution (`jlink`)\n- Migration avec modules anonymes et automatiques\n\n### 13. **[[Certification Java 17 - Internationalisation et Localisation]]**\n\n- Locales (`Locale`)\n- `ResourceBundle` pour la gestion des ressources multilingues\n- Formatage des dates, nombres et devises (`NumberFormat`, `DateTimeFormatter`)\n\n[[Java]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e5648766-c198-4852-8a19-a50320131cca",
        "title": "ChromaDB",
        "shortDescription": "",
        "description": "---\nid: 501b3586-143e-448a-bae9-4ff77f3a5793\n---\n# Rapidement c'est quoi❓\n\nChromaDB est une [[Base de donnée]] vectorielle open-source permettant de stocker et de rechercher des vecteurs de plongement (embeddings).  Elle est conçue pour être facile à utiliser et à intégrer dans des applications de recherche sémantique.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nChromaDB est une base de données qui stocke et recherche des données non structurées en utilisant des embeddings.  Un embedding est une représentation vectorielle d'un morceau de texte, d'une image, ou d'un autre type de données.  Au lieu de chercher des données par mots clés exacts, ChromaDB permet de rechercher des données similaires en fonction de la similarité vectorielle des embeddings.  Cela permet de réaliser des recherches sémantiques, c'est-à-dire de trouver des éléments dont le sens est proche de la requête, même si les mots utilisés sont différents.\n\nChromaDB utilise une architecture client-serveur. Le client envoie des requêtes à un serveur qui contient la base de données.  Il supporte plusieurs types de stockage persistant, permettant ainsi une grande flexibilité.  Il offre des fonctionnalités comme l'ajout, la mise à jour et la suppression de données, ainsi que des méthodes de recherche basées sur la similarité cosinus ou d'autres métriques.  L'API est simple et intuitive, facilitant son intégration dans divers projets.  ChromaDB est particulièrement bien adapté aux applications de recherche sémantique, de recommandation, et de clustering.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open-source et facile à utiliser:**  Le code source est disponible publiquement, facilitant l'audit et la contribution.  Son API est simple à prendre en main.\n* **Flexibilité:** Supporte plusieurs types de stockage persistant (en mémoire, disque, etc.).\n* **Performance:**  Optimisé pour la recherche de similarité vectorielle à grande échelle.\n* **Recherche sémantique:** Permet de trouver des données similaires en fonction du sens, et non seulement des mots clés.\n* **Intégration facile:** API simple et bien documentée pour une intégration aisée dans différents projets.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Maturité relative:**  Comparé à des bases de données vectorielles plus établies, ChromaDB est relativement jeune et pourrait présenter des imperfections.\n* **Scalabilité:** Bien que performant, sa scalabilité à très grande échelle pourrait nécessiter une configuration et une optimisation avancées.\n* **Dépendances:**  Nécessite des bibliothèques spécifiques pour fonctionner, ce qui peut ajouter de la complexité à l'installation et à la configuration.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "643b7d68-8af3-4764-8cab-279e51c9bb42",
        "title": "Client Side Rendering (CSR)",
        "shortDescription": "",
        "description": "---\nid: f0414542-a158-439d-9e1b-0113e950e207\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLe **Client Side Rendering (CSR)** est une méthode de rendu des pages [[Web]] où le navigateur charge une page [[HTML]] basique et exécute ensuite du [[JavaScript]] pour générer dynamiquement le contenu de la page.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe CSR repose sur le principe que le code [[JavaScript]] du côté client (navigateur) est responsable de la construction de la page. Lorsqu'un utilisateur accède à une page, le navigateur charge un fichier [[HTML]] minimal, puis télécharge et exécute du [[JavaScript]] pour récupérer et afficher les données, souvent via des appels API. Cela permet un rendu dynamique et interactif sans avoir besoin d'un serveur pour générer la page à chaque requête.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Rapidité de compilation** : Seulement un transfert de fichiers est nécessaire, ce qui rend le processus de chargement initial rapide.\n- **Adapté au contenu dynamique** : Idéal pour des sites interactifs où le contenu change souvent, comme des applications web ou des plateformes sociales.\n- **Expérience utilisateur fluide** : Une fois la page rendue, l'interaction avec la page est rapide et réactive.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **[[SEO]] limité** : Le contenu n'est pas visible pour les moteurs de recherche avant l'exécution du [[JavaScript]], rendant l'indexation difficile pour le référencement.\n- **Temps de chargement initial** : Le navigateur doit exécuter tout le [[JavaScript]] avant d'afficher la page, ce qui peut entraîner des délais d'affichage significatifs, notamment sur des appareils peu puissants.\n- **Dépendance au [[JavaScript]]** : Les utilisateurs avec des configurations de navigateur non optimisées ou des désactivations de [[JavaScript]] ne verront pas correctement la page.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "450fc502-04e9-4dd5-bb5d-41d5be4cf560",
        "title": "Certification Java 17 - Collections et Tableaux",
        "shortDescription": "",
        "description": "---\nid: 205a0c04-b33c-475b-9a7f-cc1720da1bdb\n---\n## **7.1. Tableaux (`int[]`, `String[]`)**\n\n### **Déclaration et initialisation**\n\n```java\nint[] nombres = {1, 2, 3, 4, 5}; // Déclaration et affectation\nString[] noms = new String[3]; // Tableau de taille fixe (valeurs nulles)\n```\n\n### **Accès aux éléments**\n\n```java\nSystem.out.println(nombres[0]); // Affiche 1\nnoms[0] = \"Alice\";\n```\n\n### **Boucle `for` pour parcourir un tableau**\n\n```java\nfor (int i = 0; i < nombres.length; i++) {\n    System.out.println(nombres[i]);\n}\n```\n\n### **Boucle `for-each` (simplifiée)**\n\n```java\nfor (int nombre : nombres) {\n    System.out.println(nombre);\n}\n```\n\n### **Tri avec `Arrays.sort()`**\n\n```java\nimport java.util.Arrays;\n\nArrays.sort(nombres); // Trie le tableau en ordre croissant\nSystem.out.println(Arrays.toString(nombres));\n```\n\n\uD83D\uDCCC **Un tableau a une taille fixe et ne peut pas être redimensionné.**\n\n---\n\n## **7.2. Collections (`List`, `Set`, `Map`, `Deque`)**\n\n\uD83D\uDCCC **Les collections sont dynamiques**, contrairement aux tableaux.\n\n|**Interface**|**Implémentations courantes**|**Caractéristiques**|\n|---|---|---|\n|`List`|`ArrayList`, `LinkedList`|Ordonnée, doublons autorisés|\n|`Set`|`HashSet`, `LinkedHashSet`, `TreeSet`|Uniques, non ordonnées (`HashSet`), triées (`TreeSet`)|\n|`Map`|`HashMap`, `LinkedHashMap`, `TreeMap`|Clé/valeur, unique par clé|\n|`Deque`|`ArrayDeque`, `LinkedList`|Double-ended queue (FIFO/LIFO)|\n\n---\n\n### **`List` : Tableau dynamique (ArrayList, LinkedList)**\n\n```java\nimport java.util.*;\n\nList<String> liste = new ArrayList<>();\nliste.add(\"Java\");\nliste.add(\"Python\");\nliste.add(\"C++\");\n\nSystem.out.println(liste.get(1)); // Python\nliste.remove(\"C++\"); // Supprime C++\n```\n\n\uD83D\uDCCC **`ArrayList` est optimisé pour l’accès rapide, `LinkedList` pour l’insertion/suppression.**\n\n---\n\n### **`Set` : Ensemble d’éléments uniques**\n\n```java\nSet<String> set = new HashSet<>();\nset.add(\"Java\");\nset.add(\"Python\");\nset.add(\"Java\"); // Ignoré (pas de doublons)\nSystem.out.println(set);\n```\n\n\uD83D\uDCCC **`HashSet` (désordonné), `TreeSet` (trié), `LinkedHashSet` (ordre d’insertion).**\n\n---\n\n### **`Map` : Association clé/valeur**\n\n```java\nMap<String, Integer> map = new HashMap<>();\nmap.put(\"Alice\", 25);\nmap.put(\"Bob\", 30);\nSystem.out.println(map.get(\"Alice\")); // 25\n```\n\n\uD83D\uDCCC **`TreeMap` trie par clé, `LinkedHashMap` conserve l’ordre d’insertion.**\n\n---\n\n### **`Deque` : File d’attente double**\n\n```java\nDeque<String> deque = new ArrayDeque<>();\ndeque.addFirst(\"Premier\");\ndeque.addLast(\"Dernier\");\n\nSystem.out.println(deque.pollFirst()); // \"Premier\"\nSystem.out.println(deque.pollLast());  // \"Dernier\"\n```\n\n\uD83D\uDCCC **`Deque` peut être utilisé comme une pile (`Stack`) ou une file (`Queue`).**\n\n---\n\n## **7.3. API `SequencedCollection`, `SequencedSet`, `SequencedMap` (Java 21)**\n\n\uD83D\uDCCC **Ajouté en Java 21 pour gérer l’ordre des éléments de façon plus cohérente.**\n\n### **`SequencedCollection` : Collection ordonnée**\n\n```java\nSequencedCollection<String> list = new LinkedList<>();\nlist.addFirst(\"Début\");\nlist.addLast(\"Fin\");\n\nSystem.out.println(list.getFirst()); // Début\nSystem.out.println(list.getLast());  // Fin\n```\n\n\uD83D\uDCCC **Améliore `List`, `Deque` et `SortedSet` en offrant des méthodes `getFirst()`, `getLast()` et `reversed()`.**\n\n---\n\n### **`SequencedSet` : Ensemble ordonné**\n\n```java\nSequencedSet<String> set = new LinkedHashSet<>();\nset.add(\"Java\");\nset.add(\"Python\");\nSystem.out.println(set.getFirst()); // Java\nSystem.out.println(set.getLast());  // Python\n```\n\n\uD83D\uDCCC **Permet de récupérer le premier et le dernier élément d’un `Set`.**\n\n---\n\n### **`SequencedMap` : `Map` ordonnée**\n\n```java\nSequencedMap<String, Integer> map = new LinkedHashMap<>();\nmap.put(\"Alice\", 25);\nmap.put(\"Bob\", 30);\nSystem.out.println(map.firstEntry()); // Alice=25\nSystem.out.println(map.lastEntry());  // Bob=30\n```\n\n\uD83D\uDCCC **Ajoute `firstEntry()`, `lastEntry()` et `reversed()`.**\n\n---\n\n## **7.4. Manipulations des collections (ajout, suppression, tri)**\n\n### **Ajout et suppression**\n\n```java\nList<String> list = new ArrayList<>(List.of(\"Java\", \"Python\", \"C++\"));\nlist.add(\"JavaScript\"); // Ajout\nlist.remove(\"Python\");  // Suppression\nSystem.out.println(list);\n```\n\n### **Tri d’une `List` avec `Collections.sort()`**\n\n```java\nList<Integer> nombres = Arrays.asList(3, 1, 4, 1, 5);\nCollections.sort(nombres); // Tri croissant\nSystem.out.println(nombres);\n```\n\n### **Tri d’une `List` avec un comparateur personnalisé**\n\n```java\nList<String> mots = Arrays.asList(\"Banane\", \"Pomme\", \"Orange\");\nmots.sort(Comparator.reverseOrder()); // Tri décroissant\nSystem.out.println(mots);\n```\n\n---\n\n## **Résumé**\n\n✅ **Tableaux (`int[]`, `String[]`)** : Taille fixe, rapide mais rigide.  \n✅ **`List`, `Set`, `Map`, `Deque`** : Collections dynamiques et flexibles.  \n✅ **`SequencedCollection` (Java 21)** : Meilleure gestion de l’ordre des éléments.  \n✅ **Manipulations : ajout, suppression, tri avec `Collections.sort()`.**\n\n---",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a1ac1cfe-c0dc-436c-83ca-f17362f54d14",
        "title": "Common Vulnerabilities and Exposures (CVE)",
        "shortDescription": "",
        "description": "---\nid: 2411dd03-b943-417a-93c1-64d9ff895771\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLes **CVE (Common Vulnerabilities and Exposures)** sont des identifiants uniques attribués aux vulnérabilités de sécurité dans les logiciels et systèmes, permettant de les référencer de manière standardisée pour faciliter leur gestion et leur correction.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUn CVE est un identifiant unique attribué à une vulnérabilité ou exposition de sécurité. Chaque CVE contient :\n\n- **Un identifiant unique** : Exemple : **CVE-2021-34527**.\n- **Une description de la vulnérabilité** : Explication du problème de sécurité.\n- **Des références externes** : Liens vers des détails, solutions ou correctifs pour la vulnérabilité.\n\nLes CVE sont utilisés par les chercheurs en sécurité, les entreprises, et les administrateurs systèmes pour suivre et résoudre rapidement les failles de sécurité.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Standardisation** : Offre un système commun pour identifier et discuter des vulnérabilités, facilitant la collaboration entre les professionnels de la sécurité.\n- **Accessibilité** : Des bases de données publiques permettent de rechercher rapidement des informations sur les vulnérabilités.\n- **Gestion des risques** : Permet une gestion rapide des risques et l'application de correctifs ciblés.\n- **Suivi des mises à jour** : Aide à suivre l'évolution des vulnérabilités et des correctifs disponibles.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Manque de détails techniques** : Les CVE ne contiennent souvent pas suffisamment d'informations techniques pour comprendre en profondeur la vulnérabilité sans recherches supplémentaires.\n- **Délais de mise à jour** : Parfois, les vulnérabilités peuvent être référencées après une période de retard, laissant du temps aux attaquants pour les exploiter avant qu'un patch ne soit disponible.\n- **Pas de solutions intégrées** : Le CVE fournit une identification, mais il appartient aux entreprises de mettre en place des mesures pour corriger les vulnérabilités.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "099be107-e1d0-4ad3-93d9-53376662611b",
        "title": "Certification Java 17 - Concepts de Base en Java",
        "shortDescription": "",
        "description": "---\nid: f00b7523-614f-46cb-81f9-3a5e4acdd35b\n---\n## **1.1. Types primitifs et classes enveloppes (Wrapper)**\n\n### **Types primitifs en Java**\n\nJava propose **8 types primitifs** pour stocker des valeurs en mémoire de manière efficace. Ces types sont stockés directement en **mémoire stack**, ce qui les rend plus rapides et moins gourmands en mémoire que les objets.\n\n|Type|Bits|Valeur min|Valeur max|Valeur par défaut|\n|---|---|---|---|---|\n|`boolean`|8|`false`|`true`|`false`|\n|`byte`|8|-128|127|`0`|\n|`short`|16|-32 768|32 767|`0`|\n|`int`|32|-2^31|2^31 - 1|`0`|\n|`long`|64|-2^63|2^63 - 1|`0L`|\n|`float`|32|-|-|`0.0f`|\n|`double`|64|-|-|`0.0d`|\n|`char`|16|0 (`\\u0000`)|65 535|`\\u0000`|\n\n**Exemples d’utilisation des types primitifs :**\n\n```java\nboolean isActive = true;\nint age = 25;\ndouble price = 19.99;\nchar grade = 'A';\n```\n\n### **Classes Enveloppes (Wrappers)**\n\nJava offre des **classes enveloppes (Wrapper Classes)** pour permettre aux types primitifs d’être traités comme des objets. Cela est utile notamment pour travailler avec des collections (`List`, `Set`, `Map`), qui ne peuvent contenir que des objets.\n\n|Primitif|Classe Wrapper|\n|---|---|\n|`boolean`|`Boolean`|\n|`byte`|`Byte`|\n|`short`|`Short`|\n|`int`|`Integer`|\n|`long`|`Long`|\n|`float`|`Float`|\n|`double`|`Double`|\n|`char`|`Character`|\n\n**Exemple : Auto-boxing et Unboxing**\n\n```java\nInteger obj = 10;  // Auto-boxing (int -> Integer)\nint num = obj;     // Unboxing (Integer -> int)\n```\n\n- **Auto-boxing** : Conversion automatique d’un type primitif en objet wrapper.\n- **Unboxing** : Conversion automatique d’un objet wrapper en type primitif.\n\n---\n\n## **1.2. Opérations arithmétiques et booléennes**\n\n### **Promotion de type (Type Promotion)**\n\nLorsqu’une opération est réalisée entre différents types, **Java effectue une promotion automatique** :\n\n1. **Si un des opérandes est `double`**, le résultat est `double`.\n2. **Si un des opérandes est `float`**, le résultat est `float`.\n3. **Si un des opérandes est `long`**, le résultat est `long`.\n4. **Sinon, le résultat est `int`** (même si les opérandes sont `byte` ou `short`).\n\n**Exemples :**\n\n```java\nint a = 10;\ndouble b = 2.5;\ndouble result = a + b;  // a est promu en double => 10.0 + 2.5 = 12.5\n\nbyte x = 5;\nshort y = 10;\nint z = x + y;  // x et y sont promus en int => 5 + 10 = 15\n```\n\n### **Casting explicite**\n\nLorsque la promotion automatique ne convient pas, on utilise **le casting explicite** pour convertir manuellement un type.\n\n```java\ndouble d = 9.7;\nint i = (int) d;  // 9 (la partie décimale est tronquée)\n\nlong bigValue = 100000L;\nint smallValue = (int) bigValue;  // Attention : peut causer une perte de données si la valeur dépasse la capacité d’un int\n```\n\n### **Opérateurs arithmétiques**\n\n|Opérateur|Description|Exemple|\n|---|---|---|\n|`+`|Addition|`5 + 3 // 8`|\n|`-`|Soustraction|`9 - 2 // 7`|\n|`*`|Multiplication|`4 * 6 // 24`|\n|`/`|Division entière|`10 / 3 // 3`|\n|`%`|Modulo (reste)|`10 % 3 // 1`|\n\n**Attention : Division entre entiers**\n\n```java\nint result = 5 / 2;  // 2 (car division entière)\ndouble correctResult = 5 / 2.0;  // 2.5\n```\n\n### **Opérateurs booléens**\n\n| Opérateur | Description       | Exemple                  |\n| --------- | ----------------- | ------------------------ |\n| ==        | Égalité           | `a == b`                 |\n| `!=`      | Différent         | `a != b`                 |\n| `>`       | Supérieur         | `a > b`                  |\n| `<`       | Inférieur         | `a < b`                  |\n| `>=`      | Supérieur ou égal | `a >= b`                 |\n| `<=`      | Inférieur ou égal | `a <= b`                 |\n| `&&`      | ET logique        | `true && false // false` |\n| `         |                   | `                        |\n| `!`       | NON logique       | `!true // false`         |\n\n---\n\n## **1.3. Précédence des opérateurs**\n\nJava évalue les expressions en fonction de la priorité des opérateurs.  \n**Ordre de priorité (du plus élevé au plus faible) :**\n\n1. `++`, `--` (postfixés)\n2. `++`, `--`, `!`, `~` (préfixés)\n3. `*`, `/`, `%`\n4. `+`, `-`\n5. `<<`, `>>`, `>>>`\n6. `<`, `<=`, `>`, `>=`\n7. \"==\", \"!=\"\n8. `&`\n9. `^`\n10. `|`\n11. `&&`\n12. `||`\n13. `? :` (ternaire)\n14. `=`, `+=`, `-=`, `*=`, `/=`, etc.\n\n**Exemples :**\n\n```java\nint result = 5 + 2 * 3;  // 5 + (2 * 3) = 11\nboolean test = true || false && false; // true || (false && false) = true\n```\n\n**Bonnes pratiques :**\n\n- **Toujours utiliser des parenthèses** pour éviter les ambiguïtés.\n\n```java\nint result = (5 + 2) * 3;  // 21\n```\n\n---\n\n## **1.4. Inférence de Type avec `var`**\n\nIntroduit en Java 10, `var` permet à Java de **déduire le type d'une variable lors de l'initialisation**.\n\n```java\nvar x = 10;  // int\nvar text = \"Java\";  // String\nvar list = List.of(1, 2, 3);  // List<Integer>\n```\n\n**Limitations de `var` :**\n\n- **Doit être initialisé immédiatement** (`var x;` ne compile pas).\n- **Uniquement utilisable en local** (pas pour les champs de classe ni les paramètres de méthode).\n- **Ne peut pas être utilisé avec `null` sans type explicite**.\n\n```java\nvar value = null; // ERREUR, type indéfini\n```\n\n**Cas d’utilisation typique :**\n\n```java\nfor (var entry : map.entrySet()) {\n    System.out.println(entry.getKey() + \" -> \" + entry.getValue());\n}\n```\n\n---\n\n### **Résumé**\n\n✅ **Types primitifs vs Wrappers** (Auto-boxing, Unboxing)  \n✅ **Promotion de type & casting explicite**  \n✅ **Opérations arithmétiques et booléennes**  \n✅ **Précédence des opérateurs**  \n✅ **Inférence de type avec `var`**\n\n---\n[[Java]] [[Certification Java 17]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d27e1fa6-a6f5-4430-ae47-04f0792380f4",
        "title": "Certification Java 17 - Contrôle du Flux d'Exécution",
        "shortDescription": "",
        "description": "---\nid: 6e8b33a4-8d4c-4291-b3eb-f221452b3430\n---\n## **5.1. Structures de contrôle (`if/else`, `switch`, `while`, `for`, `do-while`)**\n\n### **`if/else` : Condition simple**\n\n```java\nint age = 20;\nif (age >= 18) {\n    System.out.println(\"Majeur\");\n} else {\n    System.out.println(\"Mineur\");\n}\n```\n\n\uD83D\uDCCC **Les blocs `{}` sont obligatoires si plusieurs instructions sont présentes.**\n\n### **Opérateur ternaire (`? :`)**\n\n```java\nString statut = (age >= 18) ? \"Majeur\" : \"Mineur\";\nSystem.out.println(statut);\n```\n\n---\n\n### **`switch` : Remplace plusieurs `if/else`**\n\n```java\nint jour = 3;\nswitch (jour) {\n    case 1 -> System.out.println(\"Lundi\");\n    case 2 -> System.out.println(\"Mardi\");\n    case 3 -> System.out.println(\"Mercredi\");\n    default -> System.out.println(\"Jour inconnu\");\n}\n```\n\n\uD83D\uDCCC **Depuis Java 12**, `switch` retourne une **valeur** directement :\n\n```java\nString jourNom = switch (jour) {\n    case 1 -> \"Lundi\";\n    case 2 -> \"Mardi\";\n    case 3 -> \"Mercredi\";\n    default -> \"Jour inconnu\";\n};\nSystem.out.println(jourNom);\n```\n\n---\n\n### **`while` : Exécution tant que la condition est vraie**\n\n```java\nint i = 0;\nwhile (i < 3) {\n    System.out.println(i);\n    i++;\n}\n```\n\n\uD83D\uDCCC **Utile quand on ne sait pas à l'avance combien d'itérations seront nécessaires.**\n\n---\n\n### **`do-while` : Exécute **au moins une fois** avant de tester la condition**\n\n```java\nint i = 0;\ndo {\n    System.out.println(i);\n    i++;\n} while (i < 3);\n```\n\n---\n\n### **`for` : Boucle avec un compteur**\n\n```java\nfor (int i = 0; i < 3; i++) {\n    System.out.println(i);\n}\n```\n\n### **`for-each` : Parcourir une collection**\n\n```java\nList<String> fruits = List.of(\"Pomme\", \"Banane\", \"Orange\");\nfor (String fruit : fruits) {\n    System.out.println(fruit);\n}\n```\n\n\uD83D\uDCCC **Plus lisible que `for (int i = 0; i < list.size(); i++)`**\n\n---\n\n## **5.2. Expressions `switch` et Pattern Matching**\n\nDepuis **Java 16+, `switch` permet du Pattern Matching**, évitant les conversions manuelles.\n\n### **Pattern Matching (`instanceof`)**\n\n**Avant Java 16**\n\n```java\nObject obj = \"Bonjour\";\nif (obj instanceof String) {\n    String s = (String) obj;  // Cast manuel obligatoire\n    System.out.println(s.length());\n}\n```\n\n\uD83D\uDCCC **Avec Java 16+, pas besoin de cast explicite :**\n\n```java\nif (obj instanceof String s) {\n    System.out.println(s.length()); // Automatique !\n}\n```\n\n---\n\n### **Pattern Matching avec `switch`** _(Java 17)_\n\n\uD83D\uDCCC **Permet d'éviter des `if/else` imbriqués**\n\n```java\nObject obj = 42;\n\nString resultat = switch (obj) {\n    case Integer i -> \"C'est un entier : \" + i;\n    case String s -> \"C'est une chaîne : \" + s;\n    default -> \"Type inconnu\";\n};\nSystem.out.println(resultat);\n```\n\n\uD83D\uDCCC **Ajout de conditions (`when`)**\n\n```java\nObject obj = 50;\nswitch (obj) {\n    case Integer i when i > 10 -> System.out.println(\"Nombre supérieur à 10\");\n    case Integer i -> System.out.println(\"Nombre inférieur ou égal à 10\");\n    default -> System.out.println(\"Autre type\");\n}\n```\n\n---\n\n## **5.3. Instructions `break` et `continue`**\n\n### **`break` : Sortie immédiate d'une boucle**\n\n```java\nfor (int i = 0; i < 5; i++) {\n    if (i == 3) break;  // Arrête la boucle dès que i == 3\n    System.out.println(i);\n}\n```\n\n**Sortie :**\n\n```\n0\n1\n2\n```\n\n### **`continue` : Passe directement à l’itération suivante**\n\n```java\nfor (int i = 0; i < 5; i++) {\n    if (i == 3) continue;  // Ignore l'affichage du 3\n    System.out.println(i);\n}\n```\n\n**Sortie :**\n\n```\n0\n1\n2\n4\n```\n\n\uD83D\uDCCC **Utilisation dans `while`**\n\n```java\nint i = 0;\nwhile (i < 5) {\n    i++;\n    if (i % 2 == 0) continue; // Ignore les nombres pairs\n    System.out.println(i);\n}\n```\n\n---\n\n## **Résumé**\n\n✅ **Structures de contrôle :** `if/else`, `switch`, `while`, `for`, `do-while`  \n✅ **`switch` moderne avec pattern matching** (Java 17)  \n✅ **Pattern Matching (`instanceof` avec variables)**  \n✅ **`break` pour arrêter une boucle**  \n✅ **`continue` pour passer à l’itération suivante**\n\n---\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "1d5c0267-8703-4ef6-9e3d-2c9bc2f4fba4",
        "title": "Cucumber",
        "shortDescription": "",
        "description": "---\nid: 03afbb9c-cf5e-4cd9-8c81-db00cb35b56b\n---\n# Rapidement c'est quoi❓\n\nCucumber est un outil de test d'automatisation basé sur le langage [[Gherkin]]. Il permet aux non-développeurs (ex: testeurs, analystes fonctionnels) de décrire des scénarios de test de manière claire et concise, facilitant la collaboration entre les équipes.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCucumber utilise le langage [[Gherkin]], un langage simple et lisible par tous, basé sur des mots clés comme \"Given\", \"When\", et \"Then\".  Ces mots clés structurent les scénarios de test en décrivant l'état initial (Given), l'action effectuée (When), et le résultat attendu (Then).  Un exemple simple:\n\n```gherkin\nFeature: Withdrawing cash\n  Scenario: Successful withdrawal within balance\n    Given Alice has $234.56 in their account\n    When Alice tries to withdraw $200.00\n    Then the withdrawal is successful\n\n  Scenario: Declined withdrawal in excess of balance\n    Given Hamza has $198.76 in their account\n    When Hamza tries to withdraw $200.00\n    Then the withdrawal is declined\n```\n\nLes développeurs implémentent ensuite le code qui correspond à chaque étape (\"Given\", \"When\", \"Then\").  Cette séparation des préoccupations (séparation entre la spécification du test et son implémentation) améliore la collaboration, la lisibilité et la maintenabilité des tests.  Cucumber peut être intégré à de nombreux frameworks de test (comme [[Selenium]], [[Cypress]] via `cypress-cucumber-preprocessor`), permettant ainsi d'automatiser l'exécution des scénarios.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Collaboration améliorée:**  Permet une communication plus claire entre les équipes techniques et non-techniques. Les tests sont écrits dans un langage compréhensible par tous.\n* **Maintenance facilitée:**  La séparation des spécifications et de l'implémentation rend les tests plus faciles à maintenir et à mettre à jour.\n* **Tests plus lisibles:** Le format [[Gherkin]] rend les tests plus clairs et plus faciles à comprendre, même pour les personnes non impliquées dans leur développement.\n* **Documentation vivante:** Les scénarios [[Gherkin]] servent également de documentation exécutable du système.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:**  La mise en place et l'utilisation efficace de Cucumber peuvent nécessiter un certain temps d'apprentissage, notamment pour définir des conventions claires et cohérentes.\n* **Nécessite une bonne collaboration:**  Le succès de Cucumber dépend fortement de la collaboration entre les équipes et d'une bonne compréhension des conventions utilisées.  Des définitions ambigües des \"Given\", \"When\" et \"Then\" peuvent rendre les tests difficiles à maintenir.\n* **Peut être verbeux:** Pour des tests complexes, la description [[Gherkin]] peut devenir assez longue et détaillée.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Testing]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "7ec4ed2f-43a1-4eb2-a1aa-108cb2b03985",
        "title": "Cypress",
        "shortDescription": "",
        "description": "---\nid: 80fa04db-9979-4f13-ae6a-087b96aa069b\n---\n# Rapidement c'est quoi❓\n\nCypress est un framework de test [[JavaScript]] populaire pour les applications web. Il permet de réaliser des [[Test End2End (E2E)]] et des [[Test unitaire (TU)]] de composants.  Il se distingue par sa facilité d'utilisation et son approche intégrée.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCypress est un outil complet pour le test d'applications web.  Il offre une approche basée sur le [[Document Object Model (DOM)]], exécutant les tests directement dans le navigateur.  Cela permet une interaction plus naturelle et intuitive avec l'application testée, contrairement à des solutions qui interagissent de manière distante.\n\nCypress propose deux types de tests principaux :\n\n* **[[Test End2End (E2E)]]:**  Ces tests simulent le comportement d'un utilisateur réel, interagissant avec l'interface utilisateur de bout en bout.  Ils vérifient le flux complet d'une action, de l'interaction de l'utilisateur à la réponse du serveur.\n\n* **[[Test de Composant]]:**  Ces tests permettent de tester des composants individuels de l'interface utilisateur isolément, sans dépendance à l'application complète. Ceci permet des tests unitaires plus rapides et ciblés.\n\nL'exécution des tests se fait directement dans le navigateur, offrant un débogage facile et une meilleure visibilité sur le déroulement des tests.  Cypress propose une API intuitive et chainable, facilitant la création et la maintenance des tests.  Les fonctions principales incluent la sélection d'éléments (ex: `cy.get()`, `cy.contains()`), l'interaction avec les éléments (ex: `cy.click()`, `cy.type()`), et les assertions (ex: `cy.should()`).  Des fonctionnalités avancées comme l'interception des requêtes réseau (`cy.intercept()`), l'exécution de tâches personnalisées (`cy.task()`), et la génération de rapports avec captures d'écran sont également disponibles.  La prise en charge de la couverture de code est possible via des plugins tiers.\n\nLa configuration est relativement simple, nécessitant un fichier `cypress.config.js` (ou `cypress.config.ts`) pour spécifier les paramètres de configuration, tels que l'URL de l'application et le navigateur à utiliser.  La gestion des données de test peut être réalisée via des dumps de base de données ou d'autres techniques.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Facilité d'utilisation et d'apprentissage:** L'API intuitive et la documentation claire rendent Cypress accessible aux débutants.\n* **Débogage simplifié:** L'exécution dans le navigateur permet un débogage facile et visuel.\n* **Tests rapides et fiables:**  L'exécution directe dans le navigateur assure des tests rapides et stables.\n* **API chainable:** La possibilité d'enchaîner les commandes facilite la création de tests lisibles et maintenables.\n* **Fonctionnalités complètes:** Cypress offre un ensemble complet de fonctionnalités, incluant la génération de rapports, les captures d'écran, et l'interception des requêtes réseau.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Support limité de Safari:** Le support de [[Safari]] est moins complet que pour d'autres navigateurs.\n* **Gestion limitée des onglets multiples:** La gestion des tests sur plusieurs onglets est limitée.\n* **Pas de support natif pour les tests mobiles:** Bien qu'il soit possible d'utiliser des solutions alternatives, il n'y a pas de support natif pour les tests sur des appareils mobiles.\n* **Prise en charge limitée des applications non-web:**  Son utilisation principale se concentre sur le web; l'adaptation à d'autres types d'applications (ex: [[Electron]]) peut nécessiter des solutions spécifiques.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Testing]]\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "9d6e109e-a4f3-49f9-a5b4-83691dd4497a",
        "title": "Debezium",
        "shortDescription": "",
        "description": "---\nid: 1f2f593a-0a66-4f5d-860c-1677d5949620\n---\n# Rapidement c'est quoi❓\n\nDebezium est un outil open-source qui capture et diffuse en temps réel les modifications de données ([[Capture Data Change (CDC)]]) dans les [[Base de donnée]].  Il permet de traiter ces changements de manière fiable et efficace.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nDebezium est un middleware de [[Capture Data Change (CDC)]] qui s'intègre à différentes [[Base de donnée]] ([[MySQL]], [[PostgreSQL]], [[MongoDB]], [[Oracle]], etc.) pour capturer les modifications de données (insertions, mises à jour, suppressions) de manière transparente.  Il utilise des mécanismes spécifiques à chaque système de gestion de bases de données (SGBD) pour surveiller les logs de transactions (binlogs, WAL, oplogs, etc.) et extraire les événements de changement.  Ces événements sont ensuite formatés en JSON et diffusés via différents connecteurs ([[Apache Kafka]], etc.).  La diffusion des données est effectuée de manière incrémentale, envoyant uniquement les modifications, ce qui rend le processus efficient et évite la duplication massive de données.  \n\nDebezium offre des fonctionnalités avancées comme :\n\n* **Filtrage des données:**  Possibilité de filtrer les données capturées en fonction de tables, de colonnes ou de critères spécifiques.\n* **Transformation des données:**  Les données peuvent être transformées avant d'être diffusées, par exemple pour normaliser les formats ou enrichir les événements avec des informations contextuelles.\n* **Gestion des erreurs et de la reprise:**  Debezium intègre des mécanismes pour gérer les erreurs et assurer la reprise sur panne.\n* **Haute disponibilité:**  La conception du système permet une haute disponibilité grâce à l'utilisation de technologies distribuées.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open-source et communautaire:**  Bénéficie d'un grand support communautaire et d'une maintenance active.\n* **Support de multiples SGBD:**  Permet de capturer les modifications de données dans une variété de bases de données.\n* **Performances et scalabilité:**  Conçu pour gérer de grands volumes de données et s'adapter à des besoins croissants.\n* **Flexibilité:**  Offre des options de configuration et de personnalisation étendues.\n* **Intégration avec [[Apache Kafka]]:**  S'intègre facilement avec [[Apache Kafka]] pour une diffusion robuste et distribuée des données.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité de configuration:**  La configuration initiale peut être complexe, surtout pour des environnements hétérogènes.\n* **Courbe d'apprentissage:**  Nécessite une certaine expertise en matière de [[Base de donnée]], de [[Data Streaming]] et de [[Capture Data Change (CDC)]].\n* **Dépendances:**  Dépend de différentes technologies ([[Apache Kafka]], par exemple), ajoutant une couche de complexité à la mise en place.\n* **Gestion des schémas:**  La gestion des évolutions de schémas de données peut nécessiter une attention particulière.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "103bec1a-cef0-45fb-8eb1-c13ed1074984",
        "title": "Docker Swarm",
        "shortDescription": "",
        "description": "---\nid: 3c134b45-51a4-4e25-9876-82facf350999\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**Docker Swarm** est un outil d'orchestration de containers intégré à [[Docker]]. Il permet de gérer un cluster de machines pour déployer et orchestrer des applications conteneurisées de manière simple et scalable.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nDocker Swarm permet de créer un cluster de machines (nœuds) et de déployer des containers sur ces nœuds. Il utilise un algorithme de consensus appelé **[[Raft]]** pour élire un leader et gérer l'état du cluster. Swarm facilite la gestion des services distribués, la mise à l'échelle automatique et la tolérance aux pannes. La configuration est simplifiée et ressemble à un **[[Docker Compose]]** amélioré.\n\n- **Nœuds** : Au moins 3 (idéalement 5) nœuds sont nécessaires pour garantir la résilience du cluster.\n- **Intégration avec Docker** : Swarm est inclus avec Docker, donc aucune installation supplémentaire n'est nécessaire.\n- **Interface graphique** : Des outils comme **[[Portainer]]** peuvent être utilisés pour gérer visuellement le cluster Docker Swarm.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Facilité d'intégration** : Déjà inclus avec [[Docker]], pas besoin d'installation supplémentaire.\n- **Simplicité de configuration** : La configuration des services se fait via un fichier similaire à Docker Compose.\n- **Haute disponibilité** : Grâce à [[Raft]], le leader du cluster est élu et le consensus est maintenu, ce qui garantit la résilience.\n- **Mise à l'échelle automatique** : Permet d'ajuster automatiquement le nombre de réplicas des services selon la charge.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Moins de fonctionnalités avancées** : Par rapport à [[Kubernetes]], Swarm propose moins de fonctionnalités avancées pour la gestion complexe des clusters.\n- **Scalabilité limitée** : Bien que Swarm soit bien adapté pour des petits à moyens clusters, il n'est pas aussi performant que [[Kubernetes]] pour des environnements de très grande échelle.\n- **Communauté plus petite** : La communauté et les ressources sont plus limitées comparées à des solutions comme [[Kubernetes]].\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "23f53224-8522-45d1-b851-4fff726a77a5",
        "title": "Certification Java 17 - Déploiement et Modules Java",
        "shortDescription": "",
        "description": "---\nid: e04928bd-dd1d-411a-a12e-6760db620a4c\n---\n## **12.1. Compilation et création de JARs (modulaires et non-modulaires)**\n\nJava permet de compiler et de regrouper les classes dans des fichiers **JAR** (`Java Archive`). Avec **Java 9+, le système de modules (`JPMS`)** permet de mieux organiser les dépendances.\n\n---\n\n### **1. Compilation et exécution d’un projet classique (non modulaire)**\n\n\uD83D\uDCCC **Un projet classique n’utilise pas `module-info.java`**\n\n**Compilation** :\n\n```sh\njavac -d out src/com/exemple/Main.java\n```\n\n**Création du JAR :**\n\n```sh\njar --create --file monApp.jar -C out .\n```\n\n**Exécution :**\n\n```sh\njava -jar monApp.jar\n```\n\n---\n\n### **2. Compilation et exécution d’un projet modulaire**\n\n\uD83D\uDCCC **Un projet modulaire utilise `module-info.java`.**\n\n\uD83D\uDCC2 **Structure :**\n\n```\n/mon-projet\n  /src\n    /com.exemple.main\n      module-info.java\n      Main.java\n```\n\n\uD83D\uDCC4 **`module-info.java`**\n\n```java\nmodule com.exemple.main {\n    requires com.exemple.util;\n}\n```\n\n**Compilation** :\n\n```sh\njavac -d out --module-source-path src $(find src -name \"*.java\")\n```\n\n**Création du JAR modulaire :**\n\n```sh\njar --create --file mods/com.exemple.main.jar --module-version=1.0 -C out/com.exemple.main .\n```\n\n**Exécution du module :**\n\n```sh\njava --module-path mods -m com.exemple.main/com.exemple.Main\n```\n\n\uD83D\uDCCC **Avantages des JARs modulaires :**\n\n- Encapsulation des modules.\n- Réduction des conflits de dépendances.\n\n---\n\n## **12.2. Création d’images d’exécution avec `jlink`**\n\n\uD83D\uDCCC **Depuis Java 9, `jlink` permet de créer une image d’exécution sans installer une JDK complète.**\n\n### **1. Génération d’une image compacte**\n\n```sh\njlink --module-path $JAVA_HOME/jmods:mods \\\n      --add-modules com.exemple.main \\\n      --output monApp-image\n```\n\n\uD83D\uDCCC **Cela crée un dossier `monApp-image` contenant une JRE minimale avec uniquement les modules nécessaires.**\n\n**Exécution de l’application sans JDK installé :**\n\n```sh\nmonApp-image/bin/java -m com.exemple.main/com.exemple.Main\n```\n\n\uD83D\uDCCC **Avantages de `jlink` :**\n\n- Réduction de la taille de l’application.\n- Pas besoin d’une installation Java sur l’environnement cible.\n\n---\n\n## **12.3. Migration avec modules anonymes et automatiques**\n\n\uD83D\uDCCC **Lors de la migration d’un projet Java classique vers un projet modulaire, il existe trois types de modules :**\n\n|**Type de module**|**Définition**|\n|---|---|\n|**Module Explicite**|Défini avec `module-info.java`|\n|**Module Automatique**|Un JAR classique dans `module-path` devient un module|\n|**Module Anonyme**|Un JAR non modulaire placé dans `classpath`|\n\n---\n\n### **1. Modules automatiques**\n\n\uD83D\uDCCC **Un JAR non modulaire devient un module s’il est placé dans `--module-path`.**\n\nExemple :\n\n```sh\njava --module-path lib --add-modules nom.du.module -m com.exemple.main/com.exemple.Main\n```\n\n\uD83D\uDCCC **Son nom est dérivé du fichier JAR (`lib/monJAR.jar` devient `monJAR`).**\n\n---\n\n### **2. Modules anonymes**\n\n\uD83D\uDCCC **Si un JAR est laissé dans le `classpath`, il fonctionne comme un module anonyme.**\n\nExemple :\n\n```sh\njava -classpath lib/monJAR.jar com.exemple.Main\n```\n\n\uD83D\uDCCC **Mais il ne peut pas être référencé par un module explicite.**\n\n---\n\n## **Résumé**\n\n✅ **JARs : Compilation et création de JARs modulaires et non-modulaires.**  \n✅ **`jlink` : Création d’une image d’exécution sans JDK complet.**  \n✅ **Migration vers Java 9+ : Modules anonymes et automatiques pour compatibilité.**\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "0720059e-55bb-4a4b-bb8d-75fd23d0c0df",
        "title": "Elastic Search",
        "shortDescription": "",
        "description": "---\nid: 694568ef-b128-4cdb-bc87-67ae174314f9\n---\n# Rapidement c'est quoi❓\n\nElasticsearch est un moteur de recherche et une [[Base de donnée NoSQL]] distribuée, open source, permettant des recherches complexes et rapides sur de grands volumes de données.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nElasticsearch est un système de recherche et d'analyse de données basé sur le moteur de recherche [[Apache Lucene]]. Il utilise une architecture distribuée, permettant de répartir les données sur plusieurs serveurs pour améliorer les performances et la scalabilité.  Il indexe les données (les transforme en un format optimisé pour la recherche) et les stocke dans une structure inversée, permettant des recherches rapides même sur des ensembles de données très volumineux.  Contrairement aux bases de données relationnelles, Elasticsearch n'utilise pas de schémas fixes, offrant une grande flexibilité.  Il supporte de nombreux types de données (texte, numérique, géographique, etc.) et permet de réaliser des requêtes complexes avec des filtres, des agrégations, et des fonctionnalités de scoring pour classer les résultats.  Il est souvent utilisé pour la recherche en temps réel, l'analyse de logs, la surveillance, et bien d'autres applications nécessitant des recherches performantes sur des données non-structurées ou semi-structurées.  Son API RESTful facilite son intégration avec d'autres applications.  La gestion de clusters permet une haute disponibilité et une tolérance aux pannes.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Performance de recherche:**  Extrêmement rapide, même sur des index gigantesques.\n* **Scalabilité:** Facilement extensible pour gérer des volumes de données croissants.\n* **Flexibilité:**  Supporte différents types de données et permet des requêtes complexes.\n* **Open source:** Communauté active et large choix d'outils et de plugins.\n* **API RESTful simple et intuitive:**  Facilite l'intégration avec d'autres systèmes.\n* **Haute disponibilité:**  Architecture distribuée permettant une tolérance aux pannes.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:**  La configuration et la gestion d'un cluster Elasticsearch peuvent être complexes pour les débutants.\n* **Consommation de ressources:**  Nécessite des ressources matérielles importantes pour gérer de grands volumes de données.\n* **Gestion des transactions:**  Pas aussi robuste que les bases de données relationnelles pour les transactions ACID.\n* **Dépendance aux plugins:** Certaines fonctionnalités avancées nécessitent l'installation de plugins.\n* **Courbe d'apprentissage:** Peut nécessiter un temps d'apprentissage conséquent pour maîtriser toutes ses fonctionnalités.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d7d2e235-de41-4429-8cc3-2048f7ea0f17",
        "title": "Feature Flag",
        "shortDescription": "",
        "description": "---\nid: 5c3b2bc6-21b3-493c-8658-e5078738ffc5\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLes **feature flags** sont des mécanismes permettant d'activer ou de désactiver des fonctionnalités dans une application sans avoir à redéployer le code. Elles permettent de contrôler l'accès à certaines parties du logiciel en temps réel.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUn **feature flag** (ou _switch_) est un contrôle qui permet de gérer dynamiquement l'activation d'une fonctionnalité dans une application. Cela permet de :\n\n- **Désactiver rapidement** une fonctionnalité en cas de bugs ou de problème de performance.\n- **Restreindre l'accès** à certaines fonctionnalités en fonction de critères (utilisateur, région, version, etc.).\n- **Tester des fonctionnalités** (A/B testing) et expérimenter des évolutions avant de les déployer à tous les utilisateurs.\n\nLes **feature flags** doivent être utilisés temporairement. Une fois qu'une fonctionnalité est stable et validée, le flag devient inutile et doit être retiré.\n\nLes **paradigmes** de gestion des flags sont les suivants :\n\n- **Évaluation côté serveur** : Le serveur vérifie le statut du flag à chaque appel.\n- **Évaluation côté client** : Le flag est mis à jour dans le navigateur et peut immédiatement changer l'état de la page.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Flexibilité** : Permet d'activer ou désactiver des fonctionnalités sans redéployer, facilitant les corrections rapides.\n- **Contrôle en temps réel** : Offre un contrôle granulaire sur la disponibilité des fonctionnalités.\n- **Amélioration de la gestion des risques** : Idéal pour tester des nouvelles fonctionnalités sans impacter tous les utilisateurs.\n- **Expérimentation** : Pratique pour effectuer des tests A/B et valider des changements avant leur déploiement complet.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité de gestion** : Si trop de flags sont laissés en place, cela peut rendre le code plus complexe à maintenir.\n- **Risques de dépendances** : L'activation ou la désactivation des flags peut introduire des comportements inattendus si mal gérés.\n- **Dettes techniques** : Les flags doivent être supprimés dès qu'ils ne sont plus nécessaires, sinon ils peuvent s'accumuler et encombrer le code.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "dae92eec-24b8-41c0-9323-03f55e0f261f",
        "title": "Feign",
        "shortDescription": "",
        "description": "---\nid: e2c9e1f7-64bc-479b-b312-977feb4a83ec\n---\n# Rapidement c'est quoi❓\n\nFeign est une bibliothèque [[Java]] qui simplifie la création d'interfaces clientes pour communiquer avec des services web [[RESTful]].  Elle permet de définir des interfaces Java qui sont ensuite traduites en appels [[HTTP]] par Feign.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nFeign est une bibliothèque client [[HTTP]] déclarative pour [[Java]].  Au lieu d'écrire du code HTTP verbeux (gestion des connexions, envoi des requêtes, parsing des réponses...), vous déclarez une interface Java annotée avec des annotations spécifiques (comme `@RequestMapping` de Spring MVC) pour définir les endpoints des services web. Feign se charge ensuite de générer le code nécessaire pour effectuer les appels HTTP et de gérer les détails de bas niveau.  L'interface décrit simplement la méthode HTTP (GET, POST, etc.), l'URL, les paramètres d'entrée et la structure des données de sortie.\n\nFeign s'intègre particulièrement bien avec [[Spring Boot]], offrant un starter qui simplifie encore plus son intégration et sa configuration.  Il est souvent utilisé dans les [[Micros services]] pour communiquer entre eux, facilitant la gestion des appels inter-services et améliorant la maintenabilité du code.  Il supporte différents codecs (pour la sérialisation/désérialisation des données) comme [[Jackson]] et [[Gson]].  L'intégration avec des mécanismes de gestion des erreurs et de retries est également possible.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Déclaratif et concis:**  Le code est plus lisible et plus facile à maintenir grâce à l'approche déclarative.  On se concentre sur la logique métier plutôt que sur les détails [[HTTP]].\n* **Intégration [[Spring Boot]]:**  Le starter [[Spring Boot]] simplifie considérablement la configuration et l'intégration avec l'écosystème Spring.\n* **Support de plusieurs codecs:**  La flexibilité de choisir son codec ([[Jackson]], [[Gson]], etc.) permet de s'adapter à différents besoins de sérialisation/désérialisation.\n* **Amélioration de la maintenabilité:**  Le code est plus propre et plus facile à comprendre, ce qui facilite la maintenance et les modifications futures.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage initiale:**  Bien que déclaratif, il faut comprendre les annotations et les mécanismes de Feign pour l'utiliser efficacement.\n* **Débogage:**  Le débogage peut être plus complexe car les appels HTTP sont gérés en interne par Feign.  Un bon logging est essentiel.\n* **Complexité potentielle pour des scénarios avancés:**  Pour des scénarios complexes de gestion des erreurs, d'authentification ou de proxies, une configuration plus avancée peut être nécessaire.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "811981f6-bf27-4a66-b238-b039f2f14b3e",
        "title": "Firecracker",
        "shortDescription": "",
        "description": "---\nid: 77d3c304-e73a-4cb4-b3b3-3a683e1ce849\n---\n# Rapidement c'est quoi❓\n\nFirecracker est une technologie de [[Virtualisation]] légère, permettant de lancer des micro-machines virtuelles (micro [[VM]]) isolées. [[AWS]] l'utilise notamment pour son service Lambda.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nFirecracker est un hyperviseur open source développé par Amazon Web Services ([[AWS]]).  Son objectif principal est de fournir un environnement d'exécution sécurisé et performant pour les fonctions sans serveur.  Au lieu d'utiliser des conteneurs ou des processus partagés, Firecracker crée une microVM pour chaque fonction. Cela signifie que chaque fonction s'exécute dans son propre espace d'adressage isolé, avec son propre noyau léger.  Ce niveau d'isolation améliore la sécurité en empêchant une fonction compromise d'affecter les autres.  Les microVM Firecracker sont conçues pour démarrer très rapidement (millisecondes) et utiliser des ressources minimales, ce qui est crucial pour les architectures [[Function as a Service (FaaS)]] où de nombreuses fonctions peuvent être exécutées simultanément.  Son architecture repose sur un hyperviseur basé sur [[Kernel-based Virtual Machine (KVM)]],  mais avec une surface d'attaque significativement réduite grâce à un design minimaliste et une gestion fine des ressources.  Cela assure une meilleure performance et une plus grande fiabilité comparé à des solutions de virtualisation plus lourdes.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Sécurité accrue:** L'isolation au niveau de la [[microVM]] offre une sécurité significativement améliorée par rapport aux conteneurs, limitant l'impact d'une compromission.\n* **Démarrage rapide:** Les [[microVM]] Firecracker démarrent très rapidement, optimisant l'efficacité des architectures [[Function as a Service (FaaS)]].\n* **Ressources légères:** Elles utilisent peu de ressources système, permettant un meilleur rapport coût-performance.\n* **Open source:** La nature open source permet l'auditabilité du code et la contribution de la communauté.\n* **Intégration avec les outils existants:**  Firecracker peut s'intégrer facilement avec des systèmes existants pour la gestion et le provisionnement des machines virtuelles.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La gestion de nombreuses [[microVM]] peut complexifier l'infrastructure par rapport à des solutions basées sur des conteneurs.\n* **Surcoût potentiel:**  Bien que léger, le surcoût de la virtualisation reste présent comparé à l'exécution directe de fonctions dans un environnement non virtualisé.  Toutefois, ce surcoût est souvent compensé par les gains en sécurité et isolation.\n* **Nécessite un hyperviseur compatible:** Le fonctionnement repose sur un hyperviseur compatible, comme [[Kernel-based Virtual Machine (KVM)]].\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "336c3829-0dde-46ae-ad99-313b5adff93d",
        "title": "Flintlock",
        "shortDescription": "",
        "description": "---\nid: 84fd28c0-e6a9-44a2-adec-e0a23bf37653\n---\n# Rapidement c'est quoi❓\n\nFlintlock est un gestionnaire de paquets pour [[Firecracker]].  Il simplifie le déploiement et la gestion de microservices basés sur [[Firecracker]].\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nFlintlock est un outil en ligne de commande qui permet de gérer le cycle de vie complet des [[microVM]] basées sur [[Firecracker]].  Il automatise des tâches telles que la création, le démarrage, l'arrêt et la suppression de [[microVM]], ainsi que la gestion des images de démarrage et des ressources associées.  Flintlock gère la configuration des [[microVM]], y compris l'allocation de ressources CPU, mémoire et stockage. Il permet également de gérer le réseautage des [[microVM]], en les connectant à des réseaux virtuels ou physiques.  L'objectif principal de Flintlock est de simplifier le processus de déploiement et de gestion d'applications conteneurisées ou sans serveur, exécutées dans des environnements isolés et sécurisés grâce à [[Firecracker]]. Il agit comme une couche d'abstraction, cachant la complexité de la gestion directe de Firecracker.  Flintlock utilise des fichiers de configuration (généralement au format YAML) pour définir les paramètres des [[microVM]].  Ces configurations décrivent les ressources allouées, les images à utiliser, les réseaux et autres aspects du déploiement.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Automatisation:**  Flintlock automatise les tâches répétitives, simplifiant considérablement la gestion des [[microVM]].\n* **Simplification:**  Il masque la complexité de [[Firecracker]], le rendant plus accessible aux développeurs.\n* **Gestion de cycle de vie complet:**  Il gère la création, le démarrage, l'arrêt et la suppression des [[microVM]].\n* **Gestion des ressources:**  Il permet un contrôle précis de l'allocation des ressources (CPU, mémoire, stockage).\n* **Intégration facile (potentielle):**  Son interface en ligne de commande facilite l'intégration dans des pipelines [[CI/CD]].\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Maturité:**  En tant que projet relativement récent, Flintlock pourrait présenter des bugs ou des fonctionnalités manquantes.\n* **Documentation:** La documentation pourrait être plus complète et détaillée pour certains aspects.\n* **Dépendance à Firecracker:** Flintlock est intrinsèquement lié à [[Firecracker]], limitant son usage aux environnements utilisant ce hyperviseur.\n* **Communauté:** La communauté autour de Flintlock pourrait être moins active que pour des projets plus établis.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "ea91c790-320f-495e-9b38-8c6c3795e063",
        "title": "Function as a Service (FaaS)",
        "shortDescription": "",
        "description": "---\nid: 549b4aed-718c-4342-8b40-b3a1f957ef81\n---\n# Rapidement c'est quoi❓\n\nFonction as a Service (FaaS) : Exécution de code sans gestion d'infrastructures.  Vous envoyez du code, il s'exécute, puis les ressources sont libérées.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe Function as a Service (FaaS) est un modèle de cloud computing où le fournisseur de cloud gère l'infrastructure et vous fournissez uniquement le code de votre fonction.  Cette fonction est un petit morceau de code, généralement sans état (stateless), qui s'exécute en réponse à un événement spécifique.  Cet événement peut être une requête [[HTTP]], un message dans une file d'attente, un changement de données dans une base de données, etc.\n\nUne fois l'événement déclencheur traité, la fonction s'exécute, effectue son traitement (par exemple, le traitement d'une image, l'envoi d'un email, la mise à jour d'une base de données), puis se termine.  Le fournisseur de cloud gère automatiquement le scaling (mise à l'échelle) : il peut exécuter plusieurs instances de votre fonction simultanément pour gérer les pics de demande, et réduire le nombre d'instances lorsque la demande diminue.  Vous ne payez que pour la durée d'exécution de votre fonction, ce qui permet une tarification très avantageuse pour les charges de travail sporadiques ou imprévisibles.\n\nLes plateformes FaaS populaires incluent [[AWS Lambda]], [[Google Cloud Functions]], [[Azure Functions]], etc.  Elles offrent des fonctionnalités supplémentaires comme le monitoring, le logging, et l'intégration avec d'autres services cloud.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Tarification économique:** Payez uniquement pour le temps d'exécution, idéal pour les applications événementielles et les [[Micros services]].\n* **Scalabilité automatique:** Le fournisseur de cloud gère la mise à l'échelle, vous n'avez pas à vous soucier des ressources.\n* **Simplicité de déploiement:** Déployez facilement votre code sans gérer d'infrastructures.\n* **Maintenance réduite:** Le fournisseur de cloud gère la maintenance et les mises à jour.\n* **Intégration facile:** S'intègre souvent avec d'autres services cloud.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Cold starts:** Le premier appel à une fonction peut prendre plus de temps car elle doit être initialisée.\n* **Limitations de ressources:** Les fonctions ont des limitations de ressources (mémoire, temps d'exécution).\n* **Débogage plus complexe:** Le débogage peut être plus complexe que dans une application traditionnelle.\n* **Modèle événementiel:**  Ne convient pas à toutes les applications, notamment celles nécessitant des connexions persistantes ou un état stable.\n* **Verrouillage fournisseur:** Migration potentiellement difficile entre différents fournisseurs de FaaS.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "eaaa031f-71c3-45df-9287-a65bff77495b",
        "title": "Certification Java 17 - Gestion des Exceptions",
        "shortDescription": "",
        "description": "---\nid: 92360517-fdbe-479f-bdfb-06c5d02db86f\n---\n## **6.1. Utilisation de `try/catch/finally`**\n\nEn Java, une **exception** est une erreur qui interrompt le programme. Elle peut être **gérée** avec `try/catch/finally`.\n\n### **Structure d’un bloc `try/catch/finally`**\n\n```java\ntry {\n    int result = 10 / 0;  // Provoque une ArithmeticException\n    System.out.println(result);\n} catch (ArithmeticException e) {\n    System.out.println(\"Erreur : division par zéro !\");\n} finally {\n    System.out.println(\"Ce bloc s’exécute toujours !\");\n}\n```\n\n\uD83D\uDCCC **Le `finally` est toujours exécuté**, même en cas d’exception. Il sert généralement à **fermer des ressources** (fichiers, connexions).\n\n---\n\n## **6.2. `try-with-resources` : Gestion automatique des ressources**\n\nIntroduit en **Java 7**, ce bloc permet de fermer automatiquement les ressources implémentant **`AutoCloseable`**.\n\n### **Exemple avec `try-with-resources`**\n\n```java\nimport java.io.*;\n\npublic class Exemple {\n    public static void main(String[] args) {\n        try (BufferedReader br = new BufferedReader(new FileReader(\"fichier.txt\"))) {\n            System.out.println(br.readLine()); // Lit la première ligne\n        } catch (IOException e) {\n            System.out.println(\"Erreur d'E/S : \" + e.getMessage());\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **Pas besoin de fermer `BufferedReader` manuellement**, il est automatiquement fermé à la fin du bloc.\n\n---\n\n## **6.3. Multi-catch : Attraper plusieurs exceptions**\n\nDepuis **Java 7**, on peut attraper plusieurs exceptions dans un seul `catch`, avec `|`.\n\n```java\ntry {\n    int[] tab = {1, 2, 3};\n    System.out.println(tab[5]);  // Provoque une ArrayIndexOutOfBoundsException\n} catch (ArithmeticException | ArrayIndexOutOfBoundsException e) {\n    System.out.println(\"Erreur : \" + e.getClass().getSimpleName());\n}\n```\n\n\uD83D\uDCCC **Avantages :**\n\n- Simplifie le code en regroupant des exceptions similaires.\n- Évite les blocs `catch` redondants.\n\n\uD83D\uDCCC **Restrictions :**\n\n- Les exceptions ne doivent **pas avoir de relation d’héritage** (ex: `IOException` et `FileNotFoundException` sont invalides ensemble, car `FileNotFoundException` hérite de `IOException`).\n\n---\n\n## **6.4. Exceptions personnalisées (`extends Exception` ou `extends RuntimeException`)**\n\n### **1. Exceptions contrôlées (`extends Exception`)**\n\n\uD83D\uDD39 **Obligation** de les gérer avec `try/catch` ou `throws`.  \n\uD83D\uDD39 Utilisées pour les erreurs prévisibles (ex : erreurs métier).\n\n```java\nclass MonException extends Exception {\n    public MonException(String message) {\n        super(message);\n    }\n}\n\npublic class Test {\n    public static void main(String[] args) {\n        try {\n            verifier(15);\n        } catch (MonException e) {\n            System.out.println(\"Erreur capturée : \" + e.getMessage());\n        }\n    }\n\n    static void verifier(int valeur) throws MonException {\n        if (valeur < 18) {\n            throw new MonException(\"Âge insuffisant !\");\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **`throws` indique qu’une méthode peut lever une exception.**\n\n---\n\n### **2. Exceptions non contrôlées (`extends RuntimeException`)**\n\n\uD83D\uDD39 **Pas besoin** de `try/catch`, elles interrompent le programme.  \n\uD83D\uDD39 Utilisées pour des erreurs de programmation (ex : `NullPointerException`).\n\n```java\nclass MonRuntimeException extends RuntimeException {\n    public MonRuntimeException(String message) {\n        super(message);\n    }\n}\n\npublic class Test {\n    public static void main(String[] args) {\n        calculer(0);\n    }\n\n    static void calculer(int valeur) {\n        if (valeur == 0) {\n            throw new MonRuntimeException(\"Division par zéro interdite !\");\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **Différence avec `Exception`** : pas d'obligation de gestion avec `try/catch`.\n\n---\n\n## **Résumé**\n\n✅ **`try/catch/finally`** : Gère les erreurs, `finally` s'exécute toujours.  \n✅ **`try-with-resources`** : Ferme automatiquement les ressources (`AutoCloseable`).  \n✅ **Multi-catch (`catch` multiple)** : Regroupe plusieurs exceptions en une seule clause.  \n✅ **Exceptions personnalisées** :\n\n- `extends Exception` (**contrôlées**) → Doit être gérée (`throws` ou `try/catch`).\n- `extends RuntimeException` (**non contrôlées**) → Pas d’obligation de gestion.\n\n---",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "f750c1bb-d1a8-4f7f-b3d5-2dc4dfab5455",
        "title": "Certification Java 17 - Gestion des types Date, Temps, Texte et Numérique",
        "shortDescription": "",
        "description": "---\nid: 8ed7f80e-caff-443e-8f21-ac0ffb429bec\n---\n## **4.1. API Date-Time : `LocalDate`, `LocalTime`, `LocalDateTime`, `ZonedDateTime`**\n\nDepuis **Java 8**, la gestion des dates et heures se fait via l’**API `java.time`**, qui remplace `java.util.Date` et `java.util.Calendar`.\n\n|**Classe**|**Description**|\n|---|---|\n|`LocalDate`|Date sans heure ni fuseau horaire|\n|`LocalTime`|Heure sans date ni fuseau horaire|\n|`LocalDateTime`|Date et heure sans fuseau horaire|\n|`ZonedDateTime`|Date, heure et fuseau horaire|\n\n### **Exemples : Création et manipulation**\n\n```java\nimport java.time.*;\n\npublic class DateTimeDemo {\n    public static void main(String[] args) {\n        LocalDate date = LocalDate.now();  // Date actuelle\n        LocalTime time = LocalTime.now();  // Heure actuelle\n        LocalDateTime dateTime = LocalDateTime.now();  // Date et heure actuelle\n        ZonedDateTime zonedDateTime = ZonedDateTime.now();  // Avec fuseau horaire\n\n        System.out.println(date);         // 2025-03-05\n        System.out.println(time);         // 14:30:45.123\n        System.out.println(dateTime);     // 2025-03-05T14:30:45.123\n        System.out.println(zonedDateTime);// 2025-03-05T14:30:45.123+01:00[Europe/Paris]\n    }\n}\n```\n\n### **Manipulation des dates et heures**\n\nLes objets `java.time` sont **immuables**, donc chaque modification retourne une nouvelle instance.\n\n```java\nLocalDate date = LocalDate.of(2025, 3, 5);\nLocalDate newDate = date.plusDays(10).minusMonths(1);  // 2025-02-15\nLocalTime newTime = LocalTime.of(10, 30).plusHours(2); // 12:30\n```\n\n### **Formatage des dates**\n\n```java\nimport java.time.format.DateTimeFormatter;\n\nLocalDate date = LocalDate.now();\nDateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"dd/MM/yyyy\");\nSystem.out.println(date.format(formatter)); // 05/03/2025\n```\n\n---\n\n## **4.2. `Period`, `Duration`, `Instant` pour les intervalles de temps**\n\n|**Classe**|**Utilisation**|\n|---|---|\n|`Period`|Représente une différence en **jours, mois ou années**|\n|`Duration`|Représente une différence en **heures, minutes, secondes**|\n|`Instant`|Un point précis dans le temps (timestamp)|\n\n### **Exemples : `Period`**\n\n```java\nPeriod period = Period.of(1, 2, 3); // 1 an, 2 mois, 3 jours\nLocalDate date = LocalDate.now().plus(period);\nSystem.out.println(date);\n```\n\n### **Exemples : `Duration`**\n\n```java\nDuration duration = Duration.ofHours(5);\nLocalTime time = LocalTime.now().plus(duration);\nSystem.out.println(time);\n```\n\n### **Exemples : `Instant` (Timestamp)**\n\n```java\nInstant instant = Instant.now();\nSystem.out.println(instant); // 2025-03-05T13:15:30.123Z\n```\n\n---\n\n## **4.3. Manipulation de texte : `String`, `StringBuilder`, Text Blocks**\n\n### **`String` : immutable**\n\n\uD83D\uDCCC **Chaque modification crée un nouvel objet.**\n\n```java\nString s = \"Java\";\ns = s.concat(\" 21\"); // Nouvelle instance\nSystem.out.println(s); // Java 21\n```\n\n### **`StringBuilder` : mutable et performant**\n\n\uD83D\uDCCC **Utilisé pour éviter la création excessive d’objets.**\n\n```java\nStringBuilder sb = new StringBuilder(\"Java\");\nsb.append(\" 21\");\nSystem.out.println(sb); // Java 21\n```\n\n|**Classe**|**Immutable ?**|**Thread-safe ?**|**Performance**|\n|---|---|---|---|\n|`String`|✅ Oui|✅ Oui|\uD83D\uDEAB Lent (création d’objets)|\n|`StringBuilder`|\uD83D\uDEAB Non|\uD83D\uDEAB Non|✅ Rapide|\n|`StringBuffer`|\uD83D\uDEAB Non|✅ Oui|✅ Rapide (mais synchronisé)|\n\n### **Principales méthodes**\n\n```java\nString s = \"  Java 21  \";\nSystem.out.println(s.trim()); // Supprime espaces : \"Java 21\"\nSystem.out.println(s.toUpperCase()); // \"JAVA 21\"\nSystem.out.println(s.replace(\" \", \"-\")); // \"-Java-21-\"\n```\n\n### **Text Blocks (`\"\"\"`) - Java 13**\n\nPermet d’écrire du texte multilignes plus lisible.\n\n```java\nString json = \"\"\"\n    {\n        \"name\": \"Java\",\n        \"version\": 21\n    }\n    \"\"\";\nSystem.out.println(json);\n```\n\n---\n\n## **4.4. API Math et `BigDecimal`**\n\n### **\uD83D\uDCCC Math API : Calculs avancés**\n\n```java\nSystem.out.println(Math.abs(-10));    // 10\nSystem.out.println(Math.pow(2, 3));   // 8.0\nSystem.out.println(Math.sqrt(16));    // 4.0\nSystem.out.println(Math.random());    // [0.0, 1.0[\n```\n\n### **\uD83D\uDCCC `BigDecimal` : précision pour les calculs financiers**\n\n\uD83D\uDCCC **`double` peut entraîner des erreurs d’arrondi !**\n\n```java\ndouble a = 0.1;\ndouble b = 0.2;\nSystem.out.println(a + b); // 0.30000000000000004 (erreur)\n\nBigDecimal x = new BigDecimal(\"0.1\");\nBigDecimal y = new BigDecimal(\"0.2\");\nSystem.out.println(x.add(y)); // 0.3 (précis)\n```\n\n|**Type**|**Précision**|**Mémoire**|**Utilisation**|\n|---|---|---|---|\n|`float`|32 bits|Faible|Calculs approximatifs|\n|`double`|64 bits|Moyenne|Calculs scientifiques|\n|`BigDecimal`|Illimitée|Plus lourd|Calculs précis (monnaie)|\n\n### **Opérations avec `BigDecimal`**\n\n```java\nBigDecimal valeur = new BigDecimal(\"10.50\");\nBigDecimal taxe = new BigDecimal(\"1.20\");\nBigDecimal total = valeur.multiply(taxe);\n\nSystem.out.println(total); // 12.60\n```\n\n---\n\n## **Résumé**\n\n✅ **API Date-Time (`LocalDate`, `LocalTime`, etc.)**  \n✅ **Gestion des intervalles avec `Period`, `Duration`, `Instant`**  \n✅ **Manipulation de texte avec `String`, `StringBuilder`, `Text Blocks`**  \n✅ **Math avancé (`Math.pow`, `Math.random`) et calculs précis avec `BigDecimal`**\n\n---\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c074a5cf-bcf9-464c-90cd-87b69b5095f6",
        "title": "Git Hook",
        "shortDescription": "",
        "description": "---\nid: 65c4da6e-82ad-454b-b55b-ff45a6462d19\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLes **[[Git]] Hooks** sont des scripts exécutables permettant d’automatiser certaines actions pendant le cycle de vie d'un dépôt [[Git]], comme avant ou après un commit, push, ou merge.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLes **Git Hooks** sont des scripts qui s'exécutent à des moments spécifiques dans le flux de travail de Git. Ils permettent d'ajouter des comportements personnalisés et d’automatiser des tâches comme des vérifications, des validations ou des notifications. Ces hooks sont configurés directement dans le répertoire `.git/hooks` du projet. Chaque hook est associé à un événement précis :\n\n1. **`pre-commit`** : Avant qu'un commit soit effectué. Utilisé pour des vérifications comme les tests unitaires ou le formatage du code.\n2. **`commit-msg`** : Après un commit mais avant la validation du message. Permet de valider ou modifier le message de commit.\n3. **`post-commit`** : Après un commit. Souvent utilisé pour envoyer des notifications ou effectuer des suivis.\n4. **`pre-push`** : Avant un push vers un dépôt distant. Permet de vérifier la qualité du code avant de le partager.\n5. **`post-merge`** : Après un merge. Souvent utilisé pour réorganiser l’espace de travail ou nettoyer l'environnement.\n6. **`pre-receive` et `update`** : Sur le serveur distant, valident les changements avant qu'ils ne soient reçus.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Automatisation** : Facilite l'automatisation de processus tels que les tests, le formatage de code, ou l'envoi de notifications.\n- **Validation** : Permet de valider ou modifier des actions avant qu’elles ne soient exécutées (commit, push).\n- **Personnalisation** : Offre une grande flexibilité pour personnaliser le flux de travail de chaque équipe ou projet.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Performance** : Trop de hooks ou des vérifications lourdes peuvent ralentir le workflow, notamment lors des commits fréquents.\n- **Complexité** : La gestion de hooks dans un projet peut ajouter de la complexité, surtout si chaque développeur a une configuration différente.\n- **Dépendance locale** : Les hooks sont locaux au dépôt, ce qui peut poser problème si l'équipe utilise des configurations différentes.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "329a8a5d-8878-414f-996c-fb91884b6abd",
        "title": "Git leaks",
        "shortDescription": "",
        "description": "---\nid: d24393e4-da90-46f9-98e7-8f2025603958\n---\n# Rapidement c'est quoi❓\n\nGit Leaks est un outil permettant de détecter les fuites d'informations sensibles (mots de passe, clés API, etc.) dans un dépôt [[Git]].\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nGit Leaks est un outil de sécurité qui analyse le contenu d'un dépôt [[Git]] à la recherche de patterns correspondant à des informations sensibles.  Il fonctionne en scannant l'historique du dépôt, incluant les commits passés et les fichiers supprimés.  L'objectif est d'identifier et de signaler la présence accidentelle de données confidentielles qui auraient pu être commises par erreur.  Ces informations sensibles peuvent inclure :\n\n* **Mots de passe:**  En clair ou hachés (même si hachés, certains algorithmes faibles peuvent être détectés).\n* **Clés API:**  Pour divers services cloud, bases de données, etc.\n* **Jetons d'authentification:**  Utilisés pour l'accès à des applications ou services.\n* **Numéros de cartes de crédit:**  Respectant les formats standards.\n* **Informations personnelles sensibles:**  Numéros de sécurité sociale, adresses, etc. (dépend des réglages et des patterns utilisés).\n\nGit Leaks peut être intégré comme un [[Git Hook]] (exécuté avant chaque commit) ou dans un [[pipeline CI/CD]] (ex: [[GitLab CI]], [[GitHub Actions]], [[Jenkins]]), permettant une détection proactive des fuites avant qu'elles ne soient publiques.  L'intégration permet une automatisation de la sécurité et une meilleure prévention des incidents.  Il existe différentes implémentations et configurations possibles, modifiant la sensibilité de la détection (faible, moyen, fort).\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Détection proactive:** Identifie les fuites avant leur publication publique.\n* **Intégration facile:**  Peut être intégré facilement dans les workflows existants via des hooks ou des [[pipelines CI/CD]].\n* **Automatisation:**  Réduit le risque d'erreur humaine et accélère le processus de sécurité.\n* **Couverture large:**  Peut détecter différents types d'informations sensibles.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Faux positifs possibles:**  Peut générer des faux positifs en fonction de la configuration et de la complexité du code.  Un ajustement fin des réglages est souvent nécessaire.\n* **Dépendance aux patterns:**  La détection repose sur des patterns prédéfinis, ce qui signifie qu'il peut manquer des types d'informations sensibles non couverts par ces patterns.\n* **Ne remplace pas une revue de code complète:**  Doit être considéré comme un outil complémentaire à une bonne pratique de revue de code.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e4cdf907-2f2b-4a47-ab7b-735192fb7394",
        "title": "Grafana",
        "shortDescription": "",
        "description": "---\nid: 73f08fc3-729a-40a2-8abd-96cbe6ca9970\n---\n# Rapidement c'est quoi❓\n\nGrafana est un outil open-source de visualisation et d'analyse de données. Il permet de créer des dashboards interactifs et personnalisables à partir de nombreuses sources de données différentes.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nGrafana est une plateforme d'analyse de données qui permet de visualiser et d'interroger des données provenant de diverses sources, telles que des [[Base de donnée]] ([[PostgreSQL]], [[MySQL]], [[MongoDB]], etc.), des métriques système ([[Prometheus]], [[Graphite]]), des logs ([[Elasticsearch]], [[Loki]]), des clouds ([[AWS]], [[Azure]], [[GCP]]) et bien d'autres.  Il offre une interface utilisateur intuitive pour créer des dashboards personnalisés avec des graphiques, des tableaux, des cartes et autres visualisations.  Ces dashboards peuvent être partagés et collaboratifs.  Grafana possède un système de plugins extensif permettant d'ajouter des fonctionnalités et de supporter de nouvelles sources de données.  L'utilisateur peut effectuer des requêtes directement sur les données, définir des alertes basées sur des seuils et intégrer des fonctionnalités d'exploration de données.  Au-delà de la visualisation, Grafana permet une analyse temporelle des données, indispensable pour le monitoring et l'investigation d'incidents.  Il offre également des fonctionnalités d'annotation pour enrichir les données avec des informations contextuelles.  Enfin, Grafana est disponible en version open-source et en version entreprise avec des fonctionnalités additionnelles.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Interface utilisateur intuitive et conviviale:** La création et la personnalisation de dashboards est relativement facile, même pour les utilisateurs non-experts.\n* **Support d'un large éventail de sources de données:** Grafana s'intègre avec de nombreux outils et technologies, ce qui en fait une solution polyvalente.\n* **Fonctionnalités avancées d'analyse et d'exploration:**  Au-delà de la simple visualisation, Grafana permet une analyse approfondie des données.\n* **Communauté active et support important:** La communauté open-source est vaste et active, assurant un bon support et une disponibilité de ressources.\n* **Extensible grâce aux plugins:**  L'ajout de nouvelles fonctionnalités et sources de données se fait facilement via les plugins.\n* **Open-source (avec une version entreprise):**  Offre un bon équilibre entre gratuité et fonctionnalités avancées.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité pour des configurations avancées:**  La personnalisation poussée et la gestion de sources de données complexes peuvent devenir difficiles.\n* **Performances potentiellement limitées pour des volumes de données très importants:**  Les performances peuvent être affectées par la taille et la complexité des dashboards et des requêtes.\n* **Courbe d'apprentissage pour maîtriser toutes les fonctionnalités:** Bien que l'interface soit intuitive, maîtriser toutes les fonctionnalités avancées demande du temps et de l'apprentissage.\n* **Dépendance aux plugins pour certaines sources de données:** L'intégration avec certaines sources de données peut nécessiter l'installation et la configuration de plugins spécifiques.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "447992ea-077d-4520-a2ce-324d10237189",
        "title": "Harbor",
        "shortDescription": "",
        "description": "---\nid: 98410515-bfb3-4709-982f-a9c8134b68d5\n---\n# Rapidement c'est quoi❓\n\nHarbor est un registre de conteneurs [[Open-source]], sécurisé et de niveau entreprise,  qui étend les fonctionnalités de base de [[Registry Docker]].  Il ajoute des fonctionnalités de gestion d'accès, de scan de vulnérabilités et de gestion de cycle de vie des images.\n\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nHarbor est une solution de registre de conteneurs qui s'appuie sur le registre Docker standard mais y ajoute des fonctionnalités cruciales pour les déploiements en production.  Il permet de stocker, gérer et sécuriser les images de conteneurs.  Plus précisément, il offre :\n\n* **Gestion d'accès robuste:**  Contrôle d'accès basé sur les rôles ([[Role Based Access Control (RBAC]]) pour une gestion fine des permissions sur les images, permettant de définir des politiques d'accès granulaires pour les différents utilisateurs et équipes.  L'intégration avec des systèmes d'authentification existants ([[LDAP]], [[Active Directory]]) est possible.\n\n* **Scan de vulnérabilités:** Intégration avec des outils de scan de vulnérabilités (comme [[Clair]]) pour analyser les images à la recherche de failles de sécurité connues avant leur déploiement.  Cela permet de détecter et de corriger les vulnérabilités potentielles dès la phase de développement.\n\n* **Gestion du cycle de vie des images:**  Harbor offre des fonctionnalités pour gérer le cycle de vie complet des images, de leur création à leur suppression.  Ceci inclut la gestion des versions, la promotion d'images entre différents environnements (développement, test, production), et la gestion des politiques de rétention.\n\n* **Réplication:**  Possibilité de répliquer les images de conteneurs vers d'autres registres Harbor, permettant la création de registres miroirs pour la haute disponibilité et la réduction de la latence.\n\n* **Audit:**  Suivi complet des actions effectuées sur le registre, fournissant un historique auditable pour des raisons de conformité et de sécurité.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Sécurité renforcée:**  Le contrôle d'accès fin et la fonctionnalité de scan de vulnérabilités contribuent grandement à la sécurité des images de conteneurs.\n* **Gestion complète du cycle de vie:**  Simplifie les opérations et améliore l'efficacité en centralisant la gestion des images.\n* **Open source et extensible:**  Permet une grande flexibilité et permet des intégrations personnalisées.\n* **Haute disponibilité et réplication:**  Assure la fiabilité et la disponibilité du registre.\n* **Interface utilisateur intuitive:**  Facilite la gestion et le suivi des images.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité de configuration:**  La configuration initiale peut être complexe pour les utilisateurs novices.\n* **Ressources nécessaires:**  Nécessite des ressources serveur pour fonctionner, ce qui peut être un inconvénient pour les petites infrastructures.\n* **Dépendances:**  Dépend de plusieurs composants et outils, ce qui peut compliquer la maintenance et le dépannage.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "15291a12-30f8-4a45-9154-edc382fca715",
        "title": "Htmx",
        "shortDescription": "",
        "description": "---\nid: 5d0f7309-8e45-4091-b0fe-c2d1f341b3a5\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nHTMX est une bibliothèque qui permet d'éviter d'écrire du [[JavaScript]] pour gérer les interactions sur une page web, en utilisant uniquement des attributs HTML pour gérer des requêtes [[HTTP]] dynamiques.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nHTMX simplifie l'interactivité web en permettant de définir des comportements de requêtes [[HTTP]] directement via des attributs `hx-` sur les balises HTML. Il permet de :\n\n- Effectuer des requêtes HTTP sans JavaScript (ex : `hx-get`, `hx-post`).\n- Traiter et manipuler les réponses avant et après leur insertion dans le [[DOM]].\n- Gérer des actions comme le rafraîchissement de parties spécifiques d'une page sans recharger la page entière.\n\nCela fonctionne sur n'importe quel serveur générant du HTML, comme ceux en [[Go]], [[Rust]], ou [[JTE]].\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Simplicité** : Remplace une grande partie de [[JavaScript]] pour des interactions simples avec des formulaires et des requêtes.\n- **Adapté aux petits projets** : Idéal pour les applications [[backend]] simples sans nécessiter de frameworks [[JavaScript]] lourds.\n- **Moins de [[JavaScript]] à maintenir** : La logique d'interaction est définie dans le [[HTML]], ce qui simplifie la gestion du code.\n- **Compatibilité avec n'importe quel backend** : Fonctionne avec n'importe quel serveur générant du [[HTML]].\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Limité pour des interactions complexes** : Dès qu'il y a des traitements complexes ou des manipulations de données avant l'envoi, HTMX devient difficile à utiliser.\n- **Dépendance au HTML** : Nécessite que les endpoints retournent du HTML, ce qui peut ne pas être adapté pour des applications plus modernes qui nécessitent du [[JSON]].\n- **Moins flexible que le [[JavaScript]] natif** : Certaines interactions complexes peuvent être plus facilement réalisées avec JavaScript plutôt qu'avec HTMX.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "b40bc9b4-b756-4136-9af1-c2a7fff4d923",
        "title": "Http 103 Early Hints",
        "shortDescription": "",
        "description": "---\nid: 5bae96ff-d0fa-4198-b12f-edab95488e95\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n[[HTTP]] 103 \"Early Hints\" est un code de statut HTTP qui permet d'indiquer au client, avant la réponse finale du serveur, quelles ressources précharger pour améliorer la vitesse de rendu de la page web.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe code HTTP 103 est envoyé par le serveur avant la réponse finale à une requête [[HTTP]]. Il informe le client des ressources à précharger (comme des fichiers [[CSS]], [[JavaScript]] ou des images). Cela permet au navigateur de commencer à charger ces ressources pendant que le serveur génère la réponse principale, réduisant ainsi le temps nécessaire pour afficher la page.\n\nLe processus fonctionne ainsi :\n\n1. Le client envoie une requête au serveur.\n2. Le serveur répond avec un code 103 et une liste de ressources à précharger.\n3. Le client commence à charger ces ressources immédiatement.\n4. Le serveur termine le traitement et envoie la page finale, qui peut être affichée plus rapidement puisque les ressources ont déjà été préchargées.\n\nCe mécanisme améliore le temps de chargement des pages, en particulier pour les sites avec beaucoup de ressources externes.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Amélioration du temps de chargement** : Réduit de manière significative le temps nécessaire pour afficher la page (environ 30% de gain).\n- **Simplicité de mise en œuvre** : Facile à configurer avec des serveurs comme [[Caddy]] et [[Apache]], en particulier avec HTTP/2.\n- **Expérience utilisateur améliorée** : Le contenu de la page se charge plus rapidement grâce au préchargement des ressources.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Support limité** : Ne fonctionne pas avec [[HTTP/1]] et n'est pas supporté par [[Nginx]].\n- **Gestion des ressources** : La gestion des ressources à précharger peut être délicate, il faut bien s'assurer qu'elles sont nécessaires et gérées correctement.\n- **Dépendance au serveur et au client** : Nécessite un serveur compatible et un client capable de gérer le code 103, ce qui limite son adoption immédiate.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "64dc974d-6ff7-4106-b3ef-ca7485f6ddec",
        "title": "Husky",
        "shortDescription": "",
        "description": "---\nid: fe07726f-b2ce-4806-bbe0-a77bc3cd9da7\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nHusky est un outil permettant d'ajouter et de gérer des [[Git Hook]] (scripts exécutés à des moments clés du cycle de vie d'un dépôt [[Git]], comme avant un commit) pour automatiser des tâches comme des tests ou des vérifications de code.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nHusky simplifie l'intégration des [[Git Hook]] dans un projet [[JavaScript]]. En l'installant dans un projet, il crée un répertoire `.husky` qui contient les scripts des hooks (comme `pre-commit`, `pre-push`). Ces hooks permettent d'automatiser des processus, tels que :\n\n- Lancer des tests avant de valider un commit (`pre-commit`).\n- Vérifier le format du code (`commit-msg`).\n- Bloquer un push si certaines conditions ne sont pas remplies (`pre-push`).\n\nHusky s'installe via npm et est facile à configurer avec des commandes simples. Il permet aussi de désactiver des hooks temporairement en ajoutant des arguments ou des variables d'environnement.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Automatisation facile** : Intégration simple des hooks Git dans les projets.\n- **Gestion des erreurs** : Permet d’empêcher des commits ou des pushs si des conditions ne sont pas remplies (tests échoués, mauvaise convention de commit, etc.).\n- **Souplesse** : Facile à activer ou désactiver via des variables d’environnement ou des arguments Git.\n- **Large compatibilité** : Fonctionne avec la plupart des projets [[Git]], quel que soit le framework ou l'outil utilisé.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Dépendance au projet** : Nécessite un environnement [[Node.js]] et l'installation via [[npm]] pour fonctionner.\n- **Peut ralentir le développement** : Les hooks mal configurés ou trop nombreux peuvent freiner le développement, surtout avec des vérifications de tests lourdes.\n- **Gestion des désactivations** : Bien que possible, la désactivation des hooks peut ne pas être triviale dans certains contextes (par exemple dans [[CI/CD]]).\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a28276a6-3156-4612-a0cf-64eb71fe9552",
        "title": "ImportMap (JS)",
        "shortDescription": "",
        "description": "---\nid: 302b5d4b-497b-48db-b249-9fa80b82c068\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nUn ImportMap en [[JavaScript]] est un objet [[JSON]] qui permet de simplifier et gérer les imports dans une application en créant des alias pour les modules. Cela facilite la gestion des dépendances en permettant de définir des chemins d'accès personnalisés pour les imports.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUn ImportMap est utilisé pour définir des correspondances entre les clés d'import (les noms des modules) et leurs chemins réels (URLs ou fichiers locaux). Cela permet de contrôler où un module est chargé, simplifiant ainsi la gestion des dépendances dans un projet.\n\nExemple : au lieu d'importer directement un fichier via un long chemin, vous pouvez définir un alias comme \"my-component\" dans l'ImportMap et l'utiliser ensuite dans les imports de vos modules.\n\n- **Déploiement [[Micros Frontends]]** : Changez dynamiquement les versions de vos composants sans modifier le code, en mettant à jour uniquement l'ImportMap.\n- **Revue de code** : Permet de rediriger facilement les imports vers des versions spécifiques pour tester des modifications en direct sans toucher au code source.\n\n```html\n<script type=\"importmap\">\n\t{\n\t\t\"imports\" : {\n\t\t\t\"my-component\": \"http://localhost:8080/src/my-component.js\"\n\t\t}\n\t}\n</script>\n\n<script type=\"module\">\n\timport { MyComponent } from \"my-component\"; // L'alias défini dans l'ImportMap\n</script>\n```\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Simplification des imports** : Les alias permettent d'éviter des chemins d'import longs et complexes.\n- **Flexibilité** : Possibilité de modifier les sources des modules sans toucher au code, utile pour le déploiement de micro frontends et le rollback.\n- **Amélioration de la revue de code** : Permet de tester et valider rapidement des modifications dans des environnements sans modifier le code source.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Compatibilité limitée** : L'usage des ImportMaps est encore relativement nouveau et n'est pas pris en charge par tous les navigateurs (nécessite des fonctionnalités modernes du navigateur).\n- **Gestion des versions** : Lors de l'utilisation avec des systèmes complexes, le suivi et la mise à jour des versions des modules peuvent devenir difficiles si l'ImportMap n'est pas bien géré.\n- **Pas de support pour les outils de bundling** : L'ImportMap fonctionne côté client mais ne remplace pas les outils de bundling comme [[Webpack]] pour une gestion avancée des modules.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "56274708-5613-4cbd-9d09-78bd95f972b7",
        "title": "Incremental Static Regeneration (ISR)",
        "shortDescription": "",
        "description": "---\nid: 29cf6b6a-38cb-4f64-9238-309f5dfb2bed\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nIncremental Static Regeneration (ISR) est une amélioration du processus de génération statique des pages ([[Server Side Generation (SSG)]]), permettant de mettre à jour les pages statiques déjà générées sans nécessiter une reconstruction complète du site. ISR permet de régénérer des pages statiques de manière incrémentielle à chaque requête, tout en préservant les performances.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nISR permet de générer des pages statiques de manière classique, mais avec la possibilité de régénérer et mettre à jour ces pages à la demande (en fonction du temps ou de l'action de l'utilisateur) sans recompiler l'ensemble du site. Cela permet une mise à jour progressive du contenu sans impact sur la performance globale.\n\nLe processus fonctionne ainsi :\n\n1. Lorsqu'une page est demandée, elle est servie statiquement si elle a déjà été générée.\n2. Si la page doit être mise à jour, le serveur la régénère en arrière-plan tout en servant l'ancienne version.\n3. Une fois la régénération terminée, la nouvelle version est disponible pour les requêtes suivantes.\n\nCela est utile dans les cas où les pages doivent être régulièrement mises à jour mais sans sacrifier les avantages du contenu statique.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Performance rapide** : Le contenu statique est servi très rapidement sans travail côté serveur.\n- **SEO optimisé** : Le contenu est indexé par les moteurs de recherche comme du contenu statique, ce qui est idéal pour le référencement.\n- **Mise à jour incrémentielle** : Permet de mettre à jour des pages spécifiques sans recompilation complète du site.\n- **Scalabilité** : Idéal pour des sites avec beaucoup de pages ou du contenu qui change régulièrement.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Temps de compilation** : Le processus de génération initiale des pages peut être long, surtout pour les grands sites.\n- **Non adapté au contenu dynamique** : Pas efficace pour les pages qui changent fréquemment ou qui nécessitent une interaction en temps réel.\n- **Complexité de gestion des mises à jour** : Suivre quelles pages doivent être régénérées et quand peut devenir difficile à gérer à grande échelle.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "bedba0c6-f509-4e04-b2f4-feb4b460971d",
        "title": "Interface fonctionnelle",
        "shortDescription": "",
        "description": "---\nid: 1dc25831-3209-4d96-aa65-41a3b48815c0\n---\n## Rapidement, c'est quoi ? ❓\n\nUne interface fonctionnelle en [[Java]] est une interface qui ne possède qu'une seule méthode abstraite.  Elle sert principalement à créer des expressions lambda et des références à des méthodes.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nEn [[Java]], une interface est un type qui définit un contrat pour les classes qui l'implémentent.  Une interface fonctionnelle simplifie ce contrat en exigeant la définition d'une seule méthode.  Cela permet d'utiliser des expressions lambda (une forme concise d'écrire des objets implémentant une interface fonctionnelle) et des références de méthodes (une manière compacte de passer une méthode existante comme argument).  L'annotation `@FunctionalInterface` est utilisée pour indiquer qu'une interface est conçue comme une interface fonctionnelle.  Si une interface annotée avec `@FunctionalInterface` définit plus d'une méthode abstraite, une erreur de compilation se produira.  Cependant, elle peut contenir des méthodes de défaut (avec une implémentation par défaut), des méthodes statiques, et des méthodes privées.\n\n**Exemple:**\n\n```java\n@FunctionalInterface\ninterface Print {\n    void execute(String label);\n}\n\nclass UseCase {\n    Print print;\n\n    void printAll(List<String> labels) {\n        labels.forEach(label -> print.execute(label)); // Utilisation d'une expression lambda\n    }\n\n    public static void main(String[] args) {\n        UseCase useCase = new UseCase();\n        useCase.print = label -> System.out.println(\"Label: \" + label); // affectation d'une lambda expression à print\n\n        List<String> labels = List.of(\"Label 1\", \"Label 2\", \"Label 3\");\n        useCase.printAll(labels);\n    }\n}\n```\n\nDans cet exemple, `Print` est une interface fonctionnelle avec une seule méthode abstraite `execute`.  La méthode `printAll` utilise une expression lambda `label -> System.out.println(\"Label: \" + label)` pour fournir une implémentation de `Print` directement dans l'appel de `forEach`.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Concision du code:** Les expressions lambda rendent le code plus concis et plus lisible que les classes anonymes traditionnelles.\n* **Fonctionnalité expressive:**  Permet d'exprimer des concepts fonctionnels (comme le passage de fonctions comme arguments) de manière élégante et naturelle en [[Java]].\n* **Amélioration de la lisibilité:** Le code utilisant les interfaces fonctionnelles est généralement plus facile à lire et à comprendre.\n* **Interopérabilité:**  Facilite l'utilisation de bibliothèques fonctionnelles et de concepts fonctionnels dans les applications [[Java]].\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité potentielle pour les débutants:**  La compréhension des concepts fonctionnels peut prendre du temps pour les programmeurs habitués à la programmation impérative.\n* **Débogage:** Le débogage des expressions lambda peut être légèrement plus complexe qu'avec des méthodes classiques.  Le nom de la méthode étant implicite, l’identification de la source d’un bug peut prendre plus de temps.\n* **Surutilisation potentielle:** Une surutilisation des interfaces fonctionnelles peut rendre le code moins lisible si les expressions lambda deviennent trop complexes ou si l'intention du code n'est pas claire.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "be6a1edb-d8a6-44c7-a730-c2b2b95faaa2",
        "title": "Certification Java 17 - Internationalisation et Localisation",
        "shortDescription": "",
        "description": "---\nid: 2726c3d7-2090-4f23-99f6-b0b1ea5a3ff1\n---\nL’**internationalisation (i18n)** et la **localisation (l10n)** permettent d’adapter une application Java à différentes langues et régions.\n\n## **13.1. `Locale` : Définition de la langue et du pays**\n\n### **1. Création d’un `Locale`**\n\n```java\nimport java.util.Locale;\n\npublic class Exemple {\n    public static void main(String[] args) {\n        Locale fr = new Locale(\"fr\", \"FR\"); // Français (France)\n        Locale us = new Locale(\"en\", \"US\"); // Anglais (États-Unis)\n\n        System.out.println(fr.getDisplayLanguage()); // Français\n        System.out.println(us.getDisplayCountry());  // United States\n    }\n}\n```\n\n\uD83D\uDCCC **`Locale(language, country)` : définit une langue et un pays.**\n\n---\n\n### **2. `Locale.getDefault()` : Détecter la langue du système**\n\n```java\nLocale localeParDefaut = Locale.getDefault();\nSystem.out.println(localeParDefaut); // Ex : fr_FR ou en_US\n```\n\n\uD83D\uDCCC **On peut aussi changer la locale par défaut :**\n\n```java\nLocale.setDefault(new Locale(\"es\", \"ES\")); // Espagnol (Espagne)\n```\n\n---\n\n## **13.2. `ResourceBundle` : Chargement de textes multilingues**\n\n\uD83D\uDCCC **Les fichiers de ressources (`.properties`) permettent de stocker les traductions.**\n\n### **1. Création des fichiers `messages.properties`**\n\n\uD83D\uDCC2 **Structure du projet :**\n\n```\n/src\n  /messages_fr.properties\n  /messages_en.properties\n```\n\n\uD83D\uDCC4 **messages_fr.properties**\n\n```\nsalutation=Bonjour !\n```\n\n\uD83D\uDCC4 **messages_en.properties**\n\n```\nsalutation=Hello!\n```\n\n### **2. Chargement des ressources avec `ResourceBundle`**\n\n```java\nimport java.util.*;\n\npublic class Exemple {\n    public static void main(String[] args) {\n        Locale locale = new Locale(\"fr\", \"FR\"); // Changez en \"en\", \"US\" pour tester\n        ResourceBundle bundle = ResourceBundle.getBundle(\"messages\", locale);\n\n        System.out.println(bundle.getString(\"salutation\")); // Affiche \"Bonjour !\" ou \"Hello!\"\n    }\n}\n```\n\n\uD83D\uDCCC **Le fichier correspondant à la `Locale` est automatiquement sélectionné.**\n\n---\n\n## **13.3. Formatage des Dates, Nombres et Devises**\n\n### **1. `NumberFormat` : Formatage des nombres et devises**\n\n```java\nimport java.text.NumberFormat;\nimport java.util.Locale;\n\npublic class Exemple {\n    public static void main(String[] args) {\n        double montant = 1234.56;\n\n        NumberFormat formatFr = NumberFormat.getCurrencyInstance(Locale.FRANCE);\n        NumberFormat formatUs = NumberFormat.getCurrencyInstance(Locale.US);\n\n        System.out.println(formatFr.format(montant)); // 1 234,56 €\n        System.out.println(formatUs.format(montant)); // $1,234.56\n    }\n}\n```\n\n\uD83D\uDCCC **`getCurrencyInstance(Locale)` formate selon la devise locale.**\n\n---\n\n### **2. `DateTimeFormatter` : Formatage des dates**\n\n```java\nimport java.time.LocalDate;\nimport java.time.format.DateTimeFormatter;\nimport java.util.Locale;\n\npublic class Exemple {\n    public static void main(String[] args) {\n        LocalDate date = LocalDate.now();\n\n        DateTimeFormatter formatterFr = DateTimeFormatter.ofPattern(\"EEEE dd MMMM yyyy\", Locale.FRANCE);\n        DateTimeFormatter formatterUs = DateTimeFormatter.ofPattern(\"EEEE, MMMM dd, yyyy\", Locale.US);\n\n        System.out.println(date.format(formatterFr)); // Ex : mercredi 06 mars 2025\n        System.out.println(date.format(formatterUs)); // Ex : Wednesday, March 06, 2025\n    }\n}\n```\n\n\uD83D\uDCCC **`ofPattern(\"EEEE dd MMMM yyyy\", Locale)` formate la date selon la langue.**\n\n---\n\n## **Résumé**\n\n✅ **`Locale` : Définit la langue et le pays (`Locale(\"fr\", \"FR\")`).**  \n✅ **`ResourceBundle` : Charge des fichiers `.properties` pour les traductions.**  \n✅ **`NumberFormat` : Formate les nombres et devises selon la locale.**  \n✅ **`DateTimeFormatter` : Affiche les dates dans le format localisé.**",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a6594301-4ed1-451d-b843-a3e8c5e95706",
        "title": "Jpa Specification",
        "shortDescription": "",
        "description": "---\nid: ec614572-79e3-4b20-bd55-75d790f3a468\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLes **JPA Specifications** permettent de créer des requêtes dynamiques en utilisant l'API **[[Criteria]]** de [[Spring Data ]]. Elles sont utiles pour filtrer ou rechercher des entités en fonction de critères variables et complexes sans avoir à écrire des requêtes [[SQL]] statiques.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLes JPA Specifications sont des interfaces permettant de définir des critères de recherche dynamiques avec **[[Spring Data JPA]]**. Elles utilisent l'API **[[Criteria]]** pour créer des requêtes complexes, notamment des filtres dynamiques basés sur des conditions `WHERE`. Les critères sont représentés par des **Predicates**, qui combinent des conditions logiques et des expressions de filtrage.\n\nUne Specification est construite à partir d'un `Predicate`, qui est une condition logique sur les données, comme un test d'égalité, de comparaison ou une recherche de texte. Vous pouvez combiner plusieurs Specifications avec des méthodes comme `and()`, `or()`, et `not()` pour créer des requêtes complexes.\n\nExemple de Specification :\n\n```java\npublic static Specification<User> firstNameLike(String firstName) {\n    return (root, criteriaQuery, criteriaBuilder) -> criteriaBuilder.like(root.get(\"firstName\"), \"%\" + firstName + \"%\");\n}\n```\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Flexibilité** : Créer des requêtes dynamiques et personnalisées en fonction des besoins de l'utilisateur.\n- **Réutilisabilité** : Les Specifications peuvent être combinées et réutilisées dans différentes parties du projet.\n- **Lisibilité** : Permet de garder un code propre et lisible en évitant des requêtes [[SQL]] complexes intégrées directement dans le code.\n- **Intégration avec [[Spring Data JPA]]** : Facile à utiliser avec des repositories Spring en étendant `JpaSpecificationExecutor`.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité des requêtes** : Lorsque les critères deviennent trop complexes, la lecture et la compréhension des Specifications peuvent devenir difficiles.\n- **Performance** : Les requêtes générées peuvent être lentes pour des bases de données volumineuses, nécessitant une surveillance attentive de la performance.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Base de donnée SQL]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "08fad616-b3cf-4f10-88ee-af456f64777e",
        "title": "Kibana",
        "shortDescription": "",
        "description": "---\nid: d9182905-f3b8-4196-9a7a-a168a04da247\n---\n# Rapidement c'est quoi❓\n\nKibana est une plateforme d'analyse et de visualisation de données open-source, principalement utilisée pour explorer et interagir avec des données indexées par [[Elasticsearch]].  Elle permet de créer des tableaux de bord, des graphiques et des visualisations interactives.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nKibana est une application web qui se connecte à un cluster [[Elasticsearch]].  Elle utilise les données indexées dans [[Elasticsearch]] pour générer des visualisations personnalisées.  Elle offre un large éventail de fonctionnalités, notamment :\n\n* **Visualisation de données:** Création de différents types de graphiques (barres, lignes, camemberts, cartes, etc.), de tableaux et d'autres représentations visuelles des données.  Ces visualisations peuvent être interactives, permettant aux utilisateurs de filtrer, d'explorer et d'analyser les données de manière dynamique.\n* **Exploration de données:**  Kibana permet une exploration ad-hoc des données via une interface intuitive de recherche et de filtrage.  L'utilisateur peut poser des questions aux données et obtenir des réponses instantanément grâce à des requêtes [[Elasticsearch]].\n* **Création de tableaux de bord:**  Agrégation de plusieurs visualisations en un seul tableau de bord personnalisable, offrant une vue d'ensemble des données importantes.  Ces tableaux de bord peuvent être partagés avec d'autres utilisateurs.\n* **Monitoring:**  Surveillance des performances d'[[Elasticsearch]] et des applications qui s'y connectent.\n* **Alerting:**  Mise en place de notifications basées sur des conditions spécifiques définies sur les données.\n* **Machine Learning:**  Intégration avec les capacités de machine learning d'[[Elasticsearch]] pour la détection d'anomalies et la prédiction.\n* **Gestion des utilisateurs et des rôles:**  Contrôle d'accès aux données et aux fonctionnalités de Kibana.\n\nKibana est conçu pour être flexible et extensible, permettant aux utilisateurs de créer des visualisations personnalisées et d'intégrer des données provenant de différentes sources.  Son interface utilisateur est intuitive et conviviale, facilitant l'analyse de données même pour des utilisateurs sans expertise technique approfondie.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Interface utilisateur intuitive et conviviale:**  Facile à apprendre et à utiliser, même pour les utilisateurs moins expérimentés.\n* **Large variété de visualisations:**  Offre un large choix de graphiques et de tableaux pour représenter les données de manière efficace.\n* **Flexibilité et extensibilité:**  Permet de créer des visualisations personnalisées et de s'intégrer à d'autres systèmes.\n* **[[Open-source]]:**  Gratuit et accessible à tous.\n* **Intégration avec [[Elasticsearch]]:**  Synergie parfaite avec [[Elasticsearch]] pour une exploration et une visualisation des données optimisées.\n* **Fonctionnalités avancées:**  Offre des fonctionnalités puissantes comme l'alerte, le monitoring et le machine learning.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Performances pour de très gros volumes de données:**  Peut devenir lent avec des ensembles de données extrêmement volumineux.  Une optimisation de l'indexation et de la requête Elasticsearch est alors nécessaire.\n* **Courbe d'apprentissage pour les fonctionnalités avancées:**  Certaines fonctionnalités plus techniques (comme le scripting ou les requêtes complexes) peuvent nécessiter une expertise plus poussée.\n* **Dépendance à [[Elasticsearch]]:**  Nécessite un cluster [[Elasticsearch]] fonctionnel pour fonctionner.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "5ffac79c-2a16-420e-a848-17e8e04395ba",
        "title": "Logstash",
        "shortDescription": "",
        "description": "---\nid: 6dd4b62f-dfea-48d8-bc6d-31eb62dd914d\n---\n# Rapidement c'est quoi❓\n\nLogstash est un outil open source de traitement de données en temps réel. Il collecte, traite et expédie des données provenant de diverses sources.  On parle d'[[ETL]] (Extraction, Transformation, Loading).\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLogstash est une application écrite en [[Ruby]], conçue pour collecter des données de multiples sources (logs, bases de données, applications, etc.), les transformer selon des règles définies par l'utilisateur (filtrage, enrichissement, agrégation, etc.) et les envoyer vers des destinations variées (bases de données, systèmes de stockage cloud, systèmes de visualisation de données, etc.).  Il fonctionne comme un pipeline modulaire, où chaque étape est définie par un plugin.  Ces plugins permettent une grande flexibilité et une intégration avec un vaste écosystème d'outils.  \n\nLe processus se décompose en trois phases :\n\n* **Extraction (Input):**  Logstash récupère les données depuis les sources définies.  Les plugins d'entrée sont nombreux et permettent de se connecter à des sources variées (filesystems, réseaux, bases de données, APIs, etc.).\n\n* **Transformation (Filter):**  Logstash manipule les données.  Les plugins de filtres permettent de réaliser des opérations telles que le parsing de logs, la modification de champs, l'ajout de nouveaux champs basés sur des calculs, la suppression de données sensibles, etc.  Ces transformations sont définies via des configurations en langage [[JSON]].\n\n* **Chargement (Output):**  Logstash envoie les données transformées vers les destinations spécifiées.  Les plugins de sortie permettent d'envoyer les données vers [[Elasticsearch]], des [[Base de donnée]], des filesystems, des messageries ([[Apache Kafka]], [[RabbitMQ]]), etc.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Flexibilité et extensibilité:** Grâce à son architecture modulaire basée sur les plugins, Logstash s'adapte facilement à de nombreux cas d'utilisation et s'intègre à une large variété d'outils.\n* **Open source:**  Gratuit et accessible à tous, avec une large communauté contribuant à son développement et à son support.\n* **Traitement en temps réel:**  Permet de traiter les données au fur et à mesure de leur arrivée, ce qui est crucial pour certaines applications.\n* **Configuration déclarative:**  La configuration se fait via des fichiers JSON, facilitant la gestion et le partage des configurations.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La configuration peut devenir complexe pour des pipelines sophistiqués, nécessitant une bonne compréhension de son fonctionnement et des plugins utilisés.\n* **Performances:**  Pour des volumes de données très importants, les performances de Logstash peuvent être un point de blocage, nécessitant l'optimisation de la configuration et potentiellement l'utilisation de solutions plus performantes.\n* **Dépendance à Ruby:**  Bien que performant, [[Ruby]] peut être un frein pour certains développeurs.\n* **Maintenance et mises à jour:**  Comme tout logiciel, Logstash nécessite une maintenance régulière et la prise en compte des mises à jour de sécurité.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e7d73c5a-a571-452f-af78-02a88e191259",
        "title": "Micrometer",
        "shortDescription": "",
        "description": "---\nid: cab051d2-e62d-413b-acab-5c1c7aefa9de\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**Micrometer** est une bibliothèque [[Java]] qui permet de collecter et exporter des métriques de performance d'applications vers différents systèmes de monitoring tels que [[Prometheus]], [[Graphite]], [[Datadog]], et [[InfluxDB]]. Elle est souvent utilisée avec [[Spring Boot]].\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nMicrometer fournit une API unifiée pour intégrer des métriques dans vos applications [[Java]]. Elle supporte plusieurs types de métriques, telles que les compteurs, jauges, histogrammes et timers. Ces métriques peuvent être envoyées vers des systèmes de monitoring via des `exporters`.\n\n**Types de métriques :**\n\n- **Compteurs** : Compte des événements (ex : nombre de requêtes HTTP).\n- **Jauges** : Mesure un état variable (ex : taille d’un cache).\n- **Histogrammes** : Collecte des données statistiques (ex : latence des requêtes).\n- **Timers** : Mesure la durée d’un événement (ex : temps de réponse d’une requête HTTP).\n\n**Tags** : Vous pouvez ajouter des étiquettes (tags) aux métriques pour les différencier par exemple par type de requêtes ou région géographique.\n\nAvec [[Spring Boot]], Micrometer s'intègre facilement via le module **[[Spring Boot Actuator]]**, et expose les métriques via des endpoints comme `/actuator/prometheus`.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Intégration facile avec [[Spring Boot]]** : Micrometer fonctionne bien avec [[Spring Boot]], surtout avec [[Spring Boot Actuator]].\n- **Support multiple pour les systèmes de monitoring** : Vous pouvez exporter les métriques vers de nombreux backends comme [[Prometheus]], [[Datadog]], [[Graphite]], etc.\n- **Flexibilité avec les tags** : Les tags permettent de filtrer et analyser les métriques selon plusieurs critères (ex : type de requêtes, zones géographiques).\n- **Types de métriques variés** : Compteurs, jauges, histogrammes et timers couvrent tous les besoins courants de collecte de métriques.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité avec des configurations avancées** : Pour des cas complexes de métriques personnalisées ou des systèmes de monitoring moins communs, la configuration peut devenir délicate.\n- **Dépendance à des backends externes** : La collecte et l'exportation des métriques nécessitent une configuration des systèmes de monitoring externes.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "fefe5553-dc94-4de2-9dd2-0288dca655c3",
        "title": "Mobile First",
        "shortDescription": "",
        "description": "---\nid: d7eada46-6aee-42e1-8e29-8aaf4ff9526f\n---\n# Rapidement c'est quoi❓\n\nUne méthode de conception web consistant à prioriser l'expérience utilisateur sur les petits écrans (mobiles) avant de l'adapter aux plus grands (tablettes, ordinateurs).\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe principe \"mobile-first\" est une approche de développement web qui place l'expérience utilisateur mobile au cœur du processus de conception.  Au lieu de concevoir d'abord pour les ordinateurs de bureau et ensuite de réduire l'interface pour les mobiles (approche \"desktop-first\"), le mobile-first commence par créer une version optimisée pour les petits écrans.  Cette version inclut uniquement les éléments essentiels et les fonctionnalités clés.  Ensuite, on ajoute progressivement des fonctionnalités et du contenu pour les écrans plus grands (tablettes et ordinateurs), en utilisant des requêtes [[CSS]] media pour adapter l'affichage.  L'objectif est de garantir que le site web fonctionne correctement et offre une bonne expérience utilisateur, même sur des appareils avec des ressources limitées (bande passante, puissance de calcul). Cela implique de prioriser la vitesse de chargement, la lisibilité et la simplicité de navigation sur mobile.  L'adaptation pour les écrans plus grands se fait ensuite par ajout de contenu, d'éléments visuels, et d'une meilleure organisation de l'information, plutôt que par une simple mise à l'échelle.  Cette approche améliore l'accessibilité et l'expérience utilisateur sur tous les appareils.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Expérience utilisateur optimisée sur mobile:**  Priorise l'expérience sur les appareils les plus utilisés aujourd'hui.\n* **Vitesse de chargement plus rapide:**  Version allégée initialement conçue pour les appareils avec une bande passante limitée.\n* **Meilleure accessibilité:**  Conception plus simple et plus intuitive, facilitant la navigation pour tous les utilisateurs.\n* **Maintenance simplifiée:**  Un code plus propre et plus organisé, facilitant les mises à jour et les corrections de bogues.\n* **Adaptabilité et flexibilité:**  La conception répond naturellement aux différentes tailles d'écran.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Potentiellement plus de travail initial:** Bien que simplifiant la maintenance à long terme, la conception initiale peut nécessiter une réflexion plus approfondie pour adapter le contenu aux différents niveaux d'affichage.\n* **Nécessite une bonne maîtrise du [[CSS]]:** L'utilisation efficace des requêtes media est indispensable pour une bonne adaptation.\n* **Peut être moins intuitif pour les développeurs habitués à la méthode \"desktop-first\".**  Un changement de paradigme est nécessaire.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "27b397ff-ecad-4089-bd0d-8b2ff8680213",
        "title": "Molécule",
        "shortDescription": "",
        "description": "---\nid: bf25037e-5dd1-4369-a7aa-d581e9371615\n---\n# Rapidement c'est quoi❓\n\nMolécule est un outil [[Python]] qui utilise [[Ansible]] et [[Testinfra]] pour tester l'infrastructure en provisionnant des environnements avec [[Docker]].  Il permet de réaliser des [[Test d'intégration]] plus rapidement qu'avec des [[VM]].\n\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nMolécule est un framework de [[Test d'infrastructure]] basé sur [[Python]]. Il permet de définir, provisionner et tester des environnements d'infrastructure de manière automatisée. Il s'appuie sur [[Ansible]] pour la configuration et le déploiement de l'infrastructure, et sur [[Testinfra]] pour la validation et la vérification de l'état de l'infrastructure après déploiement.  L'utilisation de [[Docker]] permet de créer et de détruire rapidement des environnements de test, accélérant ainsi le cycle de développement et de test.  Le principe est de définir la configuration de l'infrastructure souhaité dans un fichier de configuration (généralement YAML), puis Molécule se charge de la création de l'environnement [[Docker]], du déploiement via [[Ansible]] et enfin de l'exécution des tests [[Testinfra]] pour vérifier que l'infrastructure déployée correspond à la configuration attendue.  Ce processus permet de tester l'infrastructure de manière reproductible et fiable.\n\nCet outil rend possible le [[Test Driven Developpement (TDD)]] sur de l'[[Infra as Code (IaC]].\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Rapidité:** L'utilisation de [[Docker]] permet un provisionnement et un nettoyage rapides des environnements de test, comparativement à l'utilisation de machines virtuelles.\n* **Reproductibilité:** Les tests sont exécutés dans un environnement contrôlé et reproductible, garantissant la cohérence des résultats.\n* **Intégration avec [[Ansible]] et [[Testinfra]]:** Molécule tire parti de la puissance d'[[Ansible]] pour le déploiement et de [[Testinfra]] pour la vérification de l'état de l'infrastructure, créant une synergie efficace.\n* **Automatisation:** L'ensemble du processus de test est automatisé, réduisant le temps et l'effort manuel nécessaires.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Différences entre conteneurs et machines virtuelles:** Les conteneurs [[Docker]] ne reproduisent pas parfaitement l'environnement d'une machine virtuelle.  Certaines particularités de fonctionnement peuvent entraîner des différences de comportement et des échecs de test, nécessitant une adaptation des tests et des configurations.\n* **Mocking des services externes:**  Le mocking de services externes peut être complexe et nécessiter des solutions spécifiques, selon la dépendance du système testé.\n* **Courbe d'apprentissage:**  La maîtrise d'[[Ansible]] et de [[Testinfra]] est nécessaire pour utiliser efficacement Molécule.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]][[MOC_Testing]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "ca07ae2e-28ac-4040-b12c-3318f0c63df4",
        "title": "Nitro",
        "shortDescription": "",
        "description": "---\nid: 87c37a5c-546e-4b54-a1f1-db9d7e9b3d00\n---\n# Rapidement c'est quoi❓\n\nNitro est le moteur [[HTTP]] de [[Nuxt.js]] 3, permettant un rendu [[Server Side Rendering (SSR)]] performant et la [[Server Side Generation (SSG)]] de sites web.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nNitro est le runtime de [[Nuxt.js]] 3, un framework [[Vue.js]].  Il remplace le précédent système basé sur [[koa.js]] et offre des améliorations significatives en termes de performance et de flexibilité.  Son cœur de métier est la gestion des requêtes [[HTTP]], permettant à Nuxt de servir des pages web dynamiques ou pré-rendues.  Il gère :\n\n* **[[Server Side Rendering (SSR)]]:**  Le code [[Vue.js]] est exécuté sur le serveur, et le [[HTML]] résultant est envoyé au navigateur.  Cela permet un meilleur référencement [[SEO]] et une expérience utilisateur plus rapide dans certains cas.\n* **[[Server Side Generation (SSG)]]:**  Nitro permet de générer des pages HTML statiques au moment du build, optimisant le temps de chargement et la performance.  Idéal pour des sites web à contenu statique ou peu variable.\n* **API routes:**  Permet de créer facilement des API [[RESTful]].\n* **Intégration avec des services [[Function as a Service (FaaS)]]:**  Nitro peut déployer vos applications sur des plateformes serverless comme [[AWS Lambda]], [[Netlify Functions]], etc.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Performance:** Nitro est significativement plus rapide que le moteur [[HTTP]] de Nuxt 2.\n* **Flexibilité:**  Il offre une grande variété d'options de déploiement et de configuration.\n* **Intégration Serverless:** Simplifie le déploiement sur des plateformes cloud sans serveur.\n* **Maintenance et Amélioration:** Étant le moteur de la nouvelle version de Nuxt, il bénéficie d'une maintenance active et d'améliorations régulières.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:**  Pour les développeurs habitués à Nuxt 2, l'adaptation à Nitro peut nécessiter un certain temps d'apprentissage.\n* **Complexité:**  La configuration de Nitro peut être complexe pour des applications très vastes et complexes.\n* **Dépendances:**  La bonne performance de Nitro dépend fortement de la configuration et des optimisations mises en place.  Une mauvaise configuration peut dégrader les performances.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]][[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c0d70da5-2d60-4fd4-8d80-22d7bbc471db",
        "title": "Open Feature",
        "shortDescription": "",
        "description": "---\nid: ac13e1c4-96e2-4632-b280-c159bdad84c8\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nOpenFeature est un framework qui permet de gérer de manière centralisée l’utilisation de [[Feature Flag]] dans une application. Il offre une abstraction qui permet de définir des règles pour activer ou désactiver des fonctionnalités en fonction de critères définis.\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nOpenFeature permet d’intégrer des [[Feature Flag]] dans des applications pour activer ou désactiver certaines fonctionnalités à la volée. Cela permet de tester des nouvelles fonctionnalités sans modifier le code ou déployer une nouvelle version.\n\n- Il supporte l'utilisation de _providers_, tels que [[Flagd]], pour gérer les états des [[Feature Flag]].\n- Chaque [[Feature Flag]] peut avoir plusieurs variantes (par exemple, activer une fonctionnalité à 20% des utilisateurs).\n- Avec un provider comme [[Flagd]], la configuration des [[Feature Flag]] peut être définie dans un fichier [[JSON]].\n- L'intégration avec des frameworks comme [[Spring Boot]] permet de conditionner des comportements selon l’état d’un [[Feature Flag]] dans le code, offrant ainsi un contrôle granulaire sur les fonctionnalités activées.\n\nUn exemple d’utilisation est de configurer un flag pour activer un message de bienvenue uniquement pour certains utilisateurs.\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Abstraction simple** : OpenFeature fournit une abstraction standard pour gérer les [[Feature Flag]], ce qui permet de les intégrer facilement dans différentes applications sans dépendre d’une implémentation spécifique.\n- **Flexibilité** : Il permet de tester des fonctionnalités en production sans risque, en activant des flags pour une fraction des utilisateurs.\n- **Intégration fluide avec [[Spring Boot]]** : OpenFeature peut être facilement intégré avec des frameworks populaires comme [[Spring Boot]] pour gérer dynamiquement l’activation des fonctionnalités via des flags.\n- **Support des providers multiples** : OpenFeature peut se connecter à différents _providers_ comme [[Flagd]], offrant ainsi un large éventail d’options pour gérer les [[Feature Flag]].\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Nécessité d'un provider** : Pour une utilisation complète, il est nécessaire de configurer un provider externe (comme [[Flagd]]), ce qui peut être un surcoût de gestion pour de petites applications.\n- **Configuration supplémentaire** : La configuration des [[Feature Flag]] et de leur provider nécessite une gestion supplémentaire, notamment au niveau de l’environnement (ex. fichiers JSON et lancement de services).\n- **Complexité pour les petites applications** : Pour des projets simples, l’intégration d’OpenFeature avec un provider externe peut ajouter une complexité inutile par rapport à une gestion manuelle des [[Feature Flag]].\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "b32b473f-a83e-4228-b69a-812ac8669528",
        "title": "Open Service Gateway initiative (OSGi)",
        "shortDescription": "",
        "description": "---\nid: 0fa947ed-276d-411b-9b71-cc251c56f62d\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**OSGi (Open Service Gateway Initiative)** est un framework [[Java]] qui permet de créer des applications modulaires, où des composants appelés **bundles** peuvent être installés, mis à jour ou supprimés dynamiquement sans redémarrer l'application.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nOSGi facilite la création d'applications modulaires en permettant aux composants de s'ajouter, se mettre à jour ou se retirer à la volée. Les applications sont constituées de **bundles** (fichiers JAR) qui exposent des **services**. Ces services peuvent être consommés par d'autres bundles de manière dynamique grâce à un système de gestion des dépendances et de la découverte de services.\n\n**Principaux concepts :**\n\n- **Bundle** : Un module autonome contenant des services, souvent sous forme de JAR.\n- **Service** : Fonctionnalité offerte par un bundle, accessible à d'autres bundles.\n- **Framework OSGi** : Gère l'installation, la mise à jour, la suppression et la résolution des dépendances des bundles.\n\nLes bundles peuvent interagir dynamiquement via des **références de services**, permettant une communication fluide sans dépendances statiques.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Modularité** : Permet de structurer des applications complexes en modules autonomes.\n- **Dynamisme** : Ajout, mise à jour ou retrait de modules sans interruption du service global.\n- **Flexibilité** : La communication entre les bundles via des services est dynamique et découplée.\n- **Gestion des dépendances** : OSGi résout automatiquement les dépendances entre les modules.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité** : La configuration et gestion de l'OSGi peut devenir complexe, surtout dans les applications très grandes ou avec de multiples dépendances.\n- **Performance** : L'overhead de gestion dynamique des bundles peut affecter les performances dans des systèmes très sollicités.\n- **Écosystème limité** : Moins d'adoption dans l'écosystème [[Java]] moderne comparé à d'autres solutions comme les conteneurs ou les [[Micros services]].\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "2bc77698-0a7d-453d-9044-0f6a151c7a02",
        "title": "OpenAPI",
        "shortDescription": "",
        "description": "---\nid: d256da53-27ac-4a9e-a46c-98cea1cd5d5c\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nOpenAPI est une spécification standardisée qui permet de décrire les interfaces d'API de manière structurée, généralement en format YAML ou JSON. Elle permet de documenter, interagir et générer du code pour une API de façon automatisée.\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nOpenAPI est une spécification qui standardise la description des API REST. Elle permet de définir de manière précise les routes, les paramètres d'entrée, les types de réponse, et d'autres aspects d'une API, tout en facilitant l'automatisation du développement et de la documentation.\n\n- **Swagger vs OpenAPI** : Swagger était le nom original de la spécification avant son acquisition par SmartBear, qui a transféré la gestion de la spécification à l'OpenAPI Initiative. Swagger est désormais utilisé pour les outils liés à cette spécification.\n- **Documentation API** : La spécification décrit les endpoints d'une API, leur méthode (GET, POST, etc.), les paramètres attendus et les réponses, avec des exemples et des codes de statut.\n- **Génération de code** : En utilisant la spécification OpenAPI, des outils peuvent générer automatiquement des clients API, des serveurs, ou des SDKs dans différents langages.\n- **Exemple** : Un fichier YAML peut décrire un endpoint API comme `/users`, les paramètres qu'il accepte, et la structure de la réponse (par exemple, une liste d'utilisateurs au format JSON).\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Standardisation** : OpenAPI offre un format standard qui est largement adopté, ce qui simplifie l’interopérabilité entre systèmes.\n- **Génération automatique** : Outils comme Swagger peuvent générer automatiquement des clients et serveurs à partir de la spécification, réduisant le besoin de coder manuellement.\n- **Documentation interactive** : Grâce à des outils comme Swagger UI, la documentation devient interactive, permettant aux développeurs de tester directement les API via une interface web.\n- **Support étendu** : OpenAPI est bien supporté par de nombreux outils et langages, ce qui permet de l’intégrer facilement dans des projets existants.\n- **Validation et autocomplétion** : Les outils peuvent valider les requêtes envoyées à l’API et offrir de l’autocomplétion dans les IDE pour simplifier le développement.\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité pour les petites API** : Pour de simples API, l'utilisation d'OpenAPI peut sembler un peu trop lourde, avec la nécessité de maintenir un fichier de spécification.\n- **Peu adapté aux APIs non-REST** : Bien que l'OpenAPI soit conçu pour les API REST, il n’est pas aussi adapté pour d'autres architectures d’API, comme GraphQL.\n- **Nécessite un bon maintien de la spécification** : Pour que la spécification OpenAPI soit réellement utile, elle doit être mise à jour à chaque modification de l'API, ce qui demande une discipline de maintenance continue.\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "6ed60fdf-ad49-47cb-9abd-f529c1b03e76",
        "title": "OpenFaas",
        "shortDescription": "",
        "description": "---\nid: 6e46487a-240e-46da-8086-578df2c86d75\n---\n# Rapidement c'est quoi❓\n\nOpenFaaS est une plateforme serverless open source permettant de déployer et gérer des fonctions sans serveur ([[Function as a Service (FaaS)]]). Elle est conçue pour la production et intègre des outils de monitoring.\n\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nOpenFaaS est une plateforme de fonctions-as-a-service ([[Function as a Service (FaaS)]]) open source qui simplifie le déploiement et la gestion de [[Micros services]] encapsulés sous forme de fonctions.  Elle utilise des conteneurs [[Docker]] pour encapsuler chaque fonction, ce qui permet une isolation et une portabilité élevées. OpenFaaS fournit une interface utilisateur et une API pour gérer le cycle de vie complet des fonctions : déploiement, mise à jour, scaling et monitoring.  Elle supporte plusieurs langages de programmation ([[Go]], [[Node.js]], [[Python]], etc.) sous la forme de template et offre une intégration avec des outils d'orchestration de conteneurs comme [[Kubernetes]].  Le monitoring intégré permet de surveiller les performances et l'état de santé des fonctions déployées, fournissant des métriques cruciales pour la gestion et le débogage.  La plateforme est conçue pour la production,  garantissant une haute disponibilité et une scalabilité.  Le \"lourd\" mentionné initialement se réfère probablement à la complexité de la plateforme par rapport à des solutions plus légères, mais cette complexité est compensée par ses fonctionnalités avancées et sa robustesse pour les environnements de production.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open Source et communautaire:**  Bénéficie d'une communauté active et d'un code source librement accessible, favorisant la transparence et la collaboration.\n* **Production-ready:**  Conçu pour des environnements de production exigeants, avec une forte attention portée à la stabilité et à la scalabilité.\n* **Intégration avec [[Kubernetes]]:**  Permet un déploiement facile et une gestion efficace des fonctions dans des clusters Kubernetes.\n* **Monitoring intégré:**  Fournit des outils de monitoring complets pour surveiller les performances et l'état de santé des fonctions.\n* **Support de multiples langages:**  Permet d'utiliser le langage de programmation le plus adapté à chaque fonction.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La configuration et la gestion d'OpenFaaS peuvent être plus complexes que des solutions FaaS plus simplifiées.  La courbe d'apprentissage est plus raide.\n* **Ressources:**  Nécessite des ressources plus importantes que les solutions plus légères, surtout pour les environnements à forte charge.\n* **Monitoring intégré** : Il peut ne pas être évident de brancher OpenFaaS à son propre système de monitoring\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]][[MOC_DevSecOps]]\n\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e09a057d-c675-4911-9715-4d9703cdac1c",
        "title": "Certification Java 17 - Packages et Modules",
        "shortDescription": "",
        "description": "---\nid: cb5d98b8-992b-410a-94cd-54c70b45c82a\n---\n## **3.1. Organisation des classes en packages**\n\nEn Java, un **package** est un regroupement logique de classes permettant d’organiser le code et d'éviter les conflits de noms.\n\n### **Déclaration d’un package**\n\nChaque classe Java peut appartenir à un package défini en haut du fichier source :\n\n```java\npackage com.exemple.util;\n\npublic class Outil {\n    public static void afficherMessage() {\n        System.out.println(\"Message d'un outil\");\n    }\n}\n```\n\n\uD83D\uDCCC **Le package doit correspondre à l’arborescence des fichiers :**  \n\uD83D\uDCC2 `com/exemple/util/Outil.java`\n\n### **Utilisation d’un package (`import`)**\n\nDans une autre classe, on importe la classe `Outil` :\n\n```java\nimport com.exemple.util.Outil;\n\npublic class Main {\n    public static void main(String[] args) {\n        Outil.afficherMessage();\n    }\n}\n```\n\n\uD83D\uDCCC **Sans `import`**, on doit utiliser le nom complet :\n\n```java\ncom.exemple.util.Outil.afficherMessage();\n```\n\n### **Types d’accès dans un package**\n\n|Modificateur|Même classe|Même package|Héritage|Autres classes|\n|---|---|---|---|---|\n|`public`|✅|✅|✅|✅|\n|_(default)_|✅|✅|❌|❌|\n|`protected`|✅|✅|✅|❌|\n|`private`|✅|❌|❌|❌|\n\n\uD83D\uDCCC **Les classes d’un même package ont accès aux membres `default` et `protected`.**\n\n---\n\n## **3.2. Java Platform Module System (JPMS)** _(Depuis Java 9)_\n\nJPMS permet d’organiser le code en **modules** pour améliorer la maintenance et la sécurité.\n\n### **Qu’est-ce qu’un module ?**\n\nUn module est un **groupe de packages** déclarés dans un fichier spécial `module-info.java`.\n\n\uD83D\uDCC2 **Structure d’un projet modulaire :**\n\n```\n/mon-projet\n  /src\n    /com.exemple.util\n      Outil.java\n    /com.exemple.app\n      Main.java\n    module-info.java\n```\n\n---\n\n## **3.3. Définition d’un module**\n\nChaque module a un fichier `module-info.java` définissant ses **dépendances** et les packages qu’il expose.\n\n### **Créer un module `com.exemple.util`**\n\n\uD83D\uDCC4 `module-info.java`\n\n```java\nmodule com.exemple.util {\n    exports com.exemple.util;  // Exporte le package pour qu’il soit utilisable ailleurs\n}\n```\n\n\uD83D\uDCC4 `Outil.java`\n\n```java\npackage com.exemple.util;\n\npublic class Outil {\n    public static void afficherMessage() {\n        System.out.println(\"Message du module util\");\n    }\n}\n```\n\n### **Utiliser un module dans un autre (`com.exemple.app`)**\n\n\uD83D\uDCC4 `module-info.java`\n\n```java\nmodule com.exemple.app {\n    requires com.exemple.util;  // Dépendance au module util\n}\n```\n\n\uD83D\uDCC4 `Main.java`\n\n```java\npackage com.exemple.app;\n\nimport com.exemple.util.Outil;\n\npublic class Main {\n    public static void main(String[] args) {\n        Outil.afficherMessage();\n    }\n}\n```\n\n\uD83D\uDCCC **Sans `exports` dans `com.exemple.util`, `Outil` ne serait pas accessible !**\n\n---\n\n## **3.4. Dépendances entre modules**\n\nUn module peut dépendre d’un autre grâce à `requires`.\n\n```java\nmodule com.exemple.app {\n    requires com.exemple.util;  // Dépend de ce module\n}\n```\n\n### **Types de `requires`**\n\n|Directive|Description|\n|---|---|\n|`requires`|Dépendance obligatoire|\n|`requires transitive`|Propagé aux modules dépendants|\n|`requires static`|Dépendance uniquement à la compilation|\n\n\uD83D\uDCCC **Exemple de `requires transitive`**  \nSi `com.exemple.ui` dépend de `com.exemple.util`, on peut propager la dépendance :\n\n```java\nmodule com.exemple.ui {\n    requires transitive com.exemple.util;\n}\n```\n\nMaintenant, tout module **utilisant `com.exemple.ui` aura aussi accès à `com.exemple.util`**.\n\n---\n\n## **3.5. Services dans JPMS**\n\nLe JPMS introduit un système de **services** pour **définir et charger dynamiquement des implémentations**.\n\n### **Définition d’un service**\n\n\uD83D\uDCC4 `Service.java`\n\n```java\npackage com.exemple.service;\n\npublic interface Service {\n    void executer();\n}\n```\n\n### **Implémentation du service**\n\n\uD83D\uDCC4 `ServiceImpl.java`\n\n```java\npackage com.exemple.impl;\n\nimport com.exemple.service.Service;\n\npublic class ServiceImpl implements Service {\n    public void executer() {\n        System.out.println(\"Service exécuté !\");\n    }\n}\n```\n\n### **Module définissant le service (`provides`)**\n\n\uD83D\uDCC4 `module-info.java` dans `com.exemple.impl`\n\n```java\nmodule com.exemple.impl {\n    requires com.exemple.service;\n    provides com.exemple.service.Service with com.exemple.impl.ServiceImpl;\n}\n```\n\n### **Utilisation du service (`uses`)**\n\n\uD83D\uDCC4 `module-info.java` dans `com.exemple.app`\n\n```java\nmodule com.exemple.app {\n    requires com.exemple.service;\n    uses com.exemple.service.Service;\n}\n```\n\n\uD83D\uDCC4 `Main.java`\n\n```java\npackage com.exemple.app;\n\nimport com.exemple.service.Service;\nimport java.util.ServiceLoader;\n\npublic class Main {\n    public static void main(String[] args) {\n        ServiceLoader<Service> loader = ServiceLoader.load(Service.class);\n        for (Service service : loader) {\n            service.executer();  // Exécute automatiquement les implémentations\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **Les services permettent d'ajouter dynamiquement des implémentations sans modifier le code existant.**\n\n---\n\n## **Résumé**\n\n✅ **Packages** : Organisation en namespaces (`package` et `import`).  \n✅ **Modules** : Groupes de packages, isolés avec `module-info.java`.  \n✅ **Dépendances** : `requires`, `requires transitive`.  \n✅ **Services** : `provides` et `uses` pour une architecture modulaire et flexible.\n\n---\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a64ba342-46d1-4714-b28f-193017033846",
        "title": "Pipe Angular",
        "shortDescription": "",
        "description": "---\nid: 750c7ad4-f7ec-4a65-ae5e-a2b0f34af3be\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nUn **pipe** en [[Angular]] est un outil permettant de transformer les valeurs dans un template. Il s'agit d'une classe qui implémente l'interface `PipeTransform`, utilisée pour effectuer des transformations sur des données avant de les afficher, tout en étant optimisée pour les performances.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUn **pipe** est une fonction qui prend une valeur en entrée, effectue une transformation et retourne une nouvelle valeur. Elle est utilisée dans les templates Angular pour formater ou modifier les données de manière déclarative.\n\n### Fonctionnement :\n\n- Les **pipes** sont implémentés en créant une classe qui implémente l'interface `PipeTransform`, et en redéfinissant la méthode `transform`.\n- Lorsqu'un pipe est utilisé dans un template, il prend la donnée à transformer comme argument et applique la transformation définie dans la méthode `transform`.\n- Par défaut, les pipes sont **[[Méthode pure]]**, ce qui signifie qu'ils ne modifient pas directement la valeur passée, mais retournent une nouvelle instance. Cela aide [[Angular]] à optimiser les rendus en évitant des calculs redondants.\n\n### Exemple de pipe :\n\n1. **Création** : Via la CLI [[Angular]] :\n    \n    ```\n    ng g p nom_du_pipe\n    ```\n    \n2. **Utilisation** dans le template :\n    \n    ```\n    {{ maVariable | nom_du_pipe }}\n    ```\n    \n3. **Passage de plusieurs arguments** :\n    \n    ```\n    transform(val: string | undefined, valSiVide: string): string {\n        return val ? val : valSiVide;\n    }\n    \n    {{ maVariable | nom_du_pipe : '-' }}\n    ```\n    \n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Optimisation des performances** : Les pipes sont des [[Méthode pure]] par défaut, ce qui évite des recalculs inutiles lors des re-renders.\n- **Simplicité** : Les transformations dans les templates sont faciles à mettre en place, sans avoir besoin de logique complexe dans les composants.\n- **Réutilisabilité** : Les pipes peuvent être réutilisés dans plusieurs templates, ce qui rend le code plus propre et modulaire.\n- **Personnalisation** : Possibilité de créer des pipes personnalisés pour des transformations spécifiques.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Exécution fréquente** : Bien que les pipes purs soient optimisés, si des méthodes lourdes sont exécutées à l’intérieur d'un pipe non pur, elles risquent de diminuer les performances.\n- **Complexité pour les pipes impurs** : Si un pipe a des effets secondaires ou des calculs qui doivent se produire même sans changement de valeur, il peut devenir difficile à gérer et à optimiser.\n- **Difficulté avec les types complexes** : Les pipes qui manipulent des objets complexes ou des tableaux peuvent parfois entraîner des comportements inattendus, en raison des vérifications de changement de référence.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "426b06ca-5a74-48db-95ca-e19b5d566a06",
        "title": "Pitest",
        "shortDescription": "",
        "description": "---\nid: 3f5a054c-06a1-4812-9802-1e1df6fe8452\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**PiTest** est une bibliothèque de [[Test de mutation]] pour [[Java]]. Elle permet de tester la robustesse des tests unitaires en introduisant des mutations (modifications) dans le code source et en vérifiant si les tests les détectent.\nOn surnomme cette librarie PIT.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nPiTest génère des mutants dans le code source, c'est-à-dire des modifications aléatoires ou dirigées, et exécute les tests unitaires pour voir si ces changements sont détectés. Cela permet de mesurer l'efficacité des tests existants. Par exemple, un test qui ne détecte pas une mutation est considéré comme insuffisant.\n\n**Fonctionnement :**\n\n- L’outil prend un projet [[Java]] et applique des mutations sur les classes de l’application.\n- Il exécute les tests unitaires pour chaque mutation, et génère des rapports détaillant les mutations détectées ou non par les tests.\n- Configurable via [[Maven]] ou [[Gradle]], PiTest peut être ajusté pour cibler des classes ou des tests spécifiques.\n\n**Installation :**\n\n- Ajout d’un plugin dans le fichier `pom.xml` ou `build.gradle`.\n\n**Exécution :**\n\n- Lancer la commande `mvn test-compile org.pitest:pitest-maven:mutationCoverage` pour commencer l'analyse.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Facilité d'intégration** : Ajout simple via [[Maven]] ou [[Gradle]].\n- **Rapports détaillés** : Produit des rapports de couverture des mutations qui aident à évaluer la qualité des tests.\n- **Paramétrable** : Permet de cibler des classes et tests spécifiques pour une analyse plus fine.\n- **Amélioration continue** : Aide à améliorer la qualité du code en s’assurant que les tests couvrent bien tous les cas de mutation.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Performance** : L'exécution peut être longue, surtout avec de grandes bases de code ou de nombreux tests.\n- **Complexité croissante** : Une fois les mutations et les tests multipliés, l’analyse peut devenir difficile à interpréter et à gérer.\n- **Faux positifs** : Certains mutants peuvent ne pas être pertinents pour tous les projets, ce qui nécessite des ajustements fins pour éviter des faux négatifs.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "45af2e5c-f8f4-4925-8f42-792e76f6d8f8",
        "title": "Certification Java 17 - Programmation Concurrente",
        "shortDescription": "",
        "description": "---\nid: 84743d0a-b01c-4a99-9742-863cc98bedf2\n---\n## **9.1. Threads (`Runnable`, `Callable`)**\n\nUn **thread** permet d’exécuter une tâche en parallèle d’autres instructions.  \nJava propose deux interfaces principales :\n\n- `Runnable` (pas de retour de valeur)\n- `Callable<V>` (retourne une valeur et peut lever une exception)\n\n---\n\n### **1. Création d’un `Thread` avec `Runnable`**\n\n```java\nclass Tache implements Runnable {\n    public void run() {\n        System.out.println(\"Thread exécuté !\");\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Thread t = new Thread(new Tache());\n        t.start();  // Démarre le thread\n    }\n}\n```\n\n\uD83D\uDCCC **Ne pas appeler `run()` directement, utiliser `start()`.**\n\n---\n\n### **2. Création d’un `Thread` avec `Callable` (retour de valeur)**\n\n```java\nimport java.util.concurrent.*;\n\npublic class Exemple {\n    public static void main(String[] args) throws Exception {\n        Callable<Integer> tache = () -> 42;\n        ExecutorService executor = Executors.newSingleThreadExecutor();\n        Future<Integer> futur = executor.submit(tache);\n\n        System.out.println(futur.get()); // 42\n        executor.shutdown();\n    }\n}\n```\n\n\uD83D\uDCCC **`Callable<V>` retourne une valeur via `Future<V>`.**\n\n---\n\n## **9.2. `ExecutorService`, `ForkJoinPool`**\n\n### **1. `ExecutorService` : Gestion des threads**\n\n```java\nExecutorService executor = Executors.newFixedThreadPool(3);\nexecutor.submit(() -> System.out.println(\"Thread lancé\"));\nexecutor.shutdown();\n```\n\n\uD83D\uDCCC **Avantages :**\n\n- Gère automatiquement les threads.\n- Optimise l’utilisation des ressources.\n\n|**Type d’Executor**|**Description**|\n|---|---|\n|`newFixedThreadPool(n)`|Pool de `n` threads fixes|\n|`newCachedThreadPool()`|Crée des threads à la demande|\n|`newSingleThreadExecutor()`|1 seul thread (exécution séquentielle)|\n\n---\n\n### **2. `ForkJoinPool` : Exécution de tâches récursives**\n\nUtilisé pour **diviser une tâche complexe** en sous-tâches exécutées en parallèle.\n\n```java\nimport java.util.concurrent.*;\n\nclass TacheRecursive extends RecursiveTask<Integer> {\n    int n;\n    TacheRecursive(int n) { this.n = n; }\n\n    protected Integer compute() {\n        if (n <= 1) return n;\n        TacheRecursive t1 = new TacheRecursive(n - 1);\n        TacheRecursive t2 = new TacheRecursive(n - 2);\n        t1.fork();\n        return t2.compute() + t1.join();\n    }\n}\n\npublic class Exemple {\n    public static void main(String[] args) {\n        ForkJoinPool pool = new ForkJoinPool();\n        int result = pool.invoke(new TacheRecursive(10));\n        System.out.println(result);\n    }\n}\n```\n\n\uD83D\uDCCC **Optimisé pour les calculs récursifs lourds (`divide & conquer`).**\n\n---\n\n## **9.3. Threads Virtuels (`Virtual Threads`, `Thread.ofVirtual()`)**\n\nIntroduits en **Java 21**, les **Virtual Threads** permettent d’exécuter **des millions de tâches concurrentes** avec peu de threads physiques.\n\n```java\nThread.startVirtualThread(() -> {\n    System.out.println(\"Thread virtuel lancé !\");\n});\n```\n\n\uD83D\uDCCC **Avantages :**\n\n- Très léger (pas lié à un thread système).\n- Optimisé pour des tâches bloquantes (I/O, bases de données).\n\n---\n\n### **Création d’un `Virtual Thread` avec un `Executor`**\n\n```java\nExecutorService executor = Executors.newVirtualThreadPerTaskExecutor();\nexecutor.submit(() -> System.out.println(\"Tâche exécutée\"));\nexecutor.shutdown();\n```\n\n\uD83D\uDCCC **Chaque tâche a son propre thread virtuel sans surcharger le CPU.**\n\n---\n\n## **9.4. Verrous (`synchronized`, `Lock`, `ReadWriteLock`)**\n\n### **1. `synchronized` : Verrouillage automatique**\n\n```java\nclass Compteur {\n    private int valeur = 0;\n\n    public synchronized void incrementer() {\n        valeur++;\n    }\n}\n```\n\n\uD83D\uDCCC **Seul un thread peut exécuter `incrementer()` à la fois.**\n\n---\n\n### **2. `Lock` : Gestion manuelle des verrous**\n\n```java\nimport java.util.concurrent.locks.*;\n\nclass Ressource {\n    private final Lock lock = new ReentrantLock();\n\n    public void acces() {\n        lock.lock();\n        try {\n            System.out.println(\"Accès sécurisé\");\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n\uD83D\uDCCC **`ReentrantLock` offre plus de contrôle que `synchronized`.**\n\n---\n\n### **3. `ReadWriteLock` : Optimisation des accès concurrents**\n\n- Plusieurs lectures simultanées.\n- Écriture exclusive.\n\n```java\nimport java.util.concurrent.locks.*;\n\nclass Cache {\n    private final ReadWriteLock lock = new ReentrantReadWriteLock();\n    private int valeur = 0;\n\n    public int lire() {\n        lock.readLock().lock();\n        try { return valeur; }\n        finally { lock.readLock().unlock(); }\n    }\n\n    public void ecrire(int nouvelleValeur) {\n        lock.writeLock().lock();\n        try { valeur = nouvelleValeur; }\n        finally { lock.writeLock().unlock(); }\n    }\n}\n```\n\n\uD83D\uDCCC **Optimise les lectures fréquentes avec peu d’écritures.**\n\n---\n\n## **9.5. Collections Concurrentes et Streams Parallèles**\n\n### **1. Collections Concurrentes**\n\n|**Classe**|**Description**|\n|---|---|\n|`ConcurrentHashMap`|`HashMap` thread-safe|\n|`CopyOnWriteArrayList`|`ArrayList` modifiable sans verrou|\n|`BlockingQueue`|File d’attente bloquante|\n\n**Exemple avec `ConcurrentHashMap` :**\n\n```java\nimport java.util.concurrent.*;\n\nMap<String, Integer> map = new ConcurrentHashMap<>();\nmap.put(\"A\", 1);\nSystem.out.println(map.get(\"A\"));\n```\n\n---\n\n### **2. `Stream` Parallèle (`parallelStream()`)**\n\nTransforme un `Stream` en version parallèle.\n\n```java\nList<Integer> nombres = List.of(1, 2, 3, 4, 5);\nint somme = nombres.parallelStream()\n    .mapToInt(Integer::intValue)\n    .sum();\nSystem.out.println(somme);\n```\n\n\uD83D\uDCCC **Améliore les performances pour les grandes collections.**\n\n⚠ **Attention :**\n\n- Un `Stream` parallèle ne garantit pas l’ordre des résultats.\n- Peut être moins performant pour des petites collections.\n\n---\n\n## **Résumé**\n\n✅ **Threads (`Runnable`, `Callable`)** : Exécuter des tâches en parallèle.  \n✅ **`ExecutorService`, `ForkJoinPool`** : Gestion optimisée des threads.  \n✅ **Threads Virtuels (`VirtualThread`)** : Très légers, optimisés pour I/O.  \n✅ **Verrous (`synchronized`, `Lock`, `ReadWriteLock`)** : Gestion des accès concurrents.  \n✅ **Collections Concurrentes et Streams Parallèles** : `ConcurrentHashMap`, `parallelStream()`.",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "fae7c92e-e8a3-454a-b8d9-7c971756468c",
        "title": "Certification Java 17 - Programmation Orientée Objet (OOP)",
        "shortDescription": "",
        "description": "---\nid: df0b5c7d-a921-49b3-8778-71e5ae745df5\n---\n## **2.1. Déclaration et instanciation d’objets**\n\nEn Java, tout repose sur les **objets** et les **classes**.\n\n### **Définition d’une classe et création d’objets**\n\n```java\nclass Voiture {\n    String marque;\n    \n    Voiture(String marque) {\n        this.marque = marque;\n    }\n}\n\npublic class Main {\n    public static void main(String[] args) {\n        Voiture v1 = new Voiture(\"Toyota\");  // Instanciation d’un objet\n        System.out.println(v1.marque); // Toyota\n    }\n}\n```\n\n\uD83D\uDCCC **`new` alloue de la mémoire et retourne une référence à l'objet.**\n\n### **Différences entre `new` et `newInstance()`**\n\n- `new` est utilisé directement.\n- `Class.forName(\"NomDeClasse\").newInstance();` permet une instanciation dynamique.\n\n---\n\n## **2.2. Cycle de vie des objets**\n\nLe **cycle de vie** d’un objet comprend :\n\n1. **Création** (`new`)\n2. **Utilisation** (modifications, appels de méthodes)\n3. **Perte de référence** (`null` ou sortie du scope)\n4. **Garbage Collection** (ramasse-miettes)\n\n**Exemple de perte de référence :**\n\n```java\nVoiture v1 = new Voiture(\"Renault\");\nv1 = null; // L'objet devient éligible au Garbage Collector\n```\n\n### **Garbage Collector (GC)**\n\nLe **GC** libère la mémoire des objets **inaccessibles**.\n\n- `System.gc();` demande un ramassage (sans garantie).\n- `finalize()` (déprécié) était invoqué avant suppression d’un objet.\n\n---\n\n## **2.3. Encapsulation et immutabilité**\n\n### **Encapsulation (getter/setter)**\n\nPrincipe : **cacher les champs** et y accéder via **des méthodes publiques**.\n\n```java\nclass CompteBancaire {\n    private double solde;\n\n    public double getSolde() { return solde; }\n    public void deposer(double montant) { solde += montant; }\n}\n```\n\n✅ **Sécurise les données**  \n✅ **Permet des règles métier (ex: solde min.)**\n\n### **Immutabilité**\n\nUn objet **immuable** ne peut pas être modifié après création.  \n**Bonne pratique :** Déclarer les champs `private final` et ne fournir aucun setter.\n\n```java\nclass Client {\n    private final String nom;\n\n    Client(String nom) { this.nom = nom; }\n    public String getNom() { return nom; }\n}\n```\n\n---\n\n## **2.4. Héritage, classes abstraites et classes scellées (sealed)**\n\n### **Héritage (`extends`)**\n\nPermet de réutiliser le code d'une classe mère.\n\n```java\nclass Animal {\n    String type = \"Mammifère\";\n}\n\nclass Chien extends Animal {\n    String race = \"Labrador\";\n}\n```\n\n\uD83D\uDCCC **Un objet `Chien` possède aussi `type`.**\n\n### **Classes Abstraites (`abstract`)**\n\nImpossible à instancier, sert de modèle.\n\n```java\nabstract class Animal {\n    abstract void faireDuBruit();  // Méthode abstraite\n}\nclass Chien extends Animal {\n    void faireDuBruit() { System.out.println(\"Woof!\"); }\n}\n```\n\n### **Classes Sealed (`sealed`)** _(Java 17)_\n\nRestreint l’héritage à des classes précises.\n\n```java\nsealed class Animal permits Chien, Chat {}\nfinal class Chien extends Animal {}  // Pas d’héritage possible\nnon-sealed class Chat extends Animal {}  // Héritage permis\n```\n\n---\n\n## **2.5. Polymorphisme, type objet vs type référence**\n\n**Polymorphisme** : une méthode peut se comporter différemment selon l’objet.\n\n```java\nclass Animal {\n    void faireDuBruit() { System.out.println(\"Bruit d’animal\"); }\n}\nclass Chien extends Animal {\n    void faireDuBruit() { System.out.println(\"Woof!\"); }\n}\npublic class Main {\n    public static void main(String[] args) {\n        Animal a = new Chien();  // Type référence : Animal, type objet : Chien\n        a.faireDuBruit();  // Woof! (méthode de Chien)\n    }\n}\n```\n\n\uD83D\uDCCC **Le type objet détermine la méthode exécutée.**\n\n---\n\n## **2.6. Opérateur `instanceof` et Pattern Matching**\n\n### **Opérateur `instanceof`** _(avant Java 16)_\n\n```java\nif (obj instanceof Chien) {\n    Chien c = (Chien) obj;\n    c.aboyer();\n}\n```\n\n### **Pattern Matching (`instanceof`)** _(Java 16+)_\n\n```java\nif (obj instanceof Chien c) {\n    c.aboyer();  // Plus besoin de caster !\n}\n```\n\n---\n\n## **2.7. Interfaces : méthodes `default`, `static`, privées**\n\nUne **interface** définit un **contrat** que les classes doivent respecter.\n\n```java\ninterface Animal {\n    void faireDuBruit();\n}\nclass Chien implements Animal {\n    public void faireDuBruit() { System.out.println(\"Woof!\"); }\n}\n```\n\n### **Méthodes `default`**\n\nPermet d’ajouter une méthode sans casser les implémentations existantes.\n\n```java\ninterface Animal {\n    default void dormir() { System.out.println(\"Je dors\"); }\n}\n```\n\n### **Méthodes `static`**\n\nUne méthode statique appartient à l'interface et ne peut pas être redéfinie.\n\n```java\ninterface Utilitaire {\n    static void afficherMessage() { System.out.println(\"Message statique\"); }\n}\n```\n\n### **Méthodes privées** _(Java 9+)_\n\nPermet d'éviter la duplication de code dans une interface.\n\n```java\ninterface Animal {\n    default void action() {\n        preparer();\n        System.out.println(\"Faire une action\");\n    }\n    private void preparer() {\n        System.out.println(\"Préparation...\");\n    }\n}\n```\n\n---\n\n## **2.8. Enums avec champs, méthodes et constructeurs**\n\nUn **enum** représente un ensemble **fixe** de valeurs.\n\n```java\nenum Jour {\n    LUNDI, MARDI, MERCREDI;\n}\n```\n\n### **Enum avec champs et méthodes**\n\n```java\nenum Statut {\n    EN_COURS(1), TERMINE(2);\n\n    private final int code;\n    \n    Statut(int code) { this.code = code; }\n    public int getCode() { return code; }\n}\n```\n\n\uD83D\uDCCC **Les `enum` peuvent avoir des méthodes et des constructeurs privés.**\n\n---\n\n## **Résumé**\n\n✅ **Encapsulation** avec `private` et `getter/setter`  \n✅ **Immutabilité** : `final` et pas de setter  \n✅ **Héritage** : `extends` pour spécialiser une classe  \n✅ **Classes abstraites** : modèle de base à implémenter  \n✅ **Classes `sealed`** : restreint l'héritage (Java 17)  \n✅ **Polymorphisme** : le type objet dicte le comportement  \n✅ **`instanceof` avec Pattern Matching** : simplifie les cast  \n✅ **Interfaces avec méthodes `default`, `static`, privées`** ✅ **`enum` avec méthodes et champs privés**\n\n---\n\n[[Java]] [[Certification Java 17]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "37d4edee-5398-4339-b662-b16aff7c6389",
        "title": "Prometheus",
        "shortDescription": "",
        "description": "---\nid: ec08a5df-a7b8-4dd1-bbca-5109de9470bd\n---\n# Rapidement c'est quoi❓\n\nPrometheus est un système de [[Monitoring]] et d'alerte [[Open-source]] qui stocke les données sous forme de séries temporelles.  Il récupère des métriques et les affiche via un tableau de bord.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nPrometheus est un système de surveillance et d'alerte open source basé sur une architecture de pull (contrairement à une architecture de push).  Il fonctionne en interrogeant régulièrement (par défaut toutes les 15 secondes) des targets (applications, serveurs, etc.) exposant des métriques via une interface [[HTTP]] (généralement le port 9100).  Ces métriques sont des séries temporelles, c'est-à-dire des données associées à un timestamp.  Chaque métrique est identifiée par un nom et un ensemble d'étiquettes (labels) qui permettent de filtrer et agréger les données.\n\nPrometheus stocke ces données dans une [[Base de donnée]] interne et les expose via une interface utilisateur web.  Il permet de créer des alertes basées sur des règles définies sur les métriques (ex:  si la latence dépasse 500ms, envoyer une alerte).  L'outil offre des fonctionnalités de visualisation des données et de création de dashboards pour suivre l'état de son infrastructure.  Il peut être étendu via des exporters (pour collecter des métriques de différents systèmes) et des librairies clientes pour exposer des métriques personnalisées.  Contrairement à certains systèmes de monitoring qui utilisent une architecture de push (où les targets envoient les métriques à un serveur central), Prometheus utilise une architecture de pull, ce qui simplifie la configuration et améliore la fiabilité.  Cependant, cela nécessite que les targets soient toujours accessibles à Prometheus.  Son stockage interne est basé sur un modèle de données temps-série optimisé pour les requêtes de données et la performance des requêtes.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open source et gratuit:**  Large communauté, documentation abondante et contributions constantes.\n* **Architecture robuste et scalable:**  Capable de gérer un grand nombre de métriques et de targets.\n* **Flexibilité et extensibilité:**  Large choix d'exporters et de librairies clientes.\n* **Système d'alertes puissant:**  Création facile de règles d'alerte complexes.\n* **Interface utilisateur intuitive:**  Visualisation et exploration des données simples et efficaces.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Architecture de pull:**  Nécessite que les targets soient toujours disponibles et accessibles.  Les targets inaccessibles ne sont pas monitorées.\n* **Stockage interne limité:**  Pour de très grands volumes de données, une solution de stockage externe est nécessaire (comme [[Thanos]], par exemple).\n* **Courbe d'apprentissage:**  La configuration et l'utilisation peuvent nécessiter une certaine expertise pour tirer pleinement parti de ses fonctionnalités avancées.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "ba0218cf-bb84-4722-9d0a-517f4c6f82be",
        "title": "Raison d’une bonne architecture d’un SI",
        "shortDescription": "",
        "description": "---\nid: ce97e1da-3b18-44bc-a286-a42fc3195261\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nUne bonne architecture d'un Système d'Information (SI) est une structure flexible, évolutive et adaptée aux besoins actuels et futurs de l'organisation. Elle doit être conçue pour faciliter le changement sans sacrifier la stabilité.\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUne bonne architecture d’un SI permet de répondre efficacement aux besoins immédiats tout en restant ouverte aux évolutions futures. Elle doit être :\n\n- **Adaptée au besoin** : Chaque architecture doit être alignée avec les objectifs métiers et les contraintes techniques spécifiques à l'organisation.\n- **Flexible** : Elle doit permettre des changements rapides sans compromettre la performance ou la stabilité du système.\n- **Minimiser les anticipations excessives** : Une architecture trop rigide, construite autour de changements futurs incertains, peut devenir obsolète rapidement. Il est souvent plus facile de modifier une architecture au fil de l’eau plutôt que de tenter de tout prévoir.\n- **Architecture continue** : Elle évolue de manière incrémentale, en répondant aux besoins immédiats et en intégrant progressivement les changements sans s’imposer des modèles rigides.\n\nL'idée est d'éviter le \"gros DAT\" ([[Document d'Architecture Technique]]) figé qui restreint l'innovation et de favoriser une approche agile et évolutive, où l'architecture peut se réajuster au fur et à mesure des besoins.\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Flexibilité** : Permet de s'adapter rapidement aux évolutions du marché et aux besoins changeants des utilisateurs.\n- **Évolutivité** : L'architecture est construite pour intégrer facilement de nouveaux composants ou de nouvelles fonctionnalités.\n- **Réactivité** : Une architecture continue facilite la gestion des imprévus sans perturber l’ensemble du système.\n- **Optimisation des coûts** : En adaptant les ressources en fonction des besoins réels et non des projections, l’architecture évite le gaspillage.\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité à court terme** : Lors de la mise en place d’une architecture flexible, il peut être difficile de gérer une transition en douceur avec les systèmes existants.\n- **Risque d'itération non maîtrisée** : Une trop grande flexibilité peut mener à des ajustements constants et à une incohérence entre les différentes parties du système.\n- **Gestion de la dette technique** : Sans une vision claire, l'architecture continue peut accumuler de la dette technique au fil des ajustements successifs.\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]] [[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "3f37d305-6168-491b-8487-7d9c7316354c",
        "title": "Redis Sentinel",
        "shortDescription": "",
        "description": "---\nid: 7c33ceca-69d3-469a-9986-edcee3a042f4\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nRedis Sentinel est un outil de haute disponibilité pour [[Redis]], permettant de surveiller un serveur Redis principal (master) et ses répliques (slaves), et de promouvoir automatiquement un slave en master en cas de défaillance du master actuel.\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nRedis Sentinel est conçu pour assurer la disponibilité et la résilience des instances Redis. Il surveille le serveur [[Redis]] master et ses répliques (slaves) pour détecter toute panne. En cas de défaillance du master, Sentinel sélectionne un slave (celui ayant la dernière mise à jour) pour le promouvoir en master et ainsi maintenir la disponibilité du service Redis.\n\n- **Architecture** : Un master [[Redis]] avec plusieurs répliques (slaves) synchronisées.\n- **Rôle des Sentinels** : Surveiller l'état du master et des slaves, détecter les pannes, et effectuer un basculement automatique (failover) en cas de défaillance.\n- **Critères de promotion** : Le slave avec la dernière mise à jour devient le nouveau master.\n- **Limitation** : Redis Sentinel ne constitue pas un cluster Redis distribué complet, car il ne gère pas la répartition des données entre plusieurs instances. Il se concentre uniquement sur la haute disponibilité.\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Haute disponibilité** : En cas de panne du master, un slave est automatiquement promu pour minimiser les interruptions de service.\n- **Surveillance continue** : Sentinel surveille en permanence l'état des instances [[Redis]], garantissant une détection rapide des problèmes.\n- **Failover automatique** : Pas besoin d'intervention manuelle pour promouvoir un nouveau master, ce qui réduit le risque d'erreur et améliore la réactivité.\n- **Simplicité** : Configuration relativement simple pour gérer la [[Haute disponibilité]] avec Redis.\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Pas un cluster Redis complet** : Redis Sentinel ne gère pas la distribution des données ou le partitionnement, contrairement à un cluster Redis distribué.\n- **Dépendance au réseau** : Si Sentinel et les instances Redis sont mal configurés ou s'il y a des problèmes réseau, le failover peut échouer.\n- **Sélection du nouveau master** : Le processus de promotion d'un slave peut parfois être lent si les instances Redis ne sont pas bien synchronisées.\n- **Limité à la [Haute disponibilité]]** : Redis Sentinel ne prend pas en charge d'autres fonctionnalités avancées comme la gestion automatique des partitions ou des volumes de données.\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "6b6bd7b1-3d82-4f65-be46-aa30c20f278f",
        "title": "Redis",
        "shortDescription": "",
        "description": "---\nid: c3202556-f6cf-4e20-b7e8-09270e6ab143\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**Redis** est une [[Base de donnée NoSQL]] , utilisée comme cache et store de structures de données telles que des chaînes de caractères, des listes, des ensembles, etc. Elle est populaire pour sa rapidité et sa simplicité d’utilisation, particulièrement pour la gestion de données temporaires.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nRedis offre des fonctionnalités diverses comme le caching, la gestion de sessions et le stockage temporaire de données, grâce à sa capacité à stocker des données en mémoire et à les manipuler très rapidement.\n\nAvec [[Java]], Redis peut être intégré via plusieurs mécanismes :\n\n1. **Redis Template** :  \n    Permet d'interagir avec Redis à un niveau bas, proche de la ligne de commande. Il est flexible mais nécessite plus de gestion manuelle des opérations Redis.\n    \n2. **[[Spring Data Redis]]** :  \n    Permet d'utiliser Redis avec l'API de [[Spring Data]], offrant une interface plus haut niveau pour interagir avec Redis comme avec une base de données traditionnelle (similaire à Spring [[Data JPA]]). Cependant, pour des objets complexes, cette approche peut mener à des requêtes excessives, impactant ainsi la performance.\n    \n3. **[[Spring Cache]]** :  \n    Permet une gestion de cache plus simple en annotant les méthodes avec `@Cacheable`, ce qui permet de stocker et de récupérer les résultats des méthodes dans Redis sans code supplémentaire complexe.\n    \n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **[[Redis Template]]** :\n    - Permet une gestion fine des interactions avec Redis.\n    - Offre plus de flexibilité pour des cas d’usage spécifiques.\n\n- **[[Spring Data Redis]]** :    \n    - Permet une intégration transparente avec [[Spring Framework]].\n    - Facile à utiliser pour les utilisateurs déjà familiers avec Spring Data.\n\n- **[[Spring Cache]]** :\n    - Très simple à implémenter pour la mise en cache des résultats de méthodes.\n    - Automatisation des processus de cache sans complexité supplémentaire.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Redis Template** :\n    - Nécessite de gérer soi-même les interactions avec Redis, ce qui peut augmenter la complexité du code.\n- **Spring Data Redis** :\n    - Peut entraîner des problèmes de performance pour des objets complexes en raison du nombre élevé de requêtes nécessaires pour récupérer un objet complet.\n- **Spring Cache** :\n    - Peut être limité en termes de contrôle précis sur les stratégies de cache et la gestion des données en mémoire.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "86b2d35e-3053-4031-ad65-92db698ddade",
        "title": "Renovate_Bot",
        "shortDescription": "",
        "description": "---\nid: 98f7085c-54d4-4d54-a6ba-7512a4ffaed8\n---\n# Rapidement c'est quoi❓\n\nRenovate Bot est un outil automatisé qui analyse les dépendances de vos projets [[Git]]  et crée des pull/merge requests pour mettre à jour ces dépendances vers leurs dernières versions stables ou spécifiques.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nRenovate Bot est un outil d'automatisation de la gestion des dépendances logicielles. Il fonctionne en analysant le fichier de configuration de votre projet (ex: `package.json` pour [[Node.js]], `pom.xml` pour [[Maven]] ...) afin d'identifier toutes les dépendances utilisées.  Il compare ensuite les versions actuelles avec les dernières versions disponibles sur les registres de paquets (ex: [[npm]], [[Maven Central]]).  Pour chaque dépendance obsolète, Renovate Bot crée une pull request séparée contenant les mises à jour nécessaires.  L'utilisateur peut ensuite examiner et fusionner ces pull requests, automatisant ainsi le processus fastidieux et potentiellement risqué de mise à jour manuelle des dépendances.  L'outil est configurable pour définir des règles de mise à jour (ex:  mise à jour majeure, mineure, patch, fréquence de scan, branches cibles, etc.).  Il prend en charge un large éventail de gestionnaires de paquets et de langages de programmation.  Renovate Bot peut être intégré à des [[pipelines CI/CD]] comme [[GitHub Action]] ou [[GitLab CI]].  Il permet également la gestion de configurations complexes en utilisant des fichiers de configuration YAML ou JSON.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Automatisation:**  Élimine le besoin de mises à jour manuelles chronophages et sujettes aux erreurs.\n* **Sécurité:**  Aide à maintenir les dépendances à jour, réduisant les risques de vulnérabilités.\n* **Flexibilité:**  Configuration personnalisée pour contrôler le processus de mise à jour (fréquence, versions cibles, etc.).\n* **Support multi-langage et multi-gestionnaire de paquets:** Couverture large des écosystèmes de développement.\n* **Intégration facile:**  Intégration avec les plateformes [[Git]] les plus populaires.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité de configuration:**  La configuration peut être complexe pour des projets avec des dépendances nombreuses ou des exigences spécifiques.\n* **Dépendance à un service tiers:**  La fonctionnalité dépend d'une connexion stable à l'infrastructure de Renovate Bot.\n* **Potentiel de conflits de fusion:**  Les mises à jour automatiques peuvent parfois créer des conflits avec d'autres modifications, nécessitant une intervention manuelle.\n* **Surveillance nécessaire:**  Bien que automatisé, il est toujours nécessaire de surveiller les pull requests générées pour éviter les problèmes.\n* **Courbe d'apprentissage:**  Nécessite une compréhension des gestionnaires de paquets et des principes de gestion des dépendances.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e8412082-486c-4479-8ffb-666b4cc1ff5f",
        "title": "Responsive des images html css",
        "shortDescription": "",
        "description": "---\nid: 7822de72-7567-4eb4-9a12-3980e4e48032\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLe responsive des images [[HTML]]/[[CSS]] permet de charger des images différentes en fonction de la taille de l'écran, de l'orientation ou d'autres critères. Cela permet d'optimiser le temps de chargement et la performance d'un site web.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe balisage `<picture>` et les éléments `<source>` dans HTML permettent de définir des images spécifiques à afficher selon des conditions précises, comme la taille de l'écran ou l'orientation du dispositif. Chaque `<source>` peut contenir une condition via l'attribut `media` et définir la source de l'image avec `srcset`. Le navigateur choisira automatiquement l'image la plus adaptée.\n\nExemple :\n\n```html\n<picture>\n  <source media=\"(orientation: portrait) and (max-width: 700px)\" srcset=\"https://url_image\" sizes=\"100vw\" />\n  <source media=\"(orientation: portrait)\" srcset=\"https://url_image\" sizes=\"100vw\" />\n</picture>\n```\n\nCela permet de ne charger que l'image nécessaire, en fonction de la configuration du périphérique, réduisant ainsi la consommation de bande passante et améliorant la performance du site.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Optimisation des performances** : Le navigateur choisit l'image la plus appropriée en fonction des conditions définies, ce qui réduit la taille des fichiers téléchargés.\n- **Réduction du temps de chargement** : En ne chargeant que l'image nécessaire selon la taille d'écran ou l'orientation, on évite de télécharger des images inutiles.\n- **Flexibilité** : Permet d'utiliser plusieurs images avec des tailles et résolutions différentes selon le contexte (ex : mobile vs desktop).\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité accrue** : La gestion des multiples sources d'image peut devenir complexe avec plusieurs conditions à gérer.\n- **Compatibilité limitée** : Tous les navigateurs ne supportent pas parfaitement la balise `<picture>`, bien que la prise en charge soit désormais largement répandue.\n- **Charge serveur** : Bien qu'il y ait une optimisation côté client, le serveur doit gérer plusieurs versions d'images, augmentant la gestion côté backend.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Responsive en CSS]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "9591fb64-906a-4a68-9998-f99e437f7581",
        "title": "Responsive en CSS",
        "shortDescription": "",
        "description": "---\nid: 4797285a-dc72-4c05-a1d0-75bf11fb9382\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLe responsive design en [[CSS]] permet d'adapter l'apparence d'une page web à différentes tailles d'écrans et résolutions, en utilisant des unités flexibles et des techniques comme les media queries pour offrir une expérience optimale sur mobile, tablette et desktop.\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe responsive design en [[CSS]] repose sur plusieurs concepts permettant d'adapter le contenu d'une page web en fonction des caractéristiques de l'écran (taille, orientation, résolution) :\n\n- **Unités dynamiques** : Des unités comme `vw` (viewport width), `vh` (viewport height), et `vmin` (la plus petite valeur entre `vh` et `vw`) permettent de créer des éléments qui s'ajustent à la taille de l'écran de manière fluide.\n- **Media Queries** : Ces règles permettent de spécifier différents styles CSS en fonction de critères comme la taille de l'écran, l'orientation ou la résolution.\n- **Element `<picture>`** : Utilisé pour charger des images différentes selon les conditions définies (par exemple, orientation ou taille d'écran). Cela optimise le temps de chargement et améliore la performance, en ne chargeant que l'image la plus appropriée pour l'affichage.\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Adaptabilité** : Le design réactif garantit une expérience utilisateur optimale, quelle que soit la taille de l'écran.\n- **Performance** : L’utilisation du `<picture>` pour les images et des unités dynamiques réduit la quantité d’images ou de ressources inutiles à charger, améliorant ainsi la vitesse de chargement.\n- **Facilité d’implémentation** : L’utilisation des media queries permet de faire évoluer l’affichage de manière fluide sans nécessiter de redéveloppement complet pour chaque taille d’écran.\n- **Mobile-first** : Cette approche assure que le site est toujours fonctionnel sur les appareils mobiles, qui sont souvent les plus contraints en termes de taille d'écran et de performance.\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité accrue** : Gérer de multiples tailles d’écran et orientations peut compliquer le processus de développement et de maintenance.\n- **Débogage difficile** : Tester sur tous les types d'écrans et simulateurs peut être long et fastidieux, surtout lorsque les styles ne sont pas cohérents entre différents appareils.\n- **Temps de chargement** : Bien que l'utilisation du `<picture>` soit performante, si mal configurée, cela peut entraîner des délais de chargement en fonction de la taille des images et du nombre de sources utilisées.\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Mobile First]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "42c711ee-117b-417a-8c6e-9b684a10120c",
        "title": "Réactivité",
        "shortDescription": "",
        "description": "---\nid: 4094d186-18e0-4673-a238-ad66d828c305\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLa **programmation réactive** est une approche qui permet aux programmes de réagir de manière asynchrone et dynamique aux changements d'état dans leur environnement. Cela permet d'améliorer la réactivité des applications, en particulier dans des contextes interactifs et temps réel.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLa programmation réactive se base sur l'idée que les applications doivent être capables de réagir à des changements en temps réel, comme les événements utilisateur ou les mises à jour de données. Différentes bibliothèques et frameworks utilisent cette approche pour gérer l'état et les interactions de manière plus fluide et réactive.\n\n### Types de réactivité :\n\n1. **Value-based** (ex : [[Angular]], [[React]]) :  \n    Les anciennes valeurs sont comparées aux nouvelles, et si elles diffèrent, l'application met à jour l'état. Ce modèle est simple à implémenter mais peut être inefficace pour les grandes applications car il nécessite une comparaison exhaustive des valeurs à chaque changement.\n    \n2. **Observable-based** (ex : [[Svelte]], [[RxJS]]) :  \n    L'application s'abonne à des **Observables** (flux de données) et réagit aux changements de manière asynchrone. Cela permet d’optimiser la performance, mais rend le code plus complexe et sujet à des problèmes comme les fuites de mémoire si l'abonnement n'est pas correctement géré.\n    \n3. **Signal-based** (ex : [[Vue]],[[ Solid]], et [[Angular]]) :  \n    Les variables sont stockées avec des références uniques et chaque accès passe par une gestion centralisée des références. Ce modèle est performant et synchrone, mais il peut être plus contraignant en termes de structure du code. [[Angular]], par exemple, expérimente cette approche mais rencontre des difficultés dans son adoption.\n    \n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Observable-based** :\n    - Très performant pour les applications complexes et réactives.\n    - Permet de gérer des flux de données en temps réel avec une gestion fine des mises à jour.\n\n- **Signal-based** :\n    - Offre une réactivité plus synchrone, ce qui réduit les risques d'incohérences de données.\n    - Optimisation de la gestion des accès à des variables partagées.\n\n- **Value-based** :\n    - Facile à comprendre et à mettre en place, idéal pour des applications plus simples.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Observable-based** :\n    - Peut devenir difficile à gérer, surtout avec les abonnements et désabonnements, ce qui peut conduire à des fuites mémoire si mal géré.\n    - Asynchrone, ce qui complique la gestion du flux d'exécution et du débogage.\n\n- **Signal-based** :    \n    - Le modèle strict peut rendre le code moins flexible et plus difficile à maintenir.\n    - Angular a des difficultés à implémenter cette approche de manière fluide et standardisée.\n\n- **Value-based** :    \n    - Moins performant à grande échelle, nécessite de comparer chaque changement, ce qui peut ralentir les applications avec de nombreux éléments à surveiller.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "8a8d58b5-9071-4444-8711-dd893676ac39",
        "title": "Rôles dans l’architecture d’un SI",
        "shortDescription": "",
        "description": "---\nid: b5e075e4-d8ca-4274-997f-ec7a18462829\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLes rôles dans l’architecture d’un Système d'Information (SI) définissent les responsabilités et la gestion des pratiques techniques, allant de la définition des grandes lignes architecturales à l'implémentation technique dans les applications.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\n- **Architecte d'entreprise** : Définit les directives et normes architecturales à l'échelle globale du SI. Il s'assure de l'harmonisation des pratiques et de la cohérence entre les différents systèmes.\n    \n- **Architecte solution** : Applique les directives de l'architecte d'entreprise au niveau des applications spécifiques. Il s’assure que chaque solution réponde aux normes architecturales globales tout en répondant aux besoins des projets.\n    \n- **Architecte technique / Lead dev** : Gère les choix techniques et les décisions micro-niveau au sein des projets. Il assure la cohérence technique des solutions et prend des décisions détaillées pour résoudre des problèmes spécifiques dans le code.\n    \n- **Equipe de développement** : Suit les directives d’architecture et contribue aux discussions techniques. Les développeurs mettent en œuvre les choix décidés par les architectes dans le cadre des projets.\n    \n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Clarté des rôles** : Chaque acteur a une vision claire de ses responsabilités, ce qui permet une gestion structurée du SI.\n- **Harmonisation des pratiques** : Les décisions sont prises à différents niveaux, ce qui permet de respecter des standards tout en étant agile dans les projets.\n- **Collaboration entre les rôles** : Les architectes travaillent en étroite collaboration avec l’équipe de développement, assurant la mise en œuvre des directives avec une bonne prise en compte des réalités du terrain.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité hiérarchique** : Avec plusieurs niveaux d'architecture, la communication peut devenir plus complexe et les décisions peuvent être retardées.\n- **Risque de déconnexion entre les niveaux** : Si les architectes d’entreprise ne sont pas bien alignés avec les architectes solution, ou si les développeurs ne comprennent pas les directives, cela peut créer des incohérences dans l'implémentation.\n- **Charge de gestion** : Les architectes, notamment d'entreprise et solution, peuvent être submergés par des tâches de coordination et de contrôle, ce qui peut ralentir les processus.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]] [[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c6cf519c-fd09-44ee-a12a-bbef14ae767c",
        "title": "Server Side Generation (SSG)",
        "shortDescription": "",
        "description": "---\nid: cb7dd7c1-468d-46c0-8bc8-7bc4fc778f04\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLa **Server Side Generation (SSG)** consiste à générer des pages web statiques au moment de la compilation du projet, avant même le lancement du serveur. Les pages sont rendues sous forme de fichiers [[HTML]] prêts à être servis.\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe processus de SSG consiste à pré-générer toutes les pages d'un site pendant le processus de build, ce qui permet de les servir directement sous forme de fichiers statiques au moment de la demande de l'utilisateur. Le serveur ne fait plus que renvoyer ces fichiers [[HTML]] statiques, sans avoir besoin de calculer ou d'interagir avec une base de données à chaque requête.\n\n- **Génération statique** : Les pages sont rendues à la compilation du projet, ce qui accélère le temps de réponse du serveur.\n- **Pas d'interaction serveur** : Une fois les pages générées, le serveur sert directement les fichiers [[HTML]], ce qui réduit la charge côté serveur.\n- **[[SEO]] optimisé** : Puisque les pages sont déjà prêtes, les moteurs de recherche peuvent facilement les indexer.\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Performance rapide** : Les pages sont statiques, ce qui signifie que le serveur a juste à envoyer le fichier [[HTML]] sans traitement supplémentaire.\n- **[[SEO]] optimisé** : Le contenu statique est idéal pour l’indexation par les moteurs de recherche, augmentant ainsi la visibilité du site.\n- **Simplicité du serveur** : Aucune logique côté serveur, ce qui simplifie l’architecture du backend.\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Temps de compilation long** : Si le site possède de nombreuses pages, la génération statique peut être lente et consommer des ressources.\n- **Pas adapté au contenu dynamique** : Pour des sites nécessitant une mise à jour constante de contenu (par exemple des blogs ou des plateformes sociales), le SSG peut devenir peu pratique, car il faut recompiler les pages à chaque changement.\n- **Gestion des données** : Le contenu dynamique doit être géré avant la compilation, ce qui peut limiter l'interactivité des pages.\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Server Side Rendering (SSR)]] [[Incremental Static Regeneration (ISR)]] ",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "3a646b78-b3e7-42f5-a4d1-7963e2b48a0e",
        "title": "Server Side Rendering (SSR)",
        "shortDescription": "",
        "description": "---\nid: 3d88ac3a-ed12-451b-972e-c306b861b37d\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLe Server Side Rendering (SSR) est une technique où le serveur génère et envoie une page [[HTML]] presque complète au navigateur. Contrairement à du rendu côté client, c'est le serveur qui exécute le [[JavaScript]] et construit la page avant de l'envoyer au client.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe SSR permet de pré-rendre une page [[HTML]] complète côté serveur, incluant les ressources nécessaires (images, scripts, etc.), avant de la renvoyer au client. Le [[JavaScript]] côté client prend ensuite le relais pour l'[[hydratation]], c'est-à-dire pour rendre la page interactive. Cette approche améliore les performances initiales du chargement, car le navigateur n’a qu'à afficher la page générée, sans avoir à attendre que le [[JavaScript]] s'exécute pour créer le contenu.\n\nLe SSR est souvent utilisé avec des frameworks comme [[Next.js]] pour [[React]], [[Nuxt.js]] pour [[Vue.js]] ou [[Analog.js]] pour [[Angular]]\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Amélioration des performances initiales** : Le contenu est déjà pré-rendu, ce qui permet un affichage plus rapide.\n- **[[SEO]] optimisé** : Comme le contenu est disponible dès le chargement de la page, les moteurs de recherche peuvent mieux l'indexer.\n- **Expérience utilisateur améliorée** : Le temps jusqu'à l'affichage est plus court, surtout pour les utilisateurs ayant des connexions lentes.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Complexité côté serveur** : La gestion des sessions, du cache et du rendu dynamique est plus complexe à implémenter.\n- **[[Hydratation]]** : Après le rendu initial, le [[JavaScript]] côté client doit \"prendre le relais\" pour rendre la page interactive, ce qui peut entraîner un délai supplémentaire.\n- **Ressources serveur** : Plus de travail est effectué sur le serveur pour générer chaque page, ce qui peut augmenter la charge serveur et les coûts.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Server Side Generation (SSG)]][[Incremental Static Regeneration (ISR)]]\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "8c1b08b7-54d7-41a2-82f9-2f07277a619e",
        "title": "Signal (Angular)",
        "shortDescription": "",
        "description": "---\nid: 1b418003-bf67-4b2a-9a0f-955a4f39a7ad\n---\n# Rapidement c'est quoi❓\n\nSignal est un mécanisme de [[Réactivité]] intégré à [[Angular]] depuis la version 14, offrant une alternative plus simple et parfois plus performante à [[RxJS]] pour gérer les changements de données et déclencher des mises à jour d'interface.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAngular Signals fournit une nouvelle approche pour la gestion de la réactivité dans les applications Angular.  Au lieu de s'appuyer sur les Observables de [[RxJS]], il utilise un système plus léger et plus intuitif basé sur des \"signals\". Un signal est une référence à une valeur qui peut changer au cours du temps.  Lorsqu'une valeur de signal change, Angular détecte automatiquement cette modification et met à jour le DOM en conséquence.  Ceci permet de simplifier le code et d'améliorer les performances dans certains cas d'utilisation, notamment pour les mises à jour simples et fréquentes de données.\n\nLes composants clés sont :\n\n* **`signal()`:**  Fonction qui crée un signal à partir d'une valeur initiale.  Cette fonction retourne un objet possédant deux propriétés : `.value` (pour accéder à la valeur actuelle) et `.subscribe()` (pour s'abonner aux changements de valeur, similaire aux observables [[RxJS]] mais plus léger).\n* **`computed()`:** Fonction qui permet de créer des signals dérivés à partir d'autres signals.  La valeur d'un signal `computed` est recalculée automatiquement chaque fois qu'un des signals dont il dépend est mis à jour. Ceci est similaire aux opérateurs [[RxJS]] comme `map` ou `combineLatest` mais avec une syntaxe plus concise.\n* **`effect()`:** Fonction qui exécute une fonction chaque fois qu'un ou plusieurs signals dont elle dépend changent. Ceci permet de réagir aux changements de données et d'effectuer des actions secondaires, comme des appels API ou des navigations.\n\n\nL'utilisation de Signals est souvent plus concise et lisible que [[RxJS]] pour les cas simples de gestion de la réactivité.  Il est cependant important de comprendre que Signals ne remplacent pas complètement [[RxJS]], mais offrent une alternative intéressante pour certains types de problèmes.  [[RxJS]] reste pertinent pour les cas d'utilisation plus complexes nécessitant des opérations avancées de transformation et de gestion des flux d'événements asynchrones.\n\nLes signaux sont aussi utilisés par [[Vue.js]].\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Simplicité et lisibilité:** La syntaxe des Signals est plus concise et plus facile à comprendre que [[RxJS]], facilitant le développement et la maintenance.\n* **Performances:** Dans certains cas, les Signals peuvent offrir de meilleures performances que [[RxJS]], notamment pour les mises à jour fréquentes de données simples.\n* **Intégration native dans Angular:**  L'intégration transparente avec le framework Angular simplifie l'utilisation et évite les problèmes de compatibilité.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Moins puissant que [[RxJS]]:** Les Signals ne possèdent pas la même richesse fonctionnelle que RxJS.  Pour des scénarios complexes de manipulation de flux d'événements asynchrones, RxJS reste nécessaire.\n* **Relatif manque de maturité:**  Étant une fonctionnalité plus récente, la communauté et la documentation autour des Signals sont moins étendues que pour RxJS.\n* **Courbe d'apprentissage (même si faible) :**  Il faut un temps d'adaptation même si la syntaxe est plus simple.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "928cc68c-9624-4fe4-b1a1-69ee470283f5",
        "title": "Slim Faas",
        "shortDescription": "",
        "description": "---\nid: 8b302316-614f-4cea-af00-28858b4f0603\n---\n# Rapidement c'est quoi❓\n\nSlim Faas est une plateforme [[Function as a Service (FaaS)]] légère, alternative à [[OpenFaaS]], développée et utilisée en interne par AXA.  Elle se concentre sur la simplicité et l'efficacité.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSlim Faas est une implémentation simplifiée et optimisée de la plateforme serverless [[OpenFaaS]].  Contrairement à [[OpenFaaS]] qui offre une large gamme de fonctionnalités et de complexité, Slim Faas se concentre sur l'essentiel: le déploiement et l'exécution de fonctions sans serveur.  Elle est conçue pour être légère, facile à déployer et à maintenir, et particulièrement adaptée aux environnements où les ressources sont limitées ou où une configuration minimale est souhaitable.  Son architecture simplifiée réduit la surface d'attaque et la complexité de gestion.  Elle repose généralement sur des technologies conteneurisées (comme [[Docker]]) et un [[Orchestrateur de conteneur]] (comme [[Nomad]] ou [[Kubernetes]], bien que son architecture permette une plus grande flexibilité).  L'objectif principal est de fournir une solution serverless performante et facile à utiliser, sans les surcharges liées aux fonctionnalités plus avancées d'[[OpenFaaS]].  AXA l'utilise en interne, ce qui suggère une adoption pour des cas d'usage spécifiques nécessitant une solution plus légère et plus contrôlée.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Légèreté et simplicité:**  Sa conception minimaliste facilite le déploiement, la maintenance et la gestion.\n* **Efficacité:**  Optimisée pour les ressources limitées, elle consomme moins de ressources que les solutions plus complètes.\n* **Sécurité:**  La surface d'attaque réduite améliore la sécurité globale.\n* **Contrôle:**  AXA ayant développé la solution, le contrôle et l'adaptation à ses besoins spécifiques sont facilités.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Manque de fonctionnalités:**  Son approche minimaliste signifie l'absence de certaines fonctionnalités avancées présentes dans [[OpenFaaS]] (monitoring sophistiqué, gestion d'événements complexes, etc.).\n* **Documentation limitée:**  Étant une solution interne à AXA, la documentation publique est probablement limitée ou inexistante.\n* **Adoption limitée:**  Le manque de large adoption limite la communauté et le support disponible.\n* **Dépendance à AXA:**  Le futur et le maintien de la solution dépendent des priorités d'AXA.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_DevSecOps]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "0158b215-3c8b-4d22-b80a-0dbae9306a1c",
        "title": "Spring AOP",
        "shortDescription": "",
        "description": "---\nid: d1d0d5d0-ec94-4cb7-8dac-7b39d73a115b\n---\n## Rapidement, c'est quoi ? ❓\n\nSpring AOP ([[Aspect Oriented Programming (AOP)]]) est un framework [[Java]], basé sur [[Spring Framework]] qui permet d'ajouter des fonctionnalités transversales à une application sans modifier le code source principal.  Il permet de modulariser le code qui gère des préoccupations comme la journalisation, la sécurité, ou la gestion des transactions, en les séparant du code métier principal.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSpring AOP utilise un mécanisme de *[[Proxy]]* pour intercepter les appels de méthodes et exécuter du code additionnel avant, après, ou autour de l'appel de la méthode ciblée.  Ces morceaux de code additionnels sont appelés *aspects*.  Un aspect est défini par un ensemble de *conseils* (*advice*), qui spécifient quand et comment le code additionnel doit être exécuté.  Les points d'exécution de ces conseils sont définis par des *points de jonction* (*join points*), qui représentent des points spécifiques dans l'exécution du programme (par exemple, l'appel d'une méthode, la manipulation d'une exception).\n\nSpring AOP supporte différents types de conseils :\n\n* **Avant (Before):** Le code s'exécute avant l'appel de la méthode ciblée.\n* **Après (After):** Le code s'exécute après l'appel de la méthode ciblée, que celle-ci réussisse ou échoue.\n* **Après retour (After returning):** Le code s'exécute après l'appel de la méthode ciblée si celle-ci retourne une valeur avec succès.\n* **Après lancement d'exception (After throwing):** Le code s'exécute après l'appel de la méthode ciblée si celle-ci lance une exception.\n* **Autour (Around):** Le code s'exécute avant et après l'appel de la méthode ciblée, et permet de contrôler complètement l'exécution de la méthode.\n\n**Exemple utilisant annotations:**\n\n```java\nimport org.aspectj.lang.annotation.*;\nimport org.springframework.stereotype.Component;\n\n@Aspect\n@Component\npublic class LoggingAspect {\n\n    @Before(\"execution(* com.example.service.*.*(..))\")\n    public void beforeMethodExecution(JoinPoint joinPoint) {\n        System.out.println(\"Avant l'exécution de : \" + joinPoint.getSignature());\n    }\n\n    @AfterReturning(pointcut = \"execution(* com.example.service.*.*(..))\", returning = \"result\")\n    public void afterMethodExecution(JoinPoint joinPoint, Object result) {\n        System.out.println(\"Après l'exécution de : \" + joinPoint.getSignature() + \" - Résultat : \" + result);\n    }\n\n    @AfterThrowing(pointcut = \"execution(* com.example.service.*.*(..))\", throwing = \"exception\")\n    public void afterThrowing(JoinPoint joinPoint, Throwable exception) {\n        System.out.println(\"Exception levée lors de l'exécution de : \" + joinPoint.getSignature() + \" - Exception : \" + exception.getMessage());\n    }\n}\n```\n\nCet exemple utilise des expressions pointcut pour définir les méthodes à intercepter.  `execution(* com.example.service.*.*(..))` intercepte toutes les méthodes de tous les classes dans le package `com.example.service`.\n\nA la différence de [[AspectJ]], Spring AOP créer des proxy autour des objets afin d'ajouter les comportements voulu. Quand à lui [[AspectJ]], vient modifier directement les objets au démarrage de l'application. Le code est concret.\nLa différence se fait donc dans la porté offerte par les deux frameworks. [[AspectJ]] permet de toucher tout les fichiers (même ceux des librairies), tandis que Spring AOP va se restreindre aux beans (même porté que [[Spring Framework]]).\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Modularité:** Sépare les préoccupations transversales du code métier, améliorant la lisibilité et la maintenabilité.\n* **Réutilisabilité:** Les aspects peuvent être réutilisés dans différentes parties de l'application.\n* **Simplicité:**  L'intégration avec [[Spring Framework]] est simple et bien documentée.\n* **Pouvoir d'expression:** Les expressions Pointcut permettent de cibler précisément les méthodes à intercepter.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité potentielle:**  Pour des applications complexes, la configuration et la gestion des aspects peuvent devenir difficiles.\n* **Débogage:**  Le débogage peut être plus complexe en raison de l'utilisation des [[Proxy]].\n* **Performances:** L'utilisation des [[Proxy]] peut avoir un léger impact sur les performances, bien que généralement négligeable.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "9e434a98-3fa9-48e3-9369-8abea2e18897",
        "title": "Spring Boot Actuator",
        "shortDescription": "",
        "description": "---\nid: d8c7dbd9-13a6-477b-b02b-4905b243151c\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**Spring Boot Actuator** est un module de [[Spring Boot]] qui permet d'ajouter des fonctionnalités de gestion et de surveillance à une application, en exposant des **endpoints** pour récupérer des informations sur son état, ses métriques, sa santé, etc.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSpring Boot Actuator offre un ensemble d'**endpoints** accessibles via HTTP qui fournissent des informations sur la santé, les performances et la configuration de l’application en temps réel. Ces endpoints sont principalement utilisés pour :\n\n- **Surveillance** : Permet de suivre l'état de santé de l'application, ses métriques de performance, et la configuration environnementale.\n- **Gestion des logs** : Permet d'ajuster dynamiquement les niveaux de logs.\n- **Diagnostics** : Fournit des informations détaillées sur les threads ou la mémoire pour détecter des problèmes de performance.\n\nQuelques endpoints clés :\n\n- `/actuator/health` : Indique la santé de l’application.\n- `/actuator/metrics` : Expose les statistiques de performance (via [[Micrometer]]).\n- `/actuator/info` : Informations générales sur l'application.\n- `/actuator/env` : Détaille les propriétés d’environnement.\n- `/actuator/loggers` : Permet de gérer les niveaux de logs.\n- `/actuator/threaddump` : Affiche un dump des threads pour aider au diagnostic des problèmes de performance.\n- `/actuator/heapdump` : Permet de prendre un dump de la mémoire Java.\n\n**Important** : En production, il est crucial de sécuriser ou masquer certains endpoints pour éviter des risques de sécurité.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Surveillance facilitée** : Permet de suivre facilement l'état de l'application et d'effectuer des diagnostics.\n- **Intégration avec [[Prometheus]]** : Expose des métriques que [[Prometheus]] peut récupérer via `/actuator/metrics`, grâce à l'intégration avec **[[Micrometer]]**.\n- **Gestion dynamique des logs** : Permet de changer les niveaux de logs à chaud, ce qui facilite le débogage en production.\n- **Large gamme d'endpoints** : Fournit une variété d'informations (santé, performance, mémoire, etc.) pour un contrôle complet de l'application.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Sécurité** : Par défaut, les endpoints peuvent exposer des informations sensibles. Il est essentiel de les sécuriser en production.\n- **Performance** : L'ajout de plusieurs endpoints peut avoir un impact sur la performance, surtout s'ils sont mal configurés ou trop nombreux.\n- **Dépendance à [[Micrometer]]** : Pour certaines fonctionnalités comme les métriques, il est nécessaire d'intégrer [[Micrometer]], ce qui peut ajouter une couche de complexité.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [
            {
                "id": "41d14dd5-7fee-4aa0-9360-905da8579308",
                "front": "Quel est le rôle principal de Spring Boot Actuator et comment se fait l'accès à ses fonctionnalités ?",
                "back": "Spring Boot Actuator est un module permettant de surveiller et de gérer une application Spring Boot.  Il expose des endpoints (par exemple `/actuator/health`, `/actuator/metrics`) accessibles via HTTP pour récupérer des informations sur son état, ses métriques, sa santé, etc.",
                "easeFactor": 2.5,
                "interval": 10,
                "repetitions": 1,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-15T07:54:51.171",
                "nextReviewDate": "2025-04-15T08:05:01.694",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            },
            {
                "id": "c323161e-db3d-4cf9-8031-d148a5f1bfcd",
                "front": "Donnez deux exemples d'endpoints Actuator utiles pour le débogage et expliquez brièvement leur utilité.",
                "back": "- `/actuator/loggers`: Permet de modifier dynamiquement les niveaux de logs (DEBUG, INFO, WARN, ERROR) pour faciliter le débogage.\n- `/actuator/threaddump`:  Fournit un dump des threads en cours d'exécution, aidant à identifier les blocages ou les problèmes de performance.",
                "easeFactor": 2.5,
                "interval": 10,
                "repetitions": 1,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-15T07:54:51.171",
                "nextReviewDate": "2025-04-15T08:05:08.549",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            },
            {
                "id": "12591c8f-31fb-48a4-9792-fbe2841a25d4",
                "front": "Quelles sont les principales préoccupations en matière de sécurité et de performance lorsqu'on utilise Spring Boot Actuator ?",
                "back": "**Sécurité:** Les endpoints Actuator peuvent exposer des informations sensibles.  Il est crucial de les sécuriser en production (ex: via Spring Security) ou de les désactiver/masquer.\n**Performance:** Un grand nombre d'endpoints ou une mauvaise configuration peuvent impacter les performances de l'application.  Il est important de choisir judicieusement les endpoints activés et de les optimiser.",
                "easeFactor": 2.5,
                "interval": 10,
                "repetitions": 1,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-15T07:54:51.171",
                "nextReviewDate": "2025-04-15T08:05:10.447",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            }
        ],
        "base": false,
        "atomic": false
    },
    {
        "id": "7e4eec89-9862-487b-add2-797220c08b74",
        "title": "Spring Cloud Config",
        "shortDescription": "",
        "description": "---\nid: a725a0a3-511b-459b-a1d0-6f946cf0c527\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nSpring Cloud Config est un outil permettant de centraliser la gestion des configurations dans une architecture de [[Micros services]]. Il permet à tous les services de récupérer leurs configurations depuis un serveur centralisé.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSpring Cloud Config permet de centraliser les configurations de tous les [[Micros services]] d'une application dans un serveur de configuration. Ce serveur peut récupérer les configurations depuis divers fournisseurs (comme [[Git]] ou [[S3]]). Chaque [[Micros services]], à son démarrage, se connecte à ce serveur pour récupérer sa propre configuration, ce qui simplifie la gestion de configurations multiples et complexes dans une architecture distribuée.\n\n- Un serveur Spring Cloud Config est mis en place en ajoutant une dépendance et en activant `@EnableConfigServer` sur la classe de démarrage.\n- Le serveur peut récupérer des configurations depuis des sources comme [[Git]], avec un format spécifique de fichiers (`application.yml`, `application.properties`).\n- Chaque [[Micros services]] client récupère sa configuration via un URL spécifique en fonction de son nom, de son profil et de son label [[Git]].\n\nLes configurations sont versionnées et gérées comme du code, permettant de bénéficier d'un suivi et de la réversibilité.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Centralisation des configurations** : Une seule source pour gérer toutes les configurations des [[Micros services]], ce qui simplifie la maintenance.\n- **Versioning** : Utiliser [[Git]] pour stocker les configurations permet de versionner, suivre l'historique et revenir à des versions précédentes facilement.\n- **Flexibilité des sources de configuration** : Supporte divers fournisseurs comme [[Git]], [[S3]], ce qui permet de s’adapter à différents environnements.\n- **Simplicité d'intégration** : L'intégration dans [[Spring Boot]] se fait via de simples dépendances et annotations.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Dépendance au serveur de configuration** : Si le serveur de configuration tombe, les services ne pourront plus récupérer leurs configurations.\n- **Complexité de mise en place** : Bien que la configuration de base soit simple, la gestion de multiples profils et labels [[Git]] peut compliquer la configuration des services.\n- **Scalabilité du serveur** : Il est important de mettre en place des réplicas du serveur pour garantir la disponibilité, mais cela peut ajouter de la complexité.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d022bf8a-c96a-4f14-90a3-ae8cb7ad7e26",
        "title": "Certification Java 17 - Streams et Expressions Lambda",
        "shortDescription": "",
        "description": "---\nid: 4278c6cd-387f-47f0-a011-d5c10f9d1b1c\n---\n## **8.1. Utilisation des `Stream<T>`, `IntStream`, `DoubleStream`**\n\nUn **Stream** est une séquence d’éléments pouvant être traitée de manière déclarative et fonctionnelle.\n\n|**Type**|**Description**|\n|---|---|\n|`Stream<T>`|Flux d’objets génériques|\n|`IntStream`|Flux de `int` (évite l’auto-boxing)|\n|`DoubleStream`|Flux de `double`|\n|`LongStream`|Flux de `long`|\n\n### **Création d’un `Stream`**\n\n```java\nimport java.util.stream.*;\n\nList<String> noms = List.of(\"Alice\", \"Bob\", \"Charlie\");\nStream<String> stream = noms.stream();\nstream.forEach(System.out::println);\n```\n\n\uD83D\uDCCC **Un `Stream` ne peut être consommé qu’une seule fois.**\n\n---\n\n### **Utilisation des `IntStream`, `DoubleStream`**\n\n```java\nIntStream.range(1, 5).forEach(System.out::print); // 1234\nDoubleStream.of(3.14, 2.71, 1.41).forEach(System.out::println);\n```\n\n\uD83D\uDCCC **`range(1,5)` génère `{1, 2, 3, 4}` (exclut `5`), `rangeClosed(1,5)` inclut `5`.**\n\n---\n\n## **8.2. `filter()`, `map()`, `reduce()`, `collect()`**\n\n### **1. `filter()` : Sélectionne les éléments correspondant à une condition**\n\n```java\nList<String> noms = List.of(\"Alice\", \"Bob\", \"Charlie\");\nList<String> resultat = noms.stream()\n    .filter(n -> n.startsWith(\"A\"))\n    .toList(); // Java 16+\nSystem.out.println(resultat); // [Alice]\n```\n\n---\n\n### **2. `map()` : Transforme les éléments**\n\n```java\nList<Integer> longueurs = noms.stream()\n    .map(String::length)\n    .toList();\nSystem.out.println(longueurs); // [5, 3, 7]\n```\n\n\uD83D\uDCCC **`map()` applique une fonction à chaque élément du `Stream`.**\n\n---\n\n### **3. `reduce()` : Réduction des éléments à une seule valeur**\n\n```java\nint somme = IntStream.of(1, 2, 3, 4)\n    .reduce(0, Integer::sum);\nSystem.out.println(somme); // 10\n```\n\n\uD83D\uDCCC **Permet de combiner les éléments (somme, multiplication, concaténation, etc.).**\n\n---\n\n### **4. `collect()` : Transformer un `Stream` en collection**\n\n```java\nList<String> listeMaj = noms.stream()\n    .map(String::toUpperCase)\n    .collect(Collectors.toList());\nSystem.out.println(listeMaj); // [ALICE, BOB, CHARLIE]\n```\n\n\uD83D\uDCCC **`collect()` permet de rassembler les éléments dans une `List`, `Set` ou `Map`.**\n\n---\n\n## **8.3. Décomposition, concaténation, partitionnement**\n\n### **1. `flatMap()` : Décomposition d’éléments imbriqués**\n\n```java\nList<List<Integer>> listOfLists = List.of(List.of(1, 2), List.of(3, 4));\nList<Integer> flattenedList = listOfLists.stream()\n    .flatMap(List::stream)\n    .toList();\nSystem.out.println(flattenedList); // [1, 2, 3, 4]\n```\n\n\uD83D\uDCCC **`flatMap()` aplatit plusieurs collections en un seul `Stream`.**\n\n---\n\n### **2. Concaténation de `Stream`**\n\n```java\nStream<String> s1 = Stream.of(\"A\", \"B\");\nStream<String> s2 = Stream.of(\"C\", \"D\");\n\nStream<String> concatStream = Stream.concat(s1, s2);\nconcatStream.forEach(System.out::print); // ABCD\n```\n\n\uD83D\uDCCC **`Stream.concat(s1, s2)` fusionne deux flux.**\n\n---\n\n### **3. Partitionnement (`partitioningBy`)**\n\n```java\nMap<Boolean, List<String>> partition = noms.stream()\n    .collect(Collectors.partitioningBy(n -> n.length() > 3));\n\nSystem.out.println(partition);\n// {false=[Bob], true=[Alice, Charlie]}\n```\n\n\uD83D\uDCCC **Retourne deux groupes : ceux qui respectent la condition (`true`) et les autres (`false`).**\n\n---\n\n## **8.4. Streams Séquentiels et Parallèles**\n\n### **1. `parallelStream()` : Exécution multi-thread**\n\n```java\nList<String> noms = List.of(\"Alice\", \"Bob\", \"Charlie\");\nnoms.parallelStream()\n    .forEach(System.out::println); // Exécution parallèle\n```\n\n\uD83D\uDCCC **Peut améliorer les performances sur des collections volumineuses.**\n\n### **2. `parallel()` sur un `Stream` existant**\n\n```java\nnoms.stream()\n    .parallel()\n    .forEach(System.out::println);\n```\n\n\uD83D\uDCCC **Attention aux opérations dépendant de l’ordre !**\n\n---\n\n## **Résumé**\n\n✅ **Création de `Stream<T>`, `IntStream`, `DoubleStream`**  \n✅ **Opérations `filter()`, `map()`, `reduce()`, `collect()`**  \n✅ **Décomposition (`flatMap`), concaténation, partitionnement**  \n✅ **Utilisation des `Streams` séquentiels et parallèles**\n\n---",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c52446cb-bd97-4c08-a19f-20ea2a450b58",
        "title": "Supprimer des fichiers sensibles pousser sur un repository",
        "shortDescription": "",
        "description": "---\nid: 80596fd6-1ff6-4512-8919-fe89db6b5c22\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\n**Supprimer des fichiers sensibles poussés sur un repo** consiste à retirer des fichiers contenant des informations sensibles (comme des mots de passe ou des clés API) qui ont été accidentellement poussés dans un dépôt [[Git]]. Pour cela, des outils comme `git-filter-branch` ou `bfg-repo-cleaner` permettent de nettoyer l'historique du dépôt.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\n- **git-filter-branch** : Outil intégré à Git qui permet de réécrire l'historique d'un dépôt en supprimant des fichiers ou des répertoires spécifiques, ainsi que toutes leurs traces dans l’historique des commits.\n    \n- **bfg-repo-cleaner** : Outil tiers écrit en Scala, conçu spécifiquement pour nettoyer un dépôt Git en supprimant rapidement des fichiers ou des objets (comme des clés API) qui ne doivent pas être présents. Il est plus rapide et plus simple que `git-filter-branch` et peut être étendu en Scala si nécessaire.\n    \n\nExemples de commandes avec BFG :\n\n- `bfg --delete-files id_{dsa,rsa} my-repo.git` : Supprime les fichiers de type id_dsa et id_rsa.\n- `bfg --strip-blobs-bigger-than 50M my-repo.git` : Supprime les fichiers de plus de 50 Mo.\n- `bfg --replace-text passwords.txt my-repo.git` : Remplace les mots contenus dans un fichier texte (par exemple des mots de passe) dans tout l'historique.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **BFG est plus rapide** : Par rapport à `git-filter-branch`, il est plus rapide et plus efficace, surtout pour les gros dépôts.\n- **Simplicité** : BFG est conçu uniquement pour la suppression de fichiers sensibles, rendant son usage plus direct et moins complexe que `git-filter-branch`.\n- **Extensible** : Étant écrit en Scala, il est possible de l’adapter à des besoins spécifiques.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **git-filter-branch plus flexible** : Bien que BFG soit plus rapide, `git-filter-branch` reste plus flexible pour les tâches complexes nécessitant une réécriture d’historique plus fine.\n- **Pas de protection native contre les fichiers déjà clonés** : La suppression dans l'historique ne les retire pas des copies locales déjà clonées du dépôt. Il est donc nécessaire d'informer les autres contributeurs pour éviter qu'ils ne poussent à nouveau ces fichiers sensibles.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "3926e5c7-d157-433e-b410-32b6cfcc9a63",
        "title": "Test Driven Developpement (TDD)",
        "shortDescription": "",
        "description": "---\nid: ff0f5989-5d86-4a56-aeed-d3be0809cc54\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi ❓\n\nLe **TDD** (Test Driven Development) est une méthode de développement (Et pas simplement une stratégie de test) où les tests sont écrits avant le code. Contrairement aux méthodes classiques où les tests viennent après le développement, le TDD place les tests au centre du processus pour garantir un code de meilleure qualité.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\n## Cycle du TDD\nLe TDD suit un cycle itératif en trois étapes :\n\n1. **Écrire un test qui échoue** : On commence par créer un test qui vérifie un comportement spécifique, sachant qu'il échouera au départ.\n2. **Écrire le minimum de code pour faire passer le test** : Ensuite, on rédige juste assez de code pour que le test passe, sans chercher à le rendre complexe.\n\t- C'est super important de faire des baby steps. C'est comme ça qu'on arrive à la meilleure conception. Il faut éviter de trop anticiper la conception.\n3. **Refactoriser le code** : Une fois que le test passe, on améliore et optimise le code tout en s’assurant qu’il reste fonctionnel (les tests passent toujours).\n\nLe processus permet d'améliorer la qualité du code de manière incrémentale et de rendre la conception plus simple et fiable.\nOn va clairement moins s'emmerder, et rendre le code plus fiable et plus simple.\nIl est très important de soigner autant le code de test que le code de prod, si on veut qu'ils puissent être maintenable.\n\n## Ecoles de TDD\n### Chicago/Detroit School :\n- Ces écoles sont parfois considérées comme des variantes de la **TDD classique** mais avec une approche plus stricte et plus disciplinée dans l'application du processus.\n- Les partisans de ces écoles insistent sur l'importance de ne **jamais écrire de code** qui n’a pas d'abord été testé. Leurs pratiques privilégient la simplicité et la rigueur dans le respect du cycle TDD (écrire un test, coder, refactoriser).\n- L'accent est mis sur un **code très testé**, mais parfois au prix d'une mise en œuvre plus rigide de la méthode.\n### London School :    \n- La **London School** adopte une approche plus souple et pragmatique du TDD.\n- Elle met l'accent sur l’importance d'écrire des tests qui sont facilement compréhensibles et utiles à long terme. Plutôt que de se concentrer strictement sur la couverture de test, cette école encourage à **distinguer les tests utiles des tests superflus**.\n- L’idée est de faire en sorte que le processus soit **adaptable au projet**, en fonction des besoins réels.\n### Le style Ian Cooper :\n- Ian Cooper, un défenseur du **TDD moderne**, met l'accent sur l’application du TDD pour une **architecture propre et évolutive**.\n- Il insiste sur l'importance de tester des **unités de travail cohérentes et isolées**, et de se concentrer sur des tests qui correspondent vraiment à l’intention et à la conception du système.\n- Son style met en avant la pratique de **ne pas tester à outrance** et de bien définir les limites des tests pour garantir qu'ils aient un impact réel sur la qualité du code.\n### Diamond TDD :\n- Le **Diamond TDD** est une approche qui introduit une **flexibilité dans le cycle TDD** traditionnel, en adoptant une structure en forme de diamant.\n- Ce style combine **refactoring, test et développement** en fonction des besoins du projet et du code, plutôt que de suivre rigoureusement les étapes linéaires de TDD classique. L'idée est de **réévaluer constamment la conception** et les tests pour trouver un équilibre optimal.\n- Il s'agit d'une approche plus dynamique, où le développement et les tests ne sont pas forcément réalisés dans un ordre strict, mais peuvent s'adapter en fonction des retours immédiats.\n\n## Documentation as code\nIl est possible d'utiliser le TDD comme d'une documentation fonctionnelle. Pour cela on va pouvoir utiliser l'[[Ubiquitous Language]] du projet afin de n'importe qui puisse comprendre les spécificités de la fonctionnalité.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Documentation vivante** : Les tests servent de documentation dynamique, qui est mise à jour en fonction des évolutions du code. Si un test échoue, cela indique qu’une modification est nécessaire, ce qui aide à suivre l’évolution du code et à préserver les exigences métiers.\n- **Sécurité lors du refactoring** : Le TDD offre un filet de sécurité, ce qui permet de modifier le code ou de le refactoriser sans risque de régression, car les tests signalent rapidement les erreurs introduites.\n- Force à rendre son code testable. On créant des abstractions sur les dépendances afin de les mocker ou de créer des stubs (en fonction de l'école).\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Processus contraignant au départ** : L'écriture des tests avant le code peut sembler difficile et ralentir initialement le développement.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Testing]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a39dfca8-2229-4e91-90f6-1230c3170a4b",
        "title": "Test de mutation",
        "shortDescription": "",
        "description": "---\nid: 344bca62-9704-4c85-9b12-7e21128579e2\ntags: \"\"\ncreated: 2025-02-03\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLe test de mutation est une technique utilisée pour évaluer la qualité des [[Test unitaire]]. Il consiste à introduire des mutations (modifications) dans le code et à vérifier si les tests échouent. Si un test passe après la mutation, cela signifie que le test n'est pas suffisamment précis pour détecter les erreurs.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\n- **But** : Vérifier l'efficacité des [[Test unitaire]] en s'assurant qu'ils détectent bien les changements dans le code.\n- **Mutations** : Ce sont des modifications systématiques dans le code, comme changer un opérateur, inverser une condition, ou supprimer une instruction.\n- **Processus** :\n    1. Vérification de la validité des [[Test unitaire]] existants.\n    2. Application de mutations sur le code.\n    3. Exécution des [[Test unitaire]] sur les mutants générés.\n- **Analyse** : Si un test passe malgré une mutation, cela indique que le test est incomplet ou trop laxiste. L'objectif est que tous les mutants échouent, ce qui montre que le test est robuste.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Améliore la couverture des tests** : Permet de s'assurer que les tests couvrent réellement tous les cas possibles.\n- **Identifie les tests inefficaces** : Permet de repérer les tests qui ne détectent pas les erreurs dans le code.\n- **Renforce la qualité du code** : En améliorant les tests, la qualité globale du projet est améliorée.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Consommation de ressources** : Générer et tester des mutants peut être coûteux en termes de temps et de ressources.\n- **Peut donner des faux positifs** : Si le pool de mutations est mal conçu, certains mutants peuvent passer, faussant ainsi l'évaluation de la qualité des tests.\n- **Complexité** : La mise en place d'un test de mutation nécessite une bonne configuration et peut être complexe à intégrer dans le flux de travail de développement.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Testing]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "66b6af95-a52b-458d-8494-57219fc88ff9",
        "title": "Testinfra",
        "shortDescription": "",
        "description": "---\nid: 6697390d-2ee4-497d-9f15-9728cd165ca0\n---\n# Rapidement c'est quoi❓\n\nTestinfra est un framework de [[Test d'infrastructure]] basé sur [[Python]]. Il permet de vérifier l'état de vos serveurs et de votre infrastructure en exécutant des tests écrits en [[Python]] simple et lisible.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nTestinfra est un outil puissant pour l'automatisation des [[Test d'infrastructure]].  Il fonctionne en se connectant à des machines distantes (via [[SSH]], [[WinRM]], etc.) et en exécutant des assertions sur l'état du système.  Au lieu de dépendre de commandes spécifiques à un système d'exploitation ou à un outil de provisionnement, Testinfra utilise les modules [[Python]] standard et les modules spécifiques à l'infrastructure pour interagir avec le système cible.  Cela assure une grande portabilité et une simplification du processus de test.\n\nLes tests sont écrits en Python et utilisent une syntaxe simple et intuitive.  On peut tester une variété de choses, incluant :\n\n* **Présence de fichiers et de dossiers:** Vérifier si un fichier existe, s'il est lisible, s'il a les permissions appropriées.\n* **Services système:** Vérifier si un service est en marche, arrêté, ou en cours de redémarrage.\n* **Packages logiciels:** Vérifier si un package est installé, sa version, etc.\n* **Ports réseau:** Vérifier si un port est ouvert ou fermé.\n* **Contenu de fichiers de configuration:** Vérifier la présence de lignes spécifiques dans un fichier de configuration.\n* **Commandes système:** Exécuter des commandes et valider leur sortie.\n* **Utilisateurs et groupes:** Vérifier l'existence et les permissions des utilisateurs et des groupes.\n\n\nTestinfra s'intègre facilement dans les [[pipelines CI/CD]] et permet de valider l'état de votre infrastructure de manière automatisée et fiable.  Il est particulièrement utile pour le test d'[[Infra as Code (IaC]] en permettant de vérifier que l'infrastructure provisionnée correspond bien à la configuration souhaitée.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Simplicité et lisibilité:** Les tests sont écrits en Python, ce qui les rend faciles à écrire, à lire et à maintenir.\n* **Portabilité:** Fonctionne sur plusieurs systèmes d'exploitation ([[Linux]], [[Windows]], [[macOS]]) et utilise un langage de test indépendant des outils de provisionnement.\n* **Intégration CI/CD:** S'intègre facilement dans les [[pipelines CI/CD]].\n* **Large couverture:** Permet de tester une grande variété d'aspects de l'infrastructure.\n* **Basé sur [[Python]]:**  Tire parti de l'écosystème riche de [[Python]] et de ses librairies.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:** Nécessite une connaissance de base de [[Python]].\n* **Dépendance à [[Python]]:**  Fonctionne uniquement avec [[Python]].\n* **Débogage:** Le débogage des tests peut être plus complexe que avec certains outils spécifiques.  (Cependant, les capacités de débogage de [[Python]] restent disponibles)\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Testing]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "87ba0245-8bf1-4701-ade6-2b36a270bc94",
        "title": "Unité responsive css",
        "shortDescription": "",
        "description": "---\nid: 26571386-fada-49d8-b94c-b71bcd74cc84\ntags: \"\"\ncreated: 2025-01-22\nupdated: 2025-02-03\n---\n# Rapidement c'est quoi❓\n\nLes unités responsive [[CSS]] permettent de définir des tailles relatives en fonction de la taille du viewport, c’est-à-dire la fenêtre d'affichage. Elles sont particulièrement utiles pour les designs fluides et adaptatifs sur différents appareils.\n\n---\n\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\n- **`vh` (viewport height)** : Représente 1% de la hauteur du viewport. Par exemple, `100vh` occupe toute la hauteur de l'écran.\n- **`vw` (viewport width)** : Représente 1% de la largeur du viewport. Par exemple, `100vw` occupe toute la largeur de l'écran.\n- **`lvh` (large viewport height)** : Unité relative à la hauteur du \"grand viewport\". Elle est stable et ignore les variations dues à la barre d'adresse des appareils mobiles.\n- **`svh` (small viewport height)** : Représente la hauteur en excluant les éléments qui se cachent (comme la barre d'adresse sur mobile), utile pour un redimensionnement plus stable.\n- **`dvh` (dynamic viewport height)** : Similaire à `lvh` et `svh`, mais prend en compte les changements dynamiques du viewport dus à l’orientation ou des événements d’interface utilisateur.\n- **`vmin` (viewport minimum)** : Représente la plus petite des valeurs entre `vh` et `vw`, pour maintenir une proportion uniforme entre la largeur et la hauteur du viewport, quel que soit l'orientation de l'appareil.\n\n---\n\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n- **Adaptabilité** : Ces unités permettent de créer des interfaces qui s'ajustent automatiquement à la taille du viewport, rendant le design plus flexible.\n- **Stabilité sur mobile** : Les unités comme `lvh`, `svh`, et `dvh` sont spécialement conçues pour gérer les variations de taille sur les appareils mobiles, offrant une expérience utilisateur plus prévisible.\n- **Proportions cohérentes** : `vmin` permet de maintenir des proportions constantes entre la largeur et la hauteur du viewport, quelle que soit l'orientation de l'écran.\n\n---\n\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n- **Problèmes de compatibilité** : Certaines unités comme `lvh`, `svh`, et `dvh` peuvent ne pas être supportées de manière uniforme dans tous les navigateurs, surtout dans les versions plus anciennes.\n- **Complexité accrue** : Utiliser plusieurs unités responsive dans un même projet peut ajouter de la complexité, et il faut tester minutieusement pour s'assurer de la cohérence sur tous les appareils.\n- **Incertitude sur les mobiles** : Le comportement de certaines unités (notamment `vh` et `vw`) peut être affecté par des éléments de l'interface (barre d’adresse ou navigation), rendant les tailles moins fiables.\n\n---\n\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "1ff270c7-4a18-4105-9d25-25da9d598351",
        "title": "VitePress",
        "shortDescription": "",
        "description": "---\nid: b9f8677a-eceb-429a-8172-e5dea5e9833b\n---\n# Rapidement c'est quoi❓\n\nVitePress est un générateur de site statique [[Server Side Generation (SSG)]] basé sur [[Vite]] et [[Vue.js]].  Il permet de créer rapidement et facilement des sites web, notamment des documentations.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nVitePress est un générateur de site statique qui tire parti de la vitesse et des performances de [[Vite]], un serveur de développement rapide et un outil de construction.  Il utilise [[Vue.js]] pour le rendu des pages, permettant de créer des sites web dynamiques et interactifs malgré la nature statique du résultat final.  Contrairement à des générateurs de sites statiques plus traditionnels, VitePress offre un processus de développement plus rapide grâce à l'utilisation de Hot Module Replacement (HMR).  Cela signifie que les modifications de code sont instantanément reflétées dans le navigateur sans nécessiter un rechargement complet de la page.  Il est particulièrement bien adapté à la création de documentations, car il offre des fonctionnalités intégrées pour la gestion de la navigation, la recherche, et le déploiement.  Le système de fichiers est utilisé pour structurer le contenu, ce qui facilite la gestion et la maintenance du site.  La configuration est minimale, rendant VitePress accessible même aux développeurs peu expérimentés avec [[Vue]].  Il fournit également des thèmes par défaut personnalisables.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Rapidité de développement:** Le HMR de Vite permet un cycle de développement extrêmement rapide.\n* **Facilité d'utilisation:** Configuration simple et intuitive, idéale pour les débutants en [[Vue.js]].\n* **Intégration avec [[Vue.js]]:** Permet de tirer parti de la puissance et de la flexibilité de [[Vue.js]].\n* **Performance:** Les sites générés sont optimisés pour la vitesse de chargement.\n* **Bon pour la documentation:**  Fonctionnalités intégrées facilitant la création de documentations.\n* **Système de theming:** Permet une personnalisation facile de l'apparence du site.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Moins flexible que des solutions plus complexes:**  Peut manquer de flexibilité pour des projets très spécifiques ou complexes.  Les options de personnalisation, bien que présentes, sont plus limitées que des solutions plus généralistes.\n* **Écosystème moins large que d'autres [[Server Side Generation (SSG)]]:**  La communauté et les plugins disponibles sont moins nombreux que pour des SSG plus matures comme [[Astro]], [[Gatsby]] ou [[Hugo]].\n* **Dépendance à Vue.js:**  Si vous n'êtes pas familier avec Vue.js, il faudra apprendre à l'utiliser.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Dev]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "73b8a1b5-01f0-4e3f-a721-f5ba47faef97",
        "title": "pg_vector",
        "shortDescription": "",
        "description": "---\nid: 77c31383-8845-47ff-89f1-44766cf8f9b3\n---\n# Rapidement c'est quoi❓\n\npg_vector est une extension pour le système de gestion de base de données [[PostgreSQL]] permettant d'indexer et de rechercher des vecteurs.  Cela facilite la mise en œuvre de la recherche sémantique et des systèmes de recommandation au sein d'une [[Base de donnée]].\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\npg_vector est une extension open-source pour [[PostgreSQL]] qui ajoute la capacité de stocker et de rechercher efficacement des vecteurs de données.  Ces vecteurs, généralement créés par des modèles d'apprentissage automatique (embeddings), représentent des informations sémantiques (texte, images, audio, etc.).  L'extension fournit un type de données dédié (`vector`), des opérateurs et des index spécifiques pour optimiser les requêtes de recherche de similarité.\n\nLe cœur de pg_vector réside dans ses capacités de recherche par similarité.  Au lieu de rechercher des correspondances exactes, il permet de trouver les vecteurs les plus proches d'un vecteur donné, en utilisant des métriques de distance comme la distance euclidienne ou la distance cosinus.  Cette approche est cruciale pour les applications de recherche sémantique, où l'objectif est de trouver des éléments similaires en termes de signification, même si les mots clés ne correspondent pas parfaitement.\n\nL'extension gère l'indexation des vecteurs, ce qui permet des recherches rapides et efficaces même sur de grands ensembles de données.  Les index utilisés optimisent la recherche en espace vectoriel, réduisant le temps de traitement et améliorant les performances.  Elle fournit également des fonctions pour calculer les distances entre les vecteurs et pour effectuer des recherches à l'aide de ces distances.\nCette extension permet de convertir [[PostgreSQL]] en une [[Base de donnée vectorielle]], idéal pour la création de [[RAG]] dans les [[Large Language Model (LLM)]].\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Intégration native avec [[PostgreSQL]]:**  Pas besoin d'une solution externe complexe.  Tout est géré au sein de la base de données.\n* **Performances:**  L'utilisation d'index optimisés permet des recherches rapides et efficaces, même sur de très grands ensembles de données vectorisées.\n* **[[Open-source]] et communauté active:**  Accès au code source, contribution possible et communauté pour le support.\n* **Simplicité d'utilisation:**  Relativement facile à installer et à utiliser, même pour ceux qui ne sont pas experts en bases de données.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Limité à [[PostgreSQL]]:**  L'extension ne fonctionne qu'avec PostgreSQL.  L'utilisation avec d'autres bases de données nécessite une solution alternative.\n* **Dépendance aux modèles d'apprentissage automatique:**  Nécessite de générer des vecteurs à l'aide de modèles externes.  L'extension ne fournit pas de fonctionnalité de création de vecteurs.\n* **Complexité potentielle pour des applications très spécifiques:**  La configuration optimale des index et le choix de la métrique de distance peuvent nécessiter une expertise technique.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[Base de donnée SQL]]",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "bc62b3e7-b04a-4d75-8ed7-1d1b2693304f",
        "title": "vLLM",
        "shortDescription": "",
        "description": "---\nid: fb7bce3a-8584-449e-8086-fa44d07ff590\n---\n# Rapidement c'est quoi❓\n\nvLLM est un outil permettant de déployer rapidement et facilement de grands modèles de langage ([[Large Language Model (LLM)]]) sous forme d'API web compatible avec l'API d'[[OpenAI]].  Cela permet d'utiliser les SDK OpenAI existants avec des modèles LLM personnalisés.\n\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nvLLM est une infrastructure [[Open-source]] conçue pour servir des modèles de langage volumineux (LLMs) via une API [[RESTful]] imitant celle d'OpenAI.  Au lieu de devoir construire une infrastructure complexe de serveurs et de gérer la mise à l'échelle, vLLM permet de déployer un LLM existant (entraîné préalablement) et de le rendre accessible via une interface simple et standardisée.  L'avantage clé réside dans la compatibilité avec les SDK OpenAI : les applications existantes qui utilisent l'API OpenAI peuvent fonctionner sans modification majeure avec un LLM déployé via vLLM, simplement en changeant l'URL de l'API.  vLLM gère la mise en mémoire du modèle, le parallélisme des requêtes, et optimise les performances pour servir efficacement des requêtes d'inférence (générer du texte, répondre à des questions, etc.).  Il est généralement utilisé avec des modèles quantifiés pour réduire la taille mémoire nécessaire et améliorer les performances.  Il propose différents modes de service (ex : serveur unique, serveur distribué) pour s'adapter aux besoins en ressources et au volume de requêtes.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Compatibilité OpenAI:**  Permet une transition facile vers des LLM personnalisés sans modifier le code client.\n* **Simplicité de déploiement:**  Facilite le processus de mise en production d'un LLM, simplifiant l'infrastructure nécessaire.\n* **Performances:** Optimisé pour gérer les requêtes d'inférence efficacement, même avec des modèles volumineux.\n* **Open-source:** Accessible, modifiable et améliorable par la communauté.\n* **Scalabilité:**  Possibilité de déploiement sur des serveurs multiples pour une meilleure gestion des charges importantes.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité initiale (potentielle):** Bien que visant la simplicité, la configuration et le déploiement initiaux peuvent nécessiter une certaine expertise technique, notamment en ce qui concerne la gestion des modèles et des ressources.\n* **Dépendances:** Nécessite des bibliothèques spécifiques et un environnement d'exécution adapté.\n* **Ressources:**  Le déploiement de grands modèles nécessite des ressources matérielles importantes (RAM, GPU).\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n[[Intelligence Artificielle]]\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "69136136-c910-4337-baa8-695b2bdbcf2e",
        "title": "",
        "shortDescription": "",
        "description": "# Gestion des Exceptions en Java\n\nCette note détaille la gestion des exceptions en Java, un mécanisme crucial pour la robustesse et la fiabilité des applications.  Une bonne gestion des exceptions permet d'anticiper et de traiter les erreurs de manière élégante, empêchant ainsi des plantages inattendus.\n\n## 1. Qu'est-ce qu'une exception ?\n\nUne exception est un événement qui interrompt le flux normal d'exécution d'un programme.  Elle survient généralement lorsqu'une erreur se produit, comme une tentative d'accès à un fichier inexistant, une division par zéro, ou une erreur réseau.  En Java, les exceptions sont des objets qui héritent de la classe `Throwable`.\n\n## 2. Types d'exceptions\n\nJava distingue deux grands types d'exceptions :\n\n* **Exceptions vérifiées (checked exceptions):**  Le compilateur Java impose la gestion de ces exceptions.  Si une méthode peut lever une exception vérifiée,  elle doit soit la gérer avec un bloc `try-catch`, soit la déclarer dans sa signature à l'aide du mot-clé `throws`.  Exemples : `IOException`, `SQLException`.\n\n* **Exceptions non vérifiées (unchecked exceptions):**  Le compilateur ne force pas leur gestion explicite.  Ce sont généralement des erreurs de programmation (ex: `NullPointerException`, `IndexOutOfBoundsException`, `ArithmeticException`). Elles sont souvent le signe d'un bug dans le code.  [Concepts de Base en Java]\n\n## 3. Gestion des exceptions avec `try-catch`\n\nLe mécanisme principal pour gérer les exceptions est le bloc `try-catch`.  Le code susceptible de lever une exception est placé dans le bloc `try`.  Si une exception survient, le programme saute au bloc `catch` correspondant au type d'exception.\n\n```java\ntry {\n    // Code susceptible de lever une exception\n    int result = 10 / 0; // Division par zéro\n    System.out.println(\"Résultat : \" + result);\n} catch (ArithmeticException e) {\n    // Gestion de l'exception ArithmeticException\n    System.err.println(\"Erreur : Division par zéro !\");\n    e.printStackTrace(); // Affiche le détails de l'exception dans la console\n}\n```\n\nDans cet exemple, la division par zéro lève une `ArithmeticException`. Le bloc `catch` correspondant intercepte l'exception, affiche un message d'erreur, et utilise `e.printStackTrace()` pour afficher la pile d'appels, utile pour le débogage.\n\n\n## 4.  Gestion de plusieurs exceptions\n\nUn bloc `try` peut être suivi de plusieurs blocs `catch` pour gérer différents types d'exceptions. L'ordre des blocs `catch` est important : les exceptions les plus spécifiques doivent être traitées avant les exceptions plus générales (car les classes filles sont traitées avant leurs classes mères).\n\n```java\ntry {\n    // ...\n} catch (IOException e) {\n    // Gestion d'une IOException\n} catch (SQLException e) {\n    // Gestion d'une SQLException\n} catch (Exception e) { // Exception générale, à utiliser en dernier recours\n    // Gestion d'autres exceptions\n}\n```\n\n\n## 5. Le bloc `finally`\n\nLe bloc `finally` est optionnel et contient du code qui s'exécute toujours, que l'exception soit levée ou non.  Il est souvent utilisé pour libérer des ressources (fermer des fichiers, des connexions à une base de données, etc.).\n\n```java\ntry {\n    // ...\n} catch (Exception e) {\n    // ...\n} finally {\n    // Code qui s'exécute toujours\n    System.out.println(\"Bloc finally exécuté\");\n}\n```\n\n\n## 6. Propagation des exceptions\n\nSi une méthode ne gère pas une exception, elle la propage vers la méthode appelante.  Cette propagation continue jusqu'à ce qu'une méthode gère l'exception ou que le programme termine son exécution.  Ceci est géré via le mot-clé `throws` dans la signature de la méthode.\n\n```java\npublic void maMethode() throws IOException {\n    // Code qui peut lever une IOException\n    throw new IOException(\"Erreur d'entrée/sortie\");\n}\n```\n\n## 7.  Exceptions personnalisées\n\nIl est possible de créer des exceptions personnalisées pour gérer des situations spécifiques au sein de l'application.  Cela améliore la lisibilité et la maintenabilité du code.  Il suffit de créer une nouvelle classe qui étend `Exception` (ou une de ses sous-classes).  [Gestion des Exceptions]\n\n\n## Conclusion\n\nLa maîtrise de la gestion des exceptions est essentielle pour développer des applications Java robustes et fiables.  Une gestion appropriée des exceptions améliore la qualité du code, facilite le débogage et permet de fournir une expérience utilisateur plus agréable en évitant les plantages inattendus.\n",
        "linkedConcepts": [
            {
                "id": "7ec4ed2f-43a1-4eb2-a1aa-108cb2b03985",
                "title": "Cypress",
                "shortDescription": "",
                "description": "---\nid: 80fa04db-9979-4f13-ae6a-087b96aa069b\n---\n# Rapidement c'est quoi❓\n\nCypress est un framework de test [[JavaScript]] populaire pour les applications web. Il permet de réaliser des [[Test End2End (E2E)]] et des [[Test unitaire (TU)]] de composants.  Il se distingue par sa facilité d'utilisation et son approche intégrée.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCypress est un outil complet pour le test d'applications web.  Il offre une approche basée sur le [[Document Object Model (DOM)]], exécutant les tests directement dans le navigateur.  Cela permet une interaction plus naturelle et intuitive avec l'application testée, contrairement à des solutions qui interagissent de manière distante.\n\nCypress propose deux types de tests principaux :\n\n* **[[Test End2End (E2E)]]:**  Ces tests simulent le comportement d'un utilisateur réel, interagissant avec l'interface utilisateur de bout en bout.  Ils vérifient le flux complet d'une action, de l'interaction de l'utilisateur à la réponse du serveur.\n\n* **[[Test de Composant]]:**  Ces tests permettent de tester des composants individuels de l'interface utilisateur isolément, sans dépendance à l'application complète. Ceci permet des tests unitaires plus rapides et ciblés.\n\nL'exécution des tests se fait directement dans le navigateur, offrant un débogage facile et une meilleure visibilité sur le déroulement des tests.  Cypress propose une API intuitive et chainable, facilitant la création et la maintenance des tests.  Les fonctions principales incluent la sélection d'éléments (ex: `cy.get()`, `cy.contains()`), l'interaction avec les éléments (ex: `cy.click()`, `cy.type()`), et les assertions (ex: `cy.should()`).  Des fonctionnalités avancées comme l'interception des requêtes réseau (`cy.intercept()`), l'exécution de tâches personnalisées (`cy.task()`), et la génération de rapports avec captures d'écran sont également disponibles.  La prise en charge de la couverture de code est possible via des plugins tiers.\n\nLa configuration est relativement simple, nécessitant un fichier `cypress.config.js` (ou `cypress.config.ts`) pour spécifier les paramètres de configuration, tels que l'URL de l'application et le navigateur à utiliser.  La gestion des données de test peut être réalisée via des dumps de base de données ou d'autres techniques.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Facilité d'utilisation et d'apprentissage:** L'API intuitive et la documentation claire rendent Cypress accessible aux débutants.\n* **Débogage simplifié:** L'exécution dans le navigateur permet un débogage facile et visuel.\n* **Tests rapides et fiables:**  L'exécution directe dans le navigateur assure des tests rapides et stables.\n* **API chainable:** La possibilité d'enchaîner les commandes facilite la création de tests lisibles et maintenables.\n* **Fonctionnalités complètes:** Cypress offre un ensemble complet de fonctionnalités, incluant la génération de rapports, les captures d'écran, et l'interception des requêtes réseau.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Support limité de Safari:** Le support de [[Safari]] est moins complet que pour d'autres navigateurs.\n* **Gestion limitée des onglets multiples:** La gestion des tests sur plusieurs onglets est limitée.\n* **Pas de support natif pour les tests mobiles:** Bien qu'il soit possible d'utiliser des solutions alternatives, il n'y a pas de support natif pour les tests sur des appareils mobiles.\n* **Prise en charge limitée des applications non-web:**  Son utilisation principale se concentre sur le web; l'adaptation à d'autres types d'applications (ex: [[Electron]]) peut nécessiter des solutions spécifiques.\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n[[MOC_Testing]]\n",
                "linkedConcepts": [
                    {
                        "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                        "title": "Racine",
                        "shortDescription": "Racine de l'abre des connaissances",
                        "description": "",
                        "linkedConcepts": [],
                        "flashcards": [],
                        "base": true,
                        "atomic": false
                    }
                ],
                "flashcards": [],
                "base": false,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e8e30d2b-96ea-40d6-b6f3-405ab87d1a5d",
        "title": "@MapsId",
        "shortDescription": "",
        "description": "---\nid: d232d5f0-ad62-4cb1-be4b-eb4682ecb271\n---\n# **Rapidement, c'est quoi ? ❓**\n\n`@MapsId` est une annotation de Spring Data JPA utilisée dans les relations `@OneToOne` pour partager la clé primaire entre une entité parent et une entité enfant.  Cela évite la création d'une colonne de clé étrangère dans la table enfant.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nDans une relation `@OneToOne`,  Spring Data JPA crée généralement une colonne de clé étrangère dans la table de l'entité enfant pour faire référence à l'entité parent.  Si la relation est optionnelle (l'enfant peut exister sans le parent), cette colonne est souvent nullable.  `@MapsId` permet de contourner ce comportement.  Au lieu d'une clé étrangère, l'entité enfant partage la même clé primaire que l'entité parent.  Cela implique que la clé primaire de l'entité enfant est identique à celle du parent.  L'annotation `@MapsId` spécifie le nom du champ de la clé primaire de l'entité parent qui sera mappé à la clé primaire de l'entité enfant.\n\n**Exemple:**\n\nSupposons que nous ayons une entité `Utilisateur` et une entité `Profil` avec une relation `@OneToOne`.\n\n```java\n@Entity\npublic class Utilisateur {\n\n    @Id\n    @GeneratedValue(strategy = GenerationType.IDENTITY)\n    private Long id;\n\n    // ... autres attributs ...\n\n    @OneToOne(mappedBy = \"utilisateur\", cascade = CascadeType.ALL, orphanRemoval = true, fetch = FetchType.LAZY)\n    private Profil profil;\n    // ...\n}\n\n@Entity\n@Table(name = \"profil\")\npublic class Profil {\n\n    @Id\n    private Long id; // Clé primaire partagée\n\n    @MapsId\n    @OneToOne\n    @JoinColumn(name = \"id\") //Optionnel, le nom est deja id de base\n    private Utilisateur utilisateur;\n\n\n    // ... autres attributs ...\n}\n```\n\nDans cet exemple, `@MapsId` dans la classe `Profil` indique que le champ `id` de `Profil` utilise la même clé primaire que le champ `id` de `Utilisateur`.  La table `profil` n'aura pas de colonne de clé étrangère.  La contrainte d'unicité de la clé primaire gère la relation.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Simplicité:**  Évite la complexité d'une clé étrangère, surtout dans les relations optionnelles.\n* **Performance:** Peut améliorer légèrement les performances des requêtes, car cela évite les jointures sur la clé étrangère.\n* **Clarté du schéma de données:** Le schéma relationnel est plus propre et plus facile à comprendre.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Contraintes:**  Il est crucial que la clé primaire de l'entité enfant soit du même type que celle du parent.  Une mauvaise configuration peut conduire à des erreurs.\n* **Moins flexible:**  `@MapsId` est moins flexible que l'utilisation d'une clé étrangère classique, particulièrement si vous avez besoin de fonctionnalités avancées de gestion de la relation.\n* **Difficulté de compréhension:**  Pour les développeurs non expérimentés avec JPA, cette annotation peut être moins intuitive qu'une relation avec clé étrangère.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "bd6d23da-1d38-4bd8-abca-a651a7fe152a",
        "title": "Akka",
        "shortDescription": "",
        "description": "---\nid: 3b6dc02c-51c8-42be-85d6-9effe457e5ec\n---\n# **Rapidement, c'est quoi ? ❓**\n\nAkka est un toolkit open-source et multiplateforme pour construire des applications concurrentes, distribuées et résilientes basées sur le modèle acteur.  Il simplifie le développement d'applications hautement parallèles et tolérantes aux pannes.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nAkka est basé sur le modèle acteur, un paradigme de programmation concurrent qui traite les acteurs comme des unités indépendantes de calcul.  Chaque acteur possède sa propre boîte aux lettres pour recevoir des messages, son propre état interne et un thread dédié (ou un pool de threads).  La communication entre les acteurs se fait exclusivement par l'envoi de messages asynchrones.  Cela permet d'éviter les problèmes de concurrence classiques tels que les interblocages et les conditions de course.\n\nAkka offre plusieurs fonctionnalités clés :\n\n* **Modèle Acteur:**  Le cœur d'Akka.  Il gère la création, la surveillance et la communication entre les acteurs.\n* **Supervision:** Akka fournit un mécanisme de supervision hiérarchique permettant de gérer les erreurs et les pannes des acteurs.  Si un acteur plante, son superviseur peut décider de le redémarrer, de le surveiller, ou de le terminer.\n* **Résilience:** Grâce à la supervision et à la nature asynchrone des messages, Akka permet de construire des systèmes résilients capables de tolérer les pannes.\n* **Distribution:** Akka peut distribuer les acteurs sur plusieurs machines, permettant la création d'applications distribuées.\n* **Persistance:** Akka permet de persister l'état des acteurs pour garantir la cohérence des données en cas de panne.\n* **Streaming:** Akka Streams offre un cadre puissant pour traiter des flux de données de manière réactive et concurrente.\n* **HTTP/WebSockets:**  Akka HTTP fournit des outils pour créer des serveurs et des clients HTTP et WebSockets.\n\n**Exemple (Scala):**\n\n```scala\nimport akka.actor.{Actor, ActorSystem, Props}\n\nclass MyActor extends Actor {\n  def receive: Receive = {\n    case \"hello\" => println(\"Hello from actor!\")\n    case _ => println(\"Unknown message\")\n  }\n}\n\nobject MyAkkaApp extends App {\n  val system = ActorSystem(\"mySystem\")\n  val myActor = system.actorOf(Props[MyActor], \"myActor\")\n  myActor ! \"hello\"\n  Thread.sleep(1000)\n  system.terminate()\n}\n```\n\nCet exemple crée un système d'acteurs, un acteur `MyActor`, et lui envoie un message \"hello\".\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Concurrence facile:**  Le modèle acteur simplifie la gestion de la concurrence.\n* **Résilience:**  Les systèmes Akka sont plus résilients grâce à la supervision.\n* **Scalabilité:**  Akka permet de créer des applications distribuées et hautement scalables.\n* **Communauté active et documentation complète:** Akka bénéficie d'une large communauté et d'une documentation abondante.\n* **Langages supportés:** Akka est disponible pour Java, Scala, Kotlin et d'autres langages.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage:**  Le modèle acteur peut avoir une courbe d'apprentissage plus raide que les approches de programmation concurrentes traditionnelles.\n* **Débogage:**  Le débogage des applications Akka peut être plus complexe que celui des applications monothreadées.\n* **Complexité pour les applications simples:**  Pour les applications simples, Akka peut être un sur-ingénierie.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "75ef67dd-da48-429a-ab54-af38f2851448",
        "title": "Algorithmes de Garbage Collector",
        "shortDescription": "",
        "description": "---\nid: 11284ca5-0259-472f-bb46-962fa1f2500d\n---\n# Rapidement, c'est quoi ? ❓\n\nLes garbage collectors (GC) sont des algorithmes qui automatisent la gestion de la mémoire dans les langages de programmation comme Java.  Ils identifient et récupèrent la mémoire qui n'est plus utilisée par le programme, empêchant les fuites de mémoire et libérant des ressources pour de nouvelles allocations.  Parallel, G1, et ZGC sont trois algorithmes de GC différents utilisés par la JVM (Java Virtual Machine).\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCes trois algorithmes diffèrent principalement dans leur stratégie de collecte et leur impact sur les performances de l'application :\n\n**1. Parallel Garbage Collector:**\n\n* **Stratégie:**  Un GC \"stop-the-world\" qui utilise plusieurs threads pour collecter les objets inaccessibles. Il effectue une collecte des générations (Young, Old) et utilise un copy collector pour la génération Young (objets jeunes). La génération Old (objets âgés) utilise un mark-sweep-compact collector.  \n* **Fonctionnement:** Pendant la collecte, tous les autres threads de l'application sont interrompus (stop-the-world). La collecte est rapide pour la génération Young mais peut prendre plus de temps pour la génération Old.\n* **Avantages:**  Performant pour les applications avec un taux de création d'objets faible à moyen.  Le parallélisme accélère la collecte.\n* **Inconvénients:**  Longs temps d'arrêt (\"pause times\") lors de la collecte de la génération Old.  Non adapté aux applications exigeantes en faible latence.\n\n**2. G1 Garbage Collector (Garbage-First):**\n\n* **Stratégie:** Un GC concurrent et à faible pause qui divise le heap en régions. Il priorise la collecte des régions avec le plus de garbage. Il utilise une approche à plusieurs générations.\n* **Fonctionnement:**  Il effectue des collectes partielles et concurrentes, ce qui signifie qu'il travaille en parallèle avec l'application, minimisant les temps d'arrêt.  Il vise à atteindre un objectif de temps de pause donné.\n* **Avantages:**  Meilleur compromis entre temps de pause et débit que le Parallel GC.  Adapté aux applications avec des heaps de grande taille.\n* **Inconvénients:**  Plus complexe à configurer que le Parallel GC.  Peut consommer plus de ressources CPU que le Parallel GC.\n\n**3. Z Garbage Collector (ZGC):**\n\n* **Stratégie:** Un GC concurrent, à très faible pause, et à haute performance. Il utilise des pointeurs colorés et un mécanisme de détection de cycles efficace.\n* **Fonctionnement:**  Le ZGC vise à atteindre des temps de pause inférieurs à 10ms, même avec des heaps de plusieurs téraoctets. Il est extrêmement efficace et utilise plusieurs threads pour collecter les objets de manière concurrente.\n* **Avantages:**  Très faibles pauses, adapté aux applications nécessitant une faible latence (ex: applications en temps réel).  Excellent débit même pour des heaps volumineux.\n* **Inconvénients:**  Plus récent que les autres GC, donc moins mature.  Peut consommer plus de ressources CPU que G1 ou Parallel GC. Nécessite une version Java récente.\n\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Parallel GC:**  Simple, performant pour les applications à faible latence tolérable.\n* **G1 GC:**  Bon compromis entre débit et temps de pause, adapté aux grandes applications.\n* **ZGC:**  Temps de pause extrêmement faibles, idéal pour des applications à faible latence.\n\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Parallel GC:**  Longs temps de pause lors de la collecte de la génération Old.\n* **G1 GC:**  Peut être plus complexe à configurer et à maîtriser.\n* **ZGC:**  Plus gourmand en ressources, relativement récent et nécessite une version Java récente.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "8b72417a-7de5-4399-b169-e1f5066764f7",
        "title": "Apache CouchDB",
        "shortDescription": "",
        "description": "---\nid: f21c9312-cb75-458c-bc61-69e46d477f40\n---\n# **Rapidement, c'est quoi ? ❓**\n\nApache CouchDB est une base de données NoSQL orientée document, open source, qui utilise le protocole HTTP pour accéder et manipuler les données.  Elle se distingue par sa simplicité, sa facilité de réplication et son modèle de données flexible.\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nCouchDB stocke les données sous forme de documents JSON.  Chaque document est identifié par un unique ID et possède des révisions, permettant le suivi des modifications.  L'accès aux données se fait via des requêtes HTTP (GET, POST, PUT, DELETE) sur des URLs spécifiques.  Elle utilise un mécanisme de réplication facile à mettre en place, permettant la synchronisation de données entre plusieurs serveurs.  CouchDB utilise le concept de \"vues\" (views) pour créer des index sur les documents, permettant des requêtes plus performantes.  Ces vues sont définies en utilisant une syntaxe MapReduce simplifiée, ou bien avec des fonctions écrites en Javascript.\n\nVoici un exemple d'ajout d'un document en utilisant une requête HTTP POST :\n\n```bash\ncurl -X POST -H \"Content-Type: application/json\" -d '{\"name\": \"John Doe\", \"age\": 30}' http://localhost:5984/mydb/\n```\n\nEt un exemple de requête pour récupérer un document spécifique :\n\n```bash\ncurl http://localhost:5984/mydb/doc_id\n```\n\nCouchDB offre un mécanisme de gestion des conflits lors de la réplication.  Le modèle de données flexible permet de stocker des données structurées et non structurées facilement.  L'architecture est distribuée par nature, favorisant la haute disponibilité et la tolérance aux pannes.\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Simplicité et facilité d'utilisation:**  L'API HTTP est intuitive et facile à comprendre.\n* **Réplication facile:**  La réplication est un processus simple et robuste, permettant une haute disponibilité et une distribution géographique des données.\n* **Modèle de données flexible:**  Le format JSON permet de stocker des données de différentes structures.\n* **Open source et communauté active:**  Bénéficie d'une grande communauté et d'un support important.\n* **Architecture distribuée:**  Intégrée par nature pour une meilleure tolérance aux pannes et scalabilité.\n\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Performance des requêtes complexes:**  Peut être moins performante que d'autres bases de données pour des requêtes complexes nécessitant des jointures ou des opérations avancées.  La performance dépend fortement de la conception des vues.\n* **Manque de fonctionnalités ACID strictes:**  Bien que CouchDB offre des mécanismes pour la cohérence des données, elle ne fournit pas les garanties ACID complètes comme les bases de données relationnelles.\n* **Modèle de données moins structuré:**  L'absence de schéma rigide peut compliquer la gestion des données pour certaines applications.\n* **La courbe d'apprentissage des vues MapReduce peut être raide** pour les développeurs qui ne sont pas familiers avec ce paradigme.\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "b73fab9d-4ae1-42cb-acf8-d6b4ca556589",
        "title": "Apache Pulsar",
        "shortDescription": "",
        "description": "---\nid: 9058cd6d-9b55-44d4-ac8f-efcfa34393bd\n---\n# Rapidement, c'est quoi ? ❓\n\nApache Pulsar est un système de messagerie distribué, hautement scalable et performant, conçu pour gérer des flux de données à grande échelle et à faible latence.  Il est particulièrement adapté aux applications nécessitant une haute disponibilité et une grande capacité de traitement de messages.\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nApache Pulsar est un système de messagerie à publication/abonnement (pub/sub) qui utilise une architecture multi-tenant et gérée par le cloud.  Il se différencie des systèmes de messagerie traditionnels par plusieurs aspects clés :\n\n* **Architecture en couches:** Pulsar utilise une architecture en trois couches :  brokers, clients et le service de stockage. Les brokers gèrent les connexions clients et la routage des messages. Le stockage peut être effectué dans différents systèmes de stockage persistants (comme BookKeeper ou un système de fichiers distribué), offrant flexibilité et haute disponibilité.\n\n* **BookKeeper:** Pulsar utilise BookKeeper, un système de stockage distribué hautement performant et fiable, pour la persistance des messages. Ceci assure la durabilité des messages même en cas de panne de brokers.\n\n* **Gestion des namespaces et des topics:** Pulsar offre une gestion fine des namespaces et des topics, permettant une séparation claire entre les différents locataires et applications.  Cela facilite la gestion des ressources et l'isolation des applications.\n\n* **Routing flexible:** Pulsar supporte différents modes de routage, dont le routage géométrique, permettant une distribution efficace des messages entre les consommateurs.\n\n* **Fonctionnalités avancées:** Pulsar offre des fonctionnalités telles que la segmentation des topics, la réplication des messages, la gestion des transactions et l'intégration avec des outils de monitoring.\n\n**Exemple (concept):** Imaginons une application de streaming vidéo.  Pulsar peut être utilisé pour gérer le flux de données vidéo en temps réel. Les producteurs publient les données vidéo sur un topic Pulsar, et les consommateurs les reçoivent pour les diffuser aux utilisateurs.  La haute scalabilité de Pulsar permet de gérer un grand nombre d'utilisateurs simultanés.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Haute performance et faible latence:** Pulsar est optimisé pour une faible latence et un débit élevé.\n* **Scalabilité horizontale:** Pulsar peut facilement être étendu pour gérer des charges de travail de plus en plus importantes.\n* **Haute disponibilité:** Grâce à la réplication et à BookKeeper, Pulsar offre une haute disponibilité des messages.\n* **Multi-tenancy:** Pulsar permet une séparation claire des ressources entre les différents locataires.\n* **Gestion avancée des topics:** La segmentation et la réplication des topics offre une grande flexibilité.\n* **Support de multiples langages:** Pulsar fournit des clients pour divers langages de programmation.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La configuration et la gestion de Pulsar peuvent être plus complexes que celle de systèmes de messagerie plus simples.\n* **Courbe d'apprentissage:**  Il faut du temps pour maîtriser toutes les fonctionnalités et les subtilités de Pulsar.\n* **Dépendance à BookKeeper:** La performance et la fiabilité de Pulsar dépendent en grande partie de BookKeeper.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "f2d08ce3-3069-4de6-998b-85703c531cef",
        "title": "Arch Unit",
        "shortDescription": "",
        "description": "---\nid: ffaf4087-aebd-46bc-9684-f0d5c8c188bb\n---\n# Rapidement, c'est quoi ? ❓\n\nArchUnit est une librairie Java basée sur JUnit permettant de tester l'architecture d'une application.  Elle vérifie les relations entre différents composants (classes, packages, etc.) et s'assure que l'architecture respecte les règles définies.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nArchUnit permet de définir des règles architecturales et de vérifier si le code source les respecte.  Ces règles peuvent porter sur différents aspects de l'architecture, tels que :\n\n* **Dépendances entre couches :**  Vérifier qu'une couche présentation ne dépend pas directement de la couche données, mais uniquement de la couche service.\n* **Cycles de dépendances :** Détecter les cycles entre les packages ou les classes, signe d'une architecture complexe et difficile à maintenir.\n* **Utilisation d'annotations :** S'assurer que toutes les classes annotées d'une certaine manière respectent une convention de nommage ou une structure spécifique.\n* **Respect de principes de conception :** Vérifier le respect de principes tels que la séparation des préoccupations ou l'inversion des dépendances.\n\n\nArchUnit utilise une API fluide et expressive pour définir ces règles.  On décrit la structure souhaitée à l'aide de conditions sur les classes, les packages et leurs relations.  L'exécution des tests vérifie ensuite si le code source correspond à cette description.  La fonctionnalité \"freezing arch rules\" est particulièrement utile pour intégrer ArchUnit dans des projets existants (legacy) en permettant d'appliquer les règles uniquement sur le nouveau code.\n\n\n**Exemple (Illustratif):**\n\nSupposons que l'on veuille vérifier qu'aucune classe du package `com.example.presentation` ne dépend directement du package `com.example.data`.  Avec ArchUnit, on pourrait écrire une règle similaire à :\n\n```java\nimport com.tngtech.archunit.core.importer.ImportOption;\nimport com.tngtech.archunit.lang.syntax.ArchRuleDefinition;\nimport org.junit.jupiter.api.Test;\n\nimport static com.tngtech.archunit.lang.syntax.ArchRuleDefinition.classes;\nimport static com.tngtech.archunit.library.dependencies.SlicesRuleDefinition.slices;\n\npublic class ArchitectureTest {\n\n    @Test\n    void presentationLayerShouldNotDependOnDataLayer() {\n        classes()\n                .that().resideInAPackage(\"com.example.presentation\")\n                .should().onlyDependOnClassesThat().resideInAnyPackage(\"..presentation\", \"..service\");\n\n    }\n      @Test\n    void cyclicDependenciesAreForbidden(){\n        slices().matching(\"com.example.(*)..\").should().beFreeOfCycles();\n    }\n\n}\n```\n\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Automatisation des vérifications architecturales :**  ArchUnit permet d'automatiser le respect des règles architecturales, évitant ainsi les régressions et améliorant la qualité du code.\n* **Détection précoce des problèmes :**  Les tests d'architecture sont exécutés lors des tests unitaires ou d'intégration, permettant une détection rapide des violations architecturales.\n* **Amélioration de la maintenabilité :**  En garantissant le respect de règles architecturales, ArchUnit contribue à une meilleure maintenabilité du code.\n* **Documentation de l'architecture :** Les règles définies avec ArchUnit peuvent servir de documentation de l'architecture du projet.\n* **Intégration facile avec JUnit :**  L'intégration avec JUnit est simple et transparente.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage :**  Il faut un certain temps pour maîtriser l'API d'ArchUnit et définir des règles complexes.\n* **Maintenance des règles :**  La maintenance des règles architecturales peut devenir coûteuse à mesure que le projet évolue.\n* **Potentiellement intrusif :** L'ajout de règles ArchUnit peut nécessiter des modifications dans le code existant.  \n* **Peut ralentir les tests :**  L'exécution des règles ArchUnit peut ajouter du temps aux tests.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\nJUnit, Architecture logicielle,  tests unitaires,  intégration continue.\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "6cdb72d6-e752-4997-ae64-c08258bc90bf",
        "title": "Biscuit authentication authorization token",
        "shortDescription": "",
        "description": "---\nid: 3bf7e0ea-40ce-415e-8c21-bb28171de774\n---\n# **Rapidement, c'est quoi ? ❓**\n\nUn Biscuit est un jeton d'authentification et d'autorisation décentralisé, cryptographiquement sécurisé et vérifiable hors ligne.  Il permet de vérifier les autorisations d'un utilisateur sans avoir besoin d'une connexion réseau constante à un serveur central.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nUn Biscuit est un petit fichier de données contenant des affirmations sur l'identité et les autorisations d'un utilisateur.  Ces affirmations sont chiffrées et vérifiées à l'aide de la cryptographie.  Contrairement aux systèmes centralisés qui reposent sur un serveur pour vérifier les jetons, les Biscuits peuvent être vérifiés localement par l'application cliente.\n\nUn Biscuit est créé par un serveur autorisé (\"issuer\").  Ce serveur inclut des affirmations initiales dans le Biscuit.  Par la suite, des parties tierces peuvent ajouter de nouvelles affirmations au Biscuit, mais seulement si elles ont reçu l'autorisation de le faire par le serveur initial.  Ces nouvelles affirmations sont ajoutées sous forme de \"preuves\" qui sont attachées au Biscuit et vérifiées ultérieurement.\n\nLa vérification se fait grâce à une signature cryptographique intégrée au Biscuit.  L'application cliente possède une copie de la clé publique du serveur qui a émis le Biscuit.  Elle peut ainsi vérifier l'intégrité et l'authenticité du Biscuit, ainsi que la validité des affirmations qu'il contient.\n\n**Fonctionnement interne (simplifié):**\n\n1. **Création:** Le serveur génère un Biscuit avec des affirmations initiales (par exemple, \"l'utilisateur est authentifié\", \"l'utilisateur a le rôle d'administrateur\").\n2. **Extension (optionnel):** Une autre entité (avec autorisation) peut ajouter de nouvelles affirmations au Biscuit (par exemple, \"l'utilisateur a accès à la ressource X\").  Cela se fait par la génération d'une preuve qui est attachée au Biscuit.\n3. **Vérification:** L'application cliente vérifie le Biscuit en utilisant la clé publique du serveur. Cette vérification confirme que le Biscuit n'a pas été altéré et que toutes les affirmations sont valides.\n\n**Exemple (conceptuel):**\n\nImaginez une application de partage de fichiers.  Un Biscuit pourrait contenir l'affirmation \"utilisateur A a accès au fichier X\".  Ce Biscuit serait vérifié localement par l'application avant de permettre l'accès au fichier.  L'ajout d'une nouvelle affirmation, comme \"utilisateur B peut lire le fichier X\", pourrait se faire par une entité autorisée, ajoutant une preuve au Biscuit existant.\n\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n- **Sécurité:** La cryptographie assure l'intégrité et l'authenticité du Biscuit, empêchant la falsification.\n- **Décentralisation:** La vérification hors ligne réduit la dépendance à un serveur central, améliorant la résilience et la performance.\n- **Privacy:**  Certaines implémentations permettent de limiter les informations exposées lors de la vérification.\n- **Flexibilité:**  L'ajout de preuves permet une gestion fine des autorisations et une adaptation à différents contextes.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n- **Complexité:** La mise en œuvre d'un système de Biscuits peut être complexe, nécessitant une bonne compréhension de la cryptographie.\n- **Taille des Biscuits:** Les Biscuits peuvent prendre un certain espace de stockage, bien que leur taille reste généralement raisonnable.\n- **Gestion des clés:** La sécurité du système dépend de la gestion sécurisée des clés publiques et privées.\n- **Adoption limitée:**  La technologie des Biscuits est relativement nouvelle et son adoption n'est pas encore aussi répandue que d'autres technologies d'authentification.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "21ec1638-0060-4a17-9b23-f21e76551e13",
        "title": "Blocking Queue (Java)",
        "shortDescription": "",
        "description": "---\nid: be601ded-fbb0-4d7d-82ba-aed2c27ceaa3\n---\n# **Rapidement, c'est quoi ? ❓**\n\nUne `BlockingQueue` en Java est une interface qui représente une file d'attente thread-safe.  Elle bloque les opérations d'insertion (ajout d'éléments) si la file est pleine et les opérations de suppression (retrait d'éléments) si elle est vide.  Cela permet une synchronisation efficace entre les threads producteurs et consommateurs.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nUne `BlockingQueue` est une interface dans le package `java.util.concurrent`.  Elle étend l'interface `Queue` et ajoute des méthodes spécifiques pour gérer le blocage des opérations d'ajout et de suppression.  Lorsque la file est pleine, l'insertion d'un nouvel élément bloquera le thread producteur jusqu'à ce qu'un élément soit retiré.  Inversement, si la file est vide, la tentative de suppression bloquera le thread consommateur jusqu'à ce qu'un élément soit ajouté.\n\nPlusieurs implémentations de `BlockingQueue` existent, chacune avec des caractéristiques spécifiques :\n\n* **`ArrayBlockingQueue`**:  Implémente une file d'attente bornée utilisant un tableau.  Sa taille est fixe lors de la création.\n* **`LinkedBlockingQueue`**: Implémente une file d'attente bornée ou non bornée (par défaut non bornée) utilisant une liste chaînée.  Offre une meilleure performance pour les insertions et suppressions fréquentes.\n* **`PriorityBlockingQueue`**:  Implémente une file d'attente non bornée qui ordonne les éléments selon leur priorité (définie par l'implémentation de `Comparable` ou un `Comparator`).\n* **`DelayQueue`**: Une file d'attente non bornée qui maintient des éléments qui ne sont accessibles que lorsqu'un délai spécifié est écoulé.\n* **`SynchronousQueue`**: Une file d'attente particulière où chaque insertion doit attendre une suppression correspondante, et vice-versa.  Elle n'a pas de capacité interne.\n\n**Exemple avec `ArrayBlockingQueue`:**\n\n```java\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.BlockingQueue;\n\npublic class BlockingQueueExample {\n\n    public static void main(String[] args) {\n        BlockingQueue<Integer> queue = new ArrayBlockingQueue<>(5); // File d'attente de taille 5\n\n        // Thread producteur\n        Thread producer = new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    queue.put(i); // Bloquera si la queue est pleine\n                    System.out.println(\"Producer added: \" + i);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        });\n\n        // Thread consommateur\n        Thread consumer = new Thread(() -> {\n            for (int i = 0; i < 10; i++) {\n                try {\n                    int value = queue.take(); // Bloquera si la queue est vide\n                    System.out.println(\"Consumer consumed: \" + value);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        });\n\n        producer.start();\n        consumer.start();\n    }\n}\n```\n\nCet exemple montre comment les threads producteur et consommateur interagissent avec la `BlockingQueue`. Les méthodes `put()` et `take()` gèrent le blocage et la synchronisation automatiquement.\n\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Thread-safety:**  Gère la concurrence entre les threads de manière sécurisée et efficace, éliminant le besoin de mécanismes de synchronisation manuels.\n* **Blocage automatique:**  Simplifie la gestion de la concurrence en bloquant automatiquement les threads producteurs et consommateurs lorsque nécessaire.\n* **Flexibilité:**  Différentes implémentations permettent de choisir la structure de données la plus appropriée à l'application.\n* **Performance:** Les implémentations optimisées offrent une bonne performance dans de nombreux cas d'utilisation.\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité potentielle:**  Le choix de l'implémentation appropriée peut nécessiter une compréhension des différentes caractéristiques de chaque type de `BlockingQueue`.\n* **Blocage:**  Bien que le blocage soit une fonctionnalité importante, il peut causer des problèmes si mal géré, notamment des deadlocks.\n* **Gestion des exceptions:** Il faut gérer les `InterruptedException` lors de l'utilisation des méthodes de blocage.\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "ac35e30e-23da-4355-8326-80e45caf7521",
        "title": "Compose-go",
        "shortDescription": "",
        "description": "---\nid: b977a102-d94a-4a34-97a4-4bf34427ab50\n---\n# **Rapidement, c'est quoi ? ❓**\n\nCompose-go est une bibliothèque Go qui simplifie l'interaction avec Docker Compose.  Elle permet de programmer la création, la mise à jour et la destruction de services et de réseaux définis dans des fichiers `docker-compose.yml`.  Elle offre une interface plus flexible et programmable que l'utilisation directe de la commande `docker-compose`.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nCompose-go fournit des fonctions Go pour interagir avec l'API Docker Compose.  Au lieu d'utiliser des commandes shell, on peut utiliser le code Go pour effectuer des opérations sur les fichiers `docker-compose.yml`.  Cela permet d'intégrer la gestion de Docker Compose dans des scripts et des applications Go, offrant un meilleur contrôle et une meilleure automatisation.  La bibliothèque gère la communication avec le daemon Docker, l'analyse des fichiers `docker-compose.yml`, et la gestion des erreurs.\n\nVoici un exemple simple pour démarrer un projet Docker Compose avec Compose-go:\n\n```go\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"log\"\n\n\t\"github.com/compose-spec/compose-go/cli\"\n)\n\nfunc main() {\n\tctx := context.Background()\n\tproject, err := cli.ProjectFromOptions(ctx, &cli.ProjectOptions{\n\t\tConfigFiles: []string{\"docker-compose.yml\"}, // Chemin vers votre fichier docker-compose.yml\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"Error loading project: %v\", err)\n\t}\n\n\terr = project.Up(ctx, cli.UpOptions{\n\t\t// Ajoutez des options ici si nécessaire\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"Error starting project: %v\", err)\n\t}\n\n\tfmt.Println(\"Project started successfully!\")\n\n\t// ... autres interactions avec le projet ...\n\n\t// Arrêter le projet à la fin\n\terr = project.Down(ctx, cli.DownOptions{})\n\tif err != nil {\n\t\tlog.Fatalf(\"Error stopping project: %v\", err)\n\t}\n\tfmt.Println(\"Project stopped successfully!\")\n}\n\n```\n\nCe code charge un fichier `docker-compose.yml`, démarre les services définis et les arrête ensuite.  Compose-go offre des fonctions pour effectuer d'autres opérations, comme `project.Create`, `project.Build`, `project.Start`, `project.Stop`, `project.Restart`, etc.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n- **Automatisation:**  Permet d'intégrer la gestion de Docker Compose dans des pipelines CI/CD et des scripts Go.\n- **Programmation:** Offre un contrôle précis sur les opérations Docker Compose.\n- **Flexibilité:**  Permet de personnaliser le comportement de Docker Compose en utilisant le code Go.\n- **Testabilité:** Facilite l'écriture de tests unitaires pour les interactions avec Docker Compose.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n- **Courbe d'apprentissage:**  Nécessite des connaissances en Go et en Docker Compose.\n- **Dépendances:**  Ajoute une dépendance supplémentaire à votre projet.\n- **Complexité:**  Pour des cas d'utilisation complexes, le code Go peut devenir plus long et difficile à maintenir qu'une simple commande `docker-compose`.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a87947c1-5cf5-42e3-9e3f-99787a1a2a04",
        "title": "DSFR (Design System France)",
        "shortDescription": "",
        "description": "---\nid: 885faf14-e488-4285-bd84-cb9ec7f2f730\n---\n# **Rapidement, c'est quoi ? ❓**\n\nDSFR (Design System France) est une bibliothèque de composants d'interface utilisateur et un ensemble de guidelines de design pour la création d'applications web et mobiles conformes aux standards d'accessibilité français.  Elle offre des composants prêts à l'emploi et des styles cohérents pour assurer une expérience utilisateur uniforme et accessible.\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nDSFR vise à standardiser la conception et le développement d'interfaces numériques pour les services publics français.  Il fournit une collection de composants réutilisables (boutons, formulaires, menus, etc.)  avec des styles prédéfinis, assurant une cohérence visuelle et une meilleure expérience utilisateur.  L'objectif principal est de faciliter le développement d'applications accessibles, conformes aux exigences du RGAA (Référentiel Général d'Accessibilité pour les Administrations).  DSFR propose des implémentations pour divers frameworks (React, Angular, Vue.js, etc.), permettant aux développeurs d'intégrer facilement ces composants dans leurs projets.  Ces implémentations souvent appelés \"surcouches\" fournissent des composants spécifiques à chaque framework mais conservent l'apparence visuelle et l'accessibilité définies par le DSFR.\n\nL'utilisation de DSFR permet :\n\n* **Cohérence visuelle:**  Toutes les applications utilisant DSFR auront une apparence cohérente, améliorant l'expérience utilisateur et la reconnaissance de la marque.\n* **Accessibilité:**  Les composants sont conçus pour respecter les exigences du RGAA, garantissant une accessibilité optimale pour les personnes handicapées.\n* **Efficacité de développement:**  Réutilisation des composants pré-construits et stylés, accélérant le processus de développement.\n* **Maintenance simplifiée:**  Les mises à jour et corrections de bugs sont appliquées à l'ensemble des applications utilisant DSFR.\n\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Accessibilité:**  Respect des standards RGAA, essentiel pour les services publics.\n* **Cohérence:**  Assure une expérience utilisateur uniforme sur l'ensemble des applications gouvernementales.\n* **Réutilisabilité:**  Composants prêts à l'emploi, accélérant le développement.\n* **Support multiple frameworks:**  Disponibilité de surcouches pour différents frameworks populaires.\n* **Documentation:**  Documentation généralement complète et bien maintenue (bien que la qualité puisse varier selon les versions et les frameworks).\n\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité d'intégration:**  L'intégration initiale peut parfois être complexe, nécessitant une compréhension du fonctionnement du DSFR et de sa surcouche pour le framework utilisé.\n* **Dépendance:**  L'application est dépendante du DSFR et de ses mises à jour.  Les changements dans le DSFR peuvent nécessiter des adaptations dans les applications qui l'utilisent.\n* **Personnalisation limitée:**  Bien que la personnalisation soit possible, elle peut être contraignante pour s'assurer que l'accessibilité et la cohérence restent intactes.  Un écart trop important par rapport aux styles standards peut compromettre l'expérience utilisateur et l'accessibilité.\n* **Taille du bundle:** L'inclusion de tous les composants DSFR peut augmenter la taille du bundle final de l'application, impactant le temps de chargement.  Une sélection judicieuse des composants est donc nécessaire.\n\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "27dc5b58-d4a7-4402-99f8-edf4d383f78c",
        "title": "Doppler",
        "shortDescription": "",
        "description": "---\nid: 03bc89d4-ca8c-4258-a7fe-ae938a70b0cc\n---\n# Rapidement, c'est quoi ? ❓\n\nDoppler est un gestionnaire de secrets (secret manager) en tant que service (SaaS) qui permet de stocker et de gérer en toute sécurité les variables d'environnement et autres informations sensibles utilisées par les applications.  Il simplifie la gestion des secrets pour les équipes de développement et d'exploitation.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nDoppler fournit une interface centralisée pour stocker et gérer les secrets, évitant ainsi de les coder en dur dans les applications ou de les stocker dans des fichiers non sécurisés.  Il fonctionne en permettant aux développeurs de définir des \"configurations\" qui contiennent des clés et des valeurs, y compris les secrets. Ces configurations sont ensuite accessibles par les applications via une API ou des outils en ligne de commande.  Doppler se charge de chiffrer et de protéger ces secrets, en utilisant des techniques de chiffrement robustes.\n\nLes principales fonctionnalités incluent :\n\n* **Gestion des variables d'environnement:**  Doppler simplifie la gestion des variables d'environnement sensibles, comme des clés API, des mots de passe de base de données, et des jetons d'authentification.\n* **Contrôle d'accès:**  Il permet de gérer les autorisations d'accès aux secrets, permettant de limiter l'accès aux personnes autorisées.\n* **Intégration CI/CD:** Doppler s'intègre facilement avec les pipelines CI/CD, permettant d'injecter automatiquement les secrets dans les environnements de déploiement.\n* **Audit trails:**  Il fournit un historique complet des modifications apportées aux secrets, facilitant le suivi et la vérification.\n* **Chiffrement:** Les données sont chiffrées à la fois en transit et au repos.\n* **Support de multiples environnements:**  Permet de gérer des configurations séparées pour différents environnements (développement, test, production).\n\n\n**Exemple (concept):**  Imaginons une application qui nécessite une clé API pour accéder à un service tiers.  Au lieu de coder en dur cette clé API dans le code source, le développeur peut la stocker dans Doppler et la récupérer au moment de l'exécution de l'application.\n\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Sécurité améliorée:**  Le chiffrement et le contrôle d'accès robustes garantissent la sécurité des secrets.\n* **Simplicité d'utilisation:**  L'interface utilisateur est intuitive et facile à utiliser, même pour les développeurs peu expérimentés.\n* **Intégration facile:**  L'intégration avec les pipelines CI/CD simplifie le processus de déploiement.\n* **Collaboration facilitée:**  Plusieurs membres de l'équipe peuvent accéder et gérer les secrets de manière contrôlée.\n* **Auditabilité:**  L'historique des modifications permet de suivre facilement les changements.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Dépendance à un service tiers:**  Votre application dépend du service Doppler, ce qui introduit un point de défaillance potentiel.\n* **Coût:**  L'utilisation de Doppler implique des coûts, selon le plan d'abonnement choisi.\n* **Complexité pour des configurations très complexes:**  Pour des environnements avec une multitude de configurations interdépendantes, la gestion pourrait devenir complexe.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "613183f4-d4b5-41e0-ab01-8635dd8faa42",
        "title": "Eclipse Mosquitto",
        "shortDescription": "",
        "description": "---\nid: 34fc0c9b-c544-45c5-bd61-a2199ddf11d0\n---\n# Rapidement c'est quoi❓\n\nEclipse Mosquitto est un serveur MQTT léger, open-source et performant, permettant la publication et la souscription à des messages. Il est réputé pour sa robustesse et sa facilité de déploiement.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nEclipse Mosquitto est une implémentation du protocole MQTT (Message Queuing Telemetry Transport), un protocole de communication machine-à-machine (M2M) léger et basé sur le publish/subscribe.  Il sert de courtier (broker) centralisé, permettant à différents dispositifs (capteurs, actionneurs, applications) d'échanger des messages de manière asynchrone.  Mosquitto est conçu pour être performant, scalable et fiable, capable de gérer un grand nombre de clients connectés simultanément et un volume important de messages.  Il supporte plusieurs fonctionnalités clés, notamment :\n\n* **Authentification et autorisation:**  Mosquitto permet de contrôler l'accès aux ressources via différents mécanismes d'authentification (mot de passe, certificats X.509) et d'autorisation (ACL - Access Control Lists).\n* **QoS (Quality of Service):**  Il gère différents niveaux de qualité de service pour garantir la livraison des messages (QoS 0, 1 et 2).\n* **Rétention de messages:**  Les messages peuvent être retenus par le broker, même si aucun client n'est abonné, assurant ainsi que les nouveaux abonnés reçoivent les messages les plus récents.\n* **Will messages:**  Permet de spécifier un message à publier lorsque le client se déconnecte inopinément.\n* **WebSockets:**  Mosquitto supporte les connexions via WebSockets, permettant une intégration plus facile avec les applications web.\n* **TLS/SSL:**  Le chiffrement TLS/SSL est supporté pour sécuriser les communications.\n\nMosquitto est disponible sous forme de binaires précompilés pour plusieurs systèmes d'exploitation ou en code source pour une compilation personnalisée. Sa configuration se fait via un fichier de configuration simple et lisible.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open-source et gratuit:**  Mosquitto est sous licence EPL, ce qui permet une utilisation libre et gratuite, même pour des applications commerciales.\n* **Léger et performant:**  Il consomme peu de ressources système et est capable de gérer un grand nombre de clients et de messages.\n* **Facile à installer et configurer:**  L'installation et la configuration sont relativement simples, même pour les utilisateurs novices.\n* **Documentation complète et active communauté:**  Mosquitto bénéficie d'une documentation complète et d'une communauté active et réactive.\n* **Largement adopté et testé:**  Son utilisation répandue en fait un choix fiable et éprouvé.\n* **Support multiplateforme:**  Mosquitto est disponible sur de nombreuses plateformes, facilitant le déploiement sur différents environnements.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Interface utilisateur limitée:**  Mosquitto est principalement un serveur en ligne de commande, ne disposant pas d'interface graphique intuitive pour la gestion.  Des outils tiers peuvent être nécessaires pour une gestion plus conviviale.\n* **Fonctionnalités avancées potentiellement complexes à configurer:**  Certaines fonctionnalités avancées (authentification, QoS, ACL) peuvent nécessiter une configuration plus complexe.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "5a3bca99-abe2-4aa0-90de-c31092299dd3",
        "title": "Ember.js",
        "shortDescription": "",
        "description": "---\nid: cfe3dff1-dabd-489c-95cd-b4bc688004e6\n---\n# **Rapidement, c'est quoi ? ❓**\n\nEmber.js est un framework JavaScript open-source, ambitieux et mature, conçu pour construire des applications web ambitieuses,  scalables et maintenables. Il privilégie une architecture conventionnelle sur la configuration, offrant une structure claire et prédictible pour le développement.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nEmber.js fournit une structure complète pour développer des applications web côté client, s'appuyant sur le modèle MVC (Model-View-Controller) et intégrant des fonctionnalités avancées telles que :\n\n* **Routage:**  Un système de routage puissant et déclaratif permettant de gérer facilement les URLs et la navigation au sein de l'application.  Il permet de créer des URLs propres et SEO-friendly.\n\n* **Gestion des données:**  Ember Data est un ORM (Object-Relational Mapper) intégré qui facilite l'interaction avec des APIs RESTful ou autres sources de données. Il gère la mise en cache, les requêtes et les relations entre les données.\n\n* **Composants:**  Ember utilise un système de composants réutilisables et encapsulés, facilitant l'organisation du code et la maintenance.  Ces composants gèrent leur propre logique,  template et données.\n\n* **Templates:**  Les templates Ember utilisent Handlebars, un moteur de templating facile à utiliser et puissant. Il permet d'intégrer facilement la logique et les données dans l'interface utilisateur.\n\n* **Convention over Configuration:**  Ember privilégie les conventions, réduisant le besoin de configuration manuelle et améliorant la cohérence du code. Cela rend le développement plus rapide et plus prévisible.\n\n* **Gestion du cycle de vie des composants:**  Ember gère automatiquement le cycle de vie des composants (création, mise à jour, destruction), simplifiant la gestion des états et des événements.\n\n\n**Exemple de code (Création d'un composant simple):**\n\n```javascript\n// app/components/welcome-message.js\nimport Component from '@glimmer/component';\n\nexport default class WelcomeMessageComponent extends Component {\n  message = \"Bienvenue sur mon application Ember!\";\n}\n\n// app/templates/components/welcome-message.hbs\n<p>{{this.message}}</p>\n```\n\nCe code définit un composant simple affichant un message.  Il est ensuite utilisé dans les templates de l'application.\n\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Productivité:**  L'architecture conventionnelle et les outils intégrés améliorent la productivité du développeur.\n* **Maintenabilité:**  Le code est plus organisé et facile à maintenir grâce à la structure imposée par le framework.\n* **Scalabilité:**  Ember est conçu pour gérer des applications complexes et de grande envergure.\n* **Communauté active:**  Une communauté forte et active fournit un support et des ressources abondantes.\n* **Tests intégrés:**  Ember encourage les tests unitaires et d'intégration, facilitant la qualité du code.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage:**  Ember possède une courbe d'apprentissage plus raide que certains frameworks plus simples.\n* **Taille du bundle:**  Les applications Ember peuvent générer des bundles JavaScript importants, impactant le temps de chargement initial.  Des techniques d'optimisation sont nécessaires.\n* **Moins flexible que React ou Vue.js:**  La forte conventionnalité, bien que bénéfique, peut parfois limiter la flexibilité pour des cas d'utilisation très spécifiques.\n* **Difficultés pour les petites applications:**  Pour les applications très petites et simples, Ember peut être un choix surdimensionné.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "8b0d746d-bce7-4c53-8aac-337a36c628f8",
        "title": "Exherbo",
        "shortDescription": "",
        "description": "---\nid: 50d36a14-2216-4608-bf2e-3ec2ef4d7bca\n---\n# **Rapidement, c'est quoi ? ❓**\n\nExherbo est un outil de gestion de configurations open-source pour les systèmes Linux. Il utilise un langage déclaratif pour décrire l'état souhaité du système, puis gère les modifications nécessaires pour atteindre cet état.  Il se différencie des autres outils par sa simplicité, sa robustesse et sa focalisation sur l'idémpotence.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nExherbo utilise un fichier de configuration simple, généralement écrit en YAML, pour définir l'état souhaité du système. Ce fichier décrit les paquets logiciels à installer, les services à activer, les fichiers de configuration à modifier, etc.  Exherbo compare ensuite l'état actuel du système avec l'état décrit dans le fichier de configuration et applique les modifications nécessaires pour les faire correspondre.  Ce processus est *idémpotent*, ce qui signifie qu'exécuter la même commande plusieurs fois aura le même effet que de l'exécuter une seule fois.  Il ne fera pas de changements si le système est déjà dans l'état souhaité.\n\nExherbo est basé sur une approche déclarative, ce qui le rend plus facile à comprendre et à maintenir que les approches impératives.  On décrit *ce qu'on veut*, et Exherbo s'occupe de *comment le faire*.  Ceci simplifie la gestion de configurations complexes et permet une meilleure reproductibilité des environnements.\n\n**Exemple de fichier de configuration (YAML):**\n\n```yaml\npackages:\n  - vim\n  - git\n\nservices:\n  - sshd\n\nfiles:\n  - source: /etc/exherbo/ssh_config.sample\n    destination: /etc/ssh/sshd_config\n```\n\nCe fichier indique qu'Exherbo doit installer les paquets `vim` et `git`, activer le service `sshd`, et copier le fichier `/etc/exherbo/ssh_config.sample` vers `/etc/ssh/sshd_config`.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n- **Idémpotence:**  La plus grande force d'Exherbo.  On peut l'exécuter plusieurs fois sans risque de modifications indésirables.\n- **Simplicité:** Le langage de configuration est clair et facile à apprendre.\n- **Robustesse:**  Exherbo est conçu pour être fiable et gérer les erreurs de manière robuste.\n- **Open-source:**  Librement disponible et auditable.\n- **Focalisation:**  Contrairement à certains outils plus vastes, Exherbo se concentre sur la gestion de configurations système, ce qui le rend efficace et spécialisé.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n- **Communauté plus petite:**  Comparé à des outils comme Ansible ou Puppet, Exherbo possède une communauté plus restreinte, ce qui peut rendre la recherche de solutions à des problèmes spécifiques plus difficile.\n- **Moins de fonctionnalités avancées:**  Exherbo ne propose pas toutes les fonctionnalités avancées que l'on trouve dans des outils plus complets.  Par exemple, il n'intègre pas nativement la gestion de configurations à distance.\n- **Documentation limitée (potentiellement):** La documentation pourrait être plus complète pour certains aspects.  (Ceci dépend de l'état actuel du projet).\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "cbf62fa1-f5fb-481f-b040-5e0282fe3793",
        "title": "Gestion des artefacts",
        "shortDescription": "",
        "description": "---\nid: c71d6e3d-3d47-4940-96b9-6a8aaf0e2a53\n---\n# Rapidement c'est quoi❓\n\nLa gestion des artefacts est le processus de stockage, de récupération et de gestion de fichiers produits lors du cycle de vie du développement logiciel.  Cela inclut le code source compilé, les bibliothèques, les packages d'installation, etc.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLa gestion des artefacts est une partie cruciale de la gestion de configuration logicielle et de l'intégration continue/livraison continue (CI/CD). Elle assure le suivi des versions de tous les composants logiciels, permettant une traçabilité complète et facilitant la reconstruction et le déploiement de logiciels à partir d'artefacts archivés.  Un artefact est n'importe quel produit tangible du processus de développement,  comme un fichier JAR, un WAR, un fichier exécutable, un script d'installation, ou même un document de spécification.\n\nUn système de gestion d'artefacts efficace doit fournir des fonctionnalités telles que :\n\n* **Stockage:**  Un dépôt centralisé pour stocker les artefacts, souvent avec versioning (contrôle de version).  Des solutions comme les buckets Amazon S3, des référentiels Maven ou npm, ou des solutions dédiées comme JFrog Artifactory ou Nexus sont couramment utilisées.\n* **Récupération:**  Mécanismes pour récupérer facilement les versions spécifiques d'artefacts.\n* **Métadonnées:**  Stockage d'informations sur les artefacts (date de création, version, auteur, dépendances, etc.) pour une meilleure organisation et recherche.\n* **Intégration:**  Intégration transparente avec les outils CI/CD pour automatiser le déploiement et la gestion des versions.\n* **Sécurité:** Contrôle d'accès et authentification pour garantir l'intégrité et la sécurité des artefacts.\n\n\nL'exemple `maven-s3-wagon` mentionné utilise les buckets S3 d'Amazon comme dépôt pour les artefacts Maven, démontrant comment un système de stockage cloud peut être utilisé pour la gestion d'artefacts.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Traçabilité améliorée:**  Permet de suivre facilement l'évolution du logiciel et de retrouver des versions spécifiques.\n* **Réduction des erreurs:**  Minimise les risques liés à l'utilisation de versions incorrectes ou incompatibles des composants.\n* **Automatisation:**  Intégration facile avec les pipelines CI/CD pour automatiser le processus de construction, de test et de déploiement.\n* **Collaboration améliorée:**  Facilite le partage des artefacts entre les membres de l'équipe de développement.\n* **Scalabilité:**  Les solutions modernes de gestion d'artefacts peuvent facilement s'adapter à des projets de grande envergure.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:**  La mise en place et la gestion d'un système de gestion d'artefacts peuvent être complexes, surtout pour les petits projets.\n* **Coût:**  Certaines solutions (comme les services cloud) peuvent engendrer des coûts importants en fonction de l'utilisation.\n* **Surcharge:**  Une mauvaise gestion peut conduire à une accumulation d'artefacts inutiles, rendant le système difficile à gérer.\n* **Dépendances:**  Une dépendance forte à un système de gestion d'artefacts peut créer un point de défaillance unique.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "25a68590-b3ad-459f-8628-f0d9b608d2ce",
        "title": "Gotify",
        "shortDescription": "",
        "description": "---\nid: 1f7e13b1-9b4b-476d-9712-0229556402bd\n---\n# Gotify: Rapidement c'est quoi❓\n\nUn serveur open-source léger et simple pour envoyer et recevoir des notifications.  Il utilise une API RESTful pour une intégration facile avec d'autres applications et services.\n\n---\n# Gotify: Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nGotify est un serveur de notification auto-hébergeable, conçu pour être simple à utiliser et à déployer.  Il fonctionne en recevant des messages de notification via son API REST, puis en les redistribuant aux clients connectés.  Ces clients peuvent être des applications mobiles (Android, iOS), des applications de bureau (Windows, macOS, Linux), ou même des scripts personnalisés.  Gotify supporte plusieurs méthodes d'authentification, incluant des clés API et une authentification par mot de passe, pour sécuriser l'envoi des notifications.  Le serveur lui-même est très léger, nécessitant peu de ressources et pouvant être facilement déployé sur un Raspberry Pi ou un serveur cloud.  Il est écrit en Go, d'où son nom, et propose une interface web simple pour la gestion des utilisateurs, des applications et des messages.  Les notifications peuvent être personnalisées avec des titres, des messages, et des priorités.  Gotify ne conserve pas d'historique des notifications par défaut, mais des solutions existent pour la journalisation externe si nécessaire.\n\n---\n# Gotify: Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Simplicité:**  Installation, configuration et utilisation extrêmement faciles.\n* **Flexibilité:** API REST complète permettant l'intégration avec une grande variété d'applications et de services.\n* **Léger:**  Nécessite peu de ressources serveur.\n* **Open-source:**  Code source disponible, permettant une analyse et une adaptation du logiciel.\n* **Auto-hébergeable:** Contrôle total sur vos données et votre infrastructure.\n* **Multi-plateforme:** Clients disponibles pour de nombreux systèmes d'exploitation.\n\n---\n# Gotify: Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Fonctionnalités limitées:**  Par rapport à des solutions plus complètes, Gotify manque de certaines fonctionnalités avancées comme la planification des notifications ou une intégration native avec des services spécifiques.\n* **Gestion de l'historique limitée:**  Pas de stockage d'historique des notifications intégré par défaut.  Nécessite une solution externe pour cette fonctionnalité.\n* **Dépendance à un serveur:**  Nécessite le maintien d'un serveur actif pour fonctionner.\n\n\n---\n# Gotify: A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "bf22a8e7-bac3-452e-8c34-a26fdb615473",
        "title": "Gulp",
        "shortDescription": "",
        "description": "---\nid: 17e65120-21b5-485c-99e6-c77162ee080c\n---\n# **Rapidement, c'est quoi ? ❓**\n\nGulp est un outil open-source basé sur Node.js servant à automatiser des tâches de développement web.  Il permet de simplifier et d'accélérer des processus répétitifs comme la minification de code, la compilation de préprocesseurs CSS (Sass, Less), la concaténation de fichiers, et le rafraîchissement automatique du navigateur.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nGulp utilise un système de flux (streams) pour traiter les fichiers.  Un flux est un ensemble de données qui traverse une série de transformations.  Au lieu de lire et d'écrire des fichiers entiers à chaque étape, Gulp travaille sur des flux, ce qui le rend beaucoup plus performant que les outils concurrents qui traitent les fichiers de manière plus linéaire.  L'utilisateur définit une série de tâches (tasks) dans un fichier `gulpfile.js`. Chaque tâche utilise des plugins pour exécuter des opérations spécifiques sur les fichiers qui la traversent.\n\n**Exemple concret : Minification de fichiers CSS et JS**\n\nPour minifier les fichiers CSS et JS d'un projet, on pourrait écrire un `gulpfile.js` comme ceci :\n\n```javascript\nconst gulp = require('gulp');\nconst cssmin = require('gulp-cssmin');\nconst uglify = require('gulp-uglify');\n\n// Tâche pour minifier les fichiers CSS\ngulp.task('minify-css', () => {\n  return gulp.src('src/css/*.css')\n    .pipe(cssmin())\n    .pipe(gulp.dest('dist/css'));\n});\n\n// Tâche pour minifier les fichiers JS\ngulp.task('minify-js', () => {\n  return gulp.src('src/js/*.js')\n    .pipe(uglify())\n    .pipe(gulp.dest('dist/js'));\n});\n\n// Tâche par défaut qui exécute les deux tâches précédentes\ngulp.task('default', gulp.parallel('minify-css', 'minify-js'));\n```\n\nCe code utilise les plugins `gulp-cssmin` et `gulp-uglify` pour minifier respectivement les fichiers CSS et JS.  La commande `gulp` dans le terminal exécuterait la tâche `default`, qui à son tour exécuterait `minify-css` et `minify-js`.\n\n**Fonctionnement interne:** Gulp utilise Node.js et le module `vinyl-fs` pour gérer les fichiers.  Les plugins Gulp sont des modules Node.js qui interagissent avec les flux de données et effectuent les transformations souhaitées.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Performance:** L'utilisation des flux rend Gulp très rapide et efficace, surtout sur de grands projets.\n* **Modularité:** Le système de plugins permet une grande extensibilité et la possibilité d'utiliser des outils tiers.\n* **Lisibilité:** Le code des `gulpfile.js` est généralement plus clair et plus facile à maintenir que celui d'autres outils similaires.\n* **Declaratif:** La définition des tâches est simple et intuitive.\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage:** Bien que la syntaxe soit simple, la compréhension du système de flux et l'utilisation des plugins peut nécessiter un temps d'apprentissage.\n* **Dépendances:** Gulp repose sur Node.js et nécessite l'installation de plusieurs plugins, ce qui peut complexifier la configuration.\n* **Maintenance:** La communauté autour de Gulp est moins active qu'avant, certains plugins peuvent devenir obsolètes.\n* **Alternatives:** Des outils comme npm scripts, Parcel et Webpack offrent des fonctionnalités similaires, parfois plus intégrées et complètes.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "bbad9982-49d3-4aef-93d5-075605177c94",
        "title": "JFrog Artifactory",
        "shortDescription": "",
        "description": "---\nid: b5d82f2c-3c72-483c-8599-9e87e733a492\n---\n# Rapidement c'est quoi❓\n\nJFrog Artifactory est un gestionnaire universel d'artefacts logiciels.  Il stocke, gère et distribue tous types de paquets logiciels, des bibliothèques Java aux images Docker.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nJFrog Artifactory est un serveur de gestion d'artefacts (repository manager) qui fournit un référentiel centralisé pour stocker et gérer tous les types d'artefacts logiciels utilisés dans un cycle de développement DevOps.  Il supporte un large éventail de formats de paquets, incluant (mais sans s'y limiter) : Maven, Gradle, npm, NuGet, Python (pip), Docker, Helm, Debian, RPM et bien d'autres.\n\nAu-delà du simple stockage, Artifactory offre des fonctionnalités avancées telles que :\n\n* **Gestion de versions:**  Suivi des différentes versions des artefacts, permettant un rollback facile.\n* **Contrôle d'accès:**  Gestion fine des permissions pour garantir la sécurité et le contrôle des accès aux artefacts.\n* **Intégration CI/CD:**  Intégration transparente avec les outils d'intégration continue et de livraison continue (CI/CD) pour automatiser le déploiement.\n* **Réplication:**  Possibilité de répliquer les référentiels pour une haute disponibilité et une meilleure performance.\n* **Recherche et analyse:**  Fonctions de recherche avancées et d'analyse des artefacts pour une meilleure visibilité.\n* **Promotion de versions:**  Gestion du cycle de vie des artefacts, de la phase de développement à la production, via un système de promotion entre les différents référentiels (par exemple, de \"développement\" à \"staging\" puis à \"production\").\n* **Virtual Repositories:**  Création de référentiels virtuels combinant plusieurs référentiels physiques pour une meilleure organisation et simplification de la configuration client.\n* **Support de plusieurs protocoles:**  Accès aux artefacts via divers protocoles comme HTTP, HTTPS, SFTP, etc.\n\n\nArtifactory permet ainsi d'améliorer la collaboration entre les équipes de développement, de simplifier la gestion des dépendances et d'accélérer le processus de livraison continue.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Support multi-langages et multi-formats:**  Gestion d'un très grand nombre de types d'artefacts.\n* **Fonctionnalités avancées:**  Gestion des versions, contrôle d'accès fin, intégration CI/CD robuste, etc.\n* **Haute disponibilité et scalabilité:**  Possibilité de configuration pour la haute disponibilité et la gestion de volumes importants d'artefacts.\n* **Interface utilisateur intuitive:**  L'interface utilisateur est généralement considérée comme conviviale et facile à utiliser.\n* **Intégration avec d'autres outils JFrog:**  Synergie avec d'autres outils de l'écosystème JFrog, comme Xray (analyse de vulnérabilités).\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Prix:**  Artifactory peut être coûteux, surtout pour les grandes organisations avec de nombreux utilisateurs et de gros volumes d'artefacts.\n* **Complexité:**  La configuration et l'administration d'Artifactory peuvent être complexes pour des utilisateurs moins expérimentés.\n* **Ressources requises:**  Nécessite des ressources serveur significatives pour gérer de gros volumes d'artefacts.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n# JFrog Artifactory\n\n## Rapidement, c'est quoi ? \uD83E\uDD14\n\nJFrog Artifactory est un gestionnaire universel d'artefacts logiciels.  Imaginez un entrepôt centralisé qui stocke et gère tous les composants nécessaires à vos applications, des plus petites librairies aux plus grosses images Docker.\n\n## Plus précisément, c'est quoi / ça fait quoi ? \uD83D\uDD0D\n\nJFrog Artifactory est un serveur de gestion d'artefacts (repository manager). Il centralise le stockage et la gestion de tous les types d'artefacts logiciels utilisés dans un cycle de développement DevOps.  Il supporte une multitude de formats, parmi lesquels : Maven, Gradle, npm, NuGet, Python (pip), Docker, Helm, Debian, RPM, et bien d'autres.\n\n**Au-delà du simple stockage, Artifactory offre des fonctionnalités essentielles pour un workflow DevOps efficace :**\n\n* **Gestion de versions:**  Suivi précis des versions, facilitant les rollbacks (retour à une version antérieure).  Imaginez pouvoir facilement revenir à une version stable de votre application en cas de problème.\n* **Contrôle d'accès:**  Permissions granulaires pour sécuriser l'accès aux artefacts.  Seuls les utilisateurs autorisés peuvent accéder à certains composants.\n* **Intégration CI/CD:**  Intégration fluide avec vos outils CI/CD ([Concept supprimé]) pour automatiser les déploiements.  Cela accélère le cycle de développement et réduit les erreurs manuelles.\n* **Réplication:**  Réplication des référentiels pour haute disponibilité et performances accrues.  Vos artefacts sont disponibles même en cas de panne d'un serveur.\n* **Recherche et analyse:**  Recherche puissante et analyse des artefacts pour une meilleure visibilité sur votre écosystème logiciel.\n* **Promotion de versions:**  Gestion du cycle de vie des artefacts, de développement à production, via un système de promotion entre référentiels (ex: \"dev\" -> \"staging\" -> \"prod\").  Cela permet un contrôle rigoureux des déploiements.\n* **Virtual Repositories:**  Création de référentiels virtuels combinant plusieurs référentiels physiques pour simplifier la configuration client.  Cela simplifie grandement l'accès aux artefacts pour les développeurs.\n* **Support de plusieurs protocoles:**  Accès aux artefacts via HTTP, HTTPS, SFTP, etc.  Flexibilité d'intégration avec différents environnements.\n\n\nEn résumé, Artifactory améliore la collaboration, simplifie la gestion des dépendances et accélère la livraison continue.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Support multi-langages et multi-formats:**  Gestion d'une large variété d'artefacts.\n* **Fonctionnalités avancées:**  Gestion de versions, contrôle d'accès fin, intégration CI/CD robuste.\n* **Haute disponibilité et scalabilité:**  Adaptable à des besoins croissants.\n* **Interface utilisateur intuitive:**  Facile à prendre en main.\n* **Intégration avec d'autres outils JFrog:**  Synergie avec Xray (analyse de vulnérabilités) par exemple.\n\n\n## Qu'est-ce qui est moins bien ? \uD83D\uDC4E\n\n* **Prix:**  Peut être coûteux pour les grandes organisations.\n* **Complexité:**  Configuration avancée pouvant être complexe.\n* **Ressources requises:**  Nécessite des ressources serveur importantes pour gérer de gros volumes.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n* [Gestion des artefacts]\n* [CI/CD] (Intégration Continue / Livraison Continue)\n* [Docker] (Pour la gestion des images conteneurisées)\n\n\n## Exemple de configuration d'un référentiel Maven dans Artifactory (snippet):\n\n```yaml\nrepositories:\n  - repoKey: libs-release-local\n    repositoryType: local\n    packageType: maven\n    description: Local Maven repository for releases\n```\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "b54a6baf-dffc-4f42-abf8-54d421bfd881",
        "title": "JMeter",
        "shortDescription": "",
        "description": "---\nid: 0635b1b3-d5fa-4382-8668-72e0ccd88568\n---\n# Rapidement c'est quoi❓\n\nJMeter est un outil open-source de test de performance et de charge pour des applications web et autres.  Il permet de simuler un grand nombre d'utilisateurs simultanés pour mesurer la capacité de réponse et la stabilité d'un système.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nJMeter est un outil de test de performance écrit en Java. Il permet de simuler un important volume de requêtes sur un serveur, une application web ou un autre système afin d'en évaluer les performances et la robustesse sous forte charge.  Il offre la possibilité de créer des scénarios de test complexes, incluant des éléments comme :\n\n* **Requêtes HTTP/HTTPS:**  Simuler des navigations web, des appels d'API REST, etc.  Il supporte différents protocoles et méthodes HTTP.\n* **Tests de base de données:** Tester les performances des requêtes SQL sur différentes bases de données.\n* **Tests FTP:** Tester les performances des transferts de fichiers FTP.\n* **Tests de performances JMS:** Tester les performances de la messagerie JMS.\n* **Tests LDAP:** Tester les performances des services LDAP.\n* **Éléments de configuration:**  Contrôler les aspects du test, comme les temporisations, les boucles, les assertions, etc.\n* **Écouteurs:**  Collecter et visualiser les résultats des tests, sous forme de tableaux, de graphiques, et de rapports détaillés (temps de réponse, nombre d'erreurs, temps d'attente, etc.).\n* **Assertions:** Vérifier si la réponse du serveur correspond aux attentes (codes de statut HTTP, contenu de la réponse, etc.).\n\nJMeter est très flexible et extensible grâce à ses nombreux plugins et son architecture modulaire.  Il permet d'intégrer des scripts personnalisés et d'automatiser des tâches de test complexes. Les résultats des tests permettent d'identifier les goulots d'étranglement et d'optimiser les performances de l'application testée.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open-source et gratuit:**  Accessible à tous sans coût de licence.\n* **Large communauté et documentation:**  Facile d'obtenir de l'aide et des ressources en cas de besoin.\n* **Flexible et extensible:**  Adaptable à une grande variété de scénarios de test grâce à ses plugins et fonctionnalités.\n* **Interface graphique intuitive (pour la création des tests):**  Relativement facile à prendre en main, même pour les débutants.\n* **Rapports détaillés:**  Fournit des informations complètes sur les performances du système testé.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Consommation de ressources:**  Peut consommer beaucoup de ressources (mémoire, CPU) lors de la simulation de charges importantes, surtout sur une seule machine.\n* **Courbe d'apprentissage:**  Bien que l'interface soit intuitive pour les tests simples, la création de tests complexes et l'interprétation des résultats avancés peuvent nécessiter une certaine expertise.\n* **Interface graphique peu performante pour les gros tests:**  L'interface graphique peut devenir lente et réactive avec de très grands tests.  L'utilisation de mode non-GUI est alors conseillée.\n* **Débogage parfois complexe:**  Identifier la source des erreurs dans des scénarios de test complexes peut être difficile.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "304b6f37-1909-4af5-a92b-bc4e62895631",
        "title": "Jaeger",
        "shortDescription": "",
        "description": "---\nid: dba8623c-06a9-4387-a258-3a4acaaca56f\n---\n# **Rapidement, c'est quoi ? ❓**\n\nJaeger est un système de traçage distribué open-source qui permet de surveiller et de déboguer les applications distribuées.  Il collecte et visualise les traces des requêtes traversant différents services, permettant ainsi d'identifier les goulots d'étranglement et les erreurs.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nJaeger implémente le standard OpenTracing (maintenant OpenTelemetry) pour le traçage distribué.  Il est composé de plusieurs composants principaux :\n\n* **Agent:** Un agent léger qui s'exécute sur chaque service et collecte les traces. Il envoie ces traces au collecteur.\n* **Collecteur:** Un service qui reçoit les traces de plusieurs agents et les traite.  Il peut être configuré pour stocker les traces dans une base de données (ex: Cassandra, Elasticsearch).\n* **Query:** Un service qui permet de rechercher et de visualiser les traces via une interface utilisateur web.\n* **Ingest:** Le composant qui reçoit les données brutes du traceur et les envoie au backend de stockage.\n\nLe fonctionnement se résume ainsi:\n\n1. Une application instrumente son code pour injecter des spans (unités de travail) dans le flux de la requête.  Ces spans contiennent des informations contextuelles comme le nom de l'opération, la durée et des tags.\n2. L'agent Jaeger, en local, collecte ces spans et les envoie au collecteur.\n3. Le collecteur traite les données et les stocke dans une base de données.\n4. L'interface utilisateur permet de visualiser les traces, de filtrer par service, par tag, etc.  On peut ainsi suivre le parcours d'une requête à travers l'ensemble de l'infrastructure.\n\n**Exemple (Python avec opentelemetry):**\n\n```python\nfrom opentelemetry import trace\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.sdk.resources import SERVICE_NAME, Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\n\nresource = Resource.get_empty().merge({SERVICE_NAME: \"my_service\"})\ntrace.set_tracer_provider(TracerProvider(resource=resource))\njaeger_exporter = JaegerExporter(agent_host_name='localhost', agent_port=6831)\nspan_processor = BatchSpanProcessor(jaeger_exporter)\ntrace.get_tracer_provider().add_span_processor(span_processor)\n\ntracer = trace.get_tracer(__name__)\nwith tracer.start_as_current_span(\"main_function\"):\n    with tracer.start_as_current_span(\"sub_function\"):\n        # ... code ...\n        pass\n    # ... code ...\n    pass\n```\n\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Open Source et mature:**  Jaeger est un projet stable et largement adopté.\n* **Interface utilisateur intuitive:** La visualisation des traces est facile à comprendre et à utiliser.\n* **Intégration avec plusieurs technologies:**  Jaeger s'intègre facilement avec de nombreux langages de programmation et frameworks.\n* **Scalabilité:**  Jaeger est conçu pour gérer un grand nombre de traces.\n* **Support de différents backends de stockage:**  On peut choisir le stockage qui convient le mieux à son infrastructure.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité de configuration:**  La configuration peut être complexe, notamment pour des déploiements à grande échelle.\n* **Surcoût de performance:**  L'instrumentation et la collecte des traces peuvent avoir un léger impact sur les performances de l'application.  Une instrumentation mal faite peut amplifier ce problème.\n* **Nécessite un backend de stockage:**  Jaeger ne fonctionne pas sans un backend de stockage pour les traces.  Ceci ajoute une dépendance supplémentaire.\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "6234d20e-2789-4aed-a6a5-ee646881890d",
        "title": "Jitpack",
        "shortDescription": "",
        "description": "---\nid: f7b3616a-498c-4574-a2d9-4d5a46afee0e\n---\n# Rapidement c'est quoi❓\n\nJitPack est un service d'hébergement et de distribution d'artefacts Java et Kotlin.  Il permet d'intégrer facilement des librairies hébergées sur des dépôts Git (GitHub, GitLab, Bitbucket) directement dans vos projets.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nJitPack est un référentiel Maven et Gradle qui automatise la construction et la publication de bibliothèques Java et Kotlin à partir de dépôts Git.  Au lieu de publier vos librairies manuellement sur des référentiels comme Maven Central, vous fournissez simplement JitPack avec l'URL de votre dépôt Git (public ou privé, mais les privés nécessitent un abonnement payant). JitPack se charge ensuite de :\n\n1. **Cloner votre dépôt Git:** Il récupère le code source de votre projet.\n2. **Construire votre projet:** Il utilise un environnement de build (Maven ou Gradle) défini dans votre projet pour compiler votre code et générer les artefacts (JAR, AAR, etc.).\n3. **Publier les artefacts:** Il met à disposition les artefacts compilés via son propre référentiel, accessible via des coordonnées Maven ou Gradle.\n\nCela permet aux développeurs d'intégrer vos librairies directement dans leurs projets via un simple ajout de dépendances dans leur fichier `build.gradle` (ou équivalent).  JitPack surveille les modifications dans votre dépôt Git et met à jour les artefacts automatiquement, facilitant ainsi la gestion des versions et la mise à jour des librairies.  L'intégration est transparente pour le développeur qui n'a pas besoin de gérer la publication des artefacts.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Simplicité d'utilisation:**  Intégration facile et rapide grâce à l'ajout d'une simple dépendance dans votre fichier de build.\n* **Automatisation:** JitPack automatise le processus de compilation et de publication, réduisant ainsi le temps et l'effort nécessaire.\n* **Mise à jour automatique:** Les mises à jour du dépôt Git sont automatiquement reflétées dans le référentiel JitPack.\n* **Intégration avec les dépôts Git populaires:**  Fonctionne avec GitHub, GitLab et Bitbucket.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Coût pour les dépôts privés:** L'utilisation de dépôts Git privés nécessite un abonnement payant.\n* **Dépendance à JitPack:** Votre projet dépend d'un service tiers, ce qui introduit un point de défaillance potentiel.\n* **Performances:**  La construction et le déploiement peuvent être plus lents que sur un serveur de build dédié.\n* **Contrôle limité:** Vous avez moins de contrôle sur le processus de build que si vous gérez vous-même la publication de vos artefacts.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "39981e27-4afb-40f9-a0b7-7ab17fc52da6",
        "title": "K6",
        "shortDescription": "",
        "description": "---\nid: 31ca0fd2-70a8-43d5-8c3c-250984ee0d52\n---\n# Rapidement, c'est quoi ? ❓\n\nk6 est un outil open-source de test de charge et de performance écrit en Go.  Il permet de simuler un grand nombre d'utilisateurs simultanés interagissant avec une application web ou un service afin d'évaluer sa capacité à gérer la charge et d'identifier les goulots d'étranglement.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nk6 permet de définir des scénarios de test en utilisant un langage de script simple et puissant basé sur JavaScript.  Ces scripts définissent les actions que les utilisateurs virtuels doivent réaliser (requêtes HTTP, interactions avec l'interface utilisateur, etc.).  k6 exécute ensuite ces scripts en parallèle, simulant ainsi une charge importante sur le système testé.  L'outil collecte diverses métriques de performance (temps de réponse, taux d'erreur, utilisation des ressources serveur, etc.) et les présente sous forme de rapports et de graphiques.\n\nVoici un exemple simple de script k6:\n\n```javascript\nimport http from 'k6/http';\nimport { sleep } from 'k6';\n\nexport let options = {\n  stages: [\n    { duration: '30s', target: 20 }, // Simuler 20 utilisateurs pendant 30 secondes\n    { duration: '1m', target: 20 }, // Maintenir 20 utilisateurs pendant 1 minute\n    { duration: '30s', target: 0 },  // Ramener le nombre d'utilisateurs à 0 pendant 30 secondes\n  ],\n};\n\nexport default function () {\n  let res = http.get('https://test-api.com/users');\n  sleep(1); // Attendre 1 seconde avant la prochaine requête\n  check(res, { 'status was 200': (r) => r.status === 200 });\n}\n```\n\nCe script simule 20 utilisateurs effectuant une requête GET sur une API pendant une minute et demie.  `check` permet de valider que la réponse a un code de statut 200.  L'option `stages` définit l'évolution du nombre d'utilisateurs virtuels au cours du test.\n\nk6 offre des fonctionnalités avancées telles que :\n\n* **Intégration avec des outils d'observation:**  k6 peut envoyer des métriques vers des systèmes de monitoring comme Prometheus, Grafana, InfluxDB.\n* **Scripts modulaires et réutilisables:**  Les scripts k6 peuvent être organisés en modules pour faciliter la maintenance et le partage de code.\n* **Tests de charge basés sur des scénarios réalistes:**  Il est possible de simuler des comportements d'utilisateurs plus complexes, en incluant des temps d'attente, des distributions aléatoires, etc.\n* **Support des protocoles HTTP/1.1, HTTP/2, et WebSocket:**  k6 permet de tester une large gamme d'applications.\n\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Open-source et gratuit:** k6 est librement disponible et utilisable.\n* **Langage de script simple et puissant:**  Le JavaScript utilisé est relativement facile à apprendre et permet de créer des tests complexes.\n* **Résultats clairs et concis:**  k6 fournit des rapports détaillés et des visualisations graphiques des résultats.\n* **Intégration facile avec l'écosystème DevOps:**  k6 s'intègre bien avec d'autres outils populaires.\n* **Performance et stabilité:**  k6 est performant et robuste.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:** Bien que le langage de script soit simple, une certaine familiarité avec JavaScript est nécessaire pour créer des tests sophistiqués.\n* **Débogage:** Le débogage des scripts peut être parfois complexe.  Des outils spécifiques sont nécessaires pour un débogage efficace.\n* **Limitations pour les tests UI complexes:** Bien que possible,  tester des applications avec de nombreuses interactions UI complexes peut être plus difficile qu'avec d'autres outils spécialisés dans les tests d'interface utilisateur.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "ff09cb51-6aea-4704-908c-b252fcebb82b",
        "title": "Karate",
        "shortDescription": "",
        "description": "---\nid: 1c914381-073b-493f-9b0e-f8c82b8f9e98\n---\n# Rapidement c'est quoi❓\n\nKarate DSL est un framework open-source basé sur Cucumber (Gherkin) pour l'automatisation des tests, notamment pour les API, mais aussi pour les applications web et les applications desktop.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nKarate est un framework de test d'intégration basé sur le langage [[Gherkin]], connu pour sa syntaxe simple et lisible (BDD - Behavior Driven Development).  Il permet de décrire les scénarios de test de manière concise et compréhensible par les équipes techniques et non-techniques.  Au lieu d'écrire du code complexe, on décrit le comportement attendu de l'application via des mots clés simples.  Karate s'occupe ensuite de l'exécution et de la validation.\n\nKarate offre une grande flexibilité et peut être utilisé pour tester différents types d'applications :\n\n* **API REST :** C'est son utilisation principale. Il permet d'envoyer des requêtes HTTP (GET, POST, PUT, DELETE, etc.), de valider les réponses (codes de statut, corps JSON, etc.) et de gérer l'authentification.\n* **Applications Web :**  Karate peut interagir avec des applications web via son intégration avec des outils comme Selenium, permettant de simuler des actions utilisateur.\n* **Applications Desktop :**  Bien que moins courant, Karate peut être utilisé pour tester des applications desktop grâce à son API extensible.\n* **Tests de performance de base :**  Karate permet d’effectuer des tests de charge légers, notamment grâce à ses capacités de parallélisation.\n\nKarate utilise un puissant moteur de matching JSON qui simplifie les validations. Il propose également des fonctionnalités avancées telles que la gestion des données de test, la génération de rapports et l'intégration avec des systèmes de CI/CD.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Syntaxe simple et lisible (Gherkin) :** Rend les tests faciles à comprendre et à maintenir.\n* **Polyvalence :** Permet de tester des API REST, des applications web et même des applications desktop.\n* **Intégration facile :** S'intègre bien avec de nombreux outils et technologies.\n* **Gestion avancée des données de test :** Simplifie la gestion des données d'entrée.\n* **Puissant moteur de matching JSON :** Facilite la validation des réponses API.\n* **Reporting clair et concis :** Facilite l'analyse des résultats.\n* **Communauté active et documentation assez complète:** Facilite le démarrage et l'apprentissage.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Pour les tests UI complexes, il peut être moins performant que des outils dédiés comme Selenium ou Cypress:** Il est plus adapté pour la validation de l'API qui sous-tend l'UI plutôt que la validation de l'expérience utilisateur elle-même.\n* **Courbe d'apprentissage légèrement plus raide que des outils plus simples pour les débutants complets en test.**  La maîtrise des expressions régulières et des manipulations JSON est un atout.\n* **Moins de plugins disponibles qu'avec des frameworks plus établis** pour les tests UI.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "4f9fb72d-9eb3-4874-b3cf-2aea798c1efa",
        "title": "LowDb",
        "shortDescription": "",
        "description": "---\nid: 1f2a7d57-7f12-4d6a-8ad5-d1eb8ef07f91\n---\n## **Rapidement, c'est quoi ? ❓**\n\nLowDB est une petite base de données JavaScript légère, basée sur un fichier JSON.  Elle est idéale pour les applications qui n'ont pas besoin d'une base de données relationnelle complexe et qui veulent un stockage persistant simple et rapide.\n\n---\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLowDB est une base de données NoSQL orientée document.  Cela signifie qu'elle stocke les données sous forme de documents JSON, sans le besoin de schémas rigides.  Elle utilise un seul fichier JSON comme stockage persistant, ce qui la rend facile à déployer et à utiliser.  LowDB fournit une API simple et intuitive pour effectuer des opérations CRUD (Créer, Lire, Mettre à jour, Supprimer) sur les données.  Elle est basée sur Lodash, ce qui facilite l'utilisation de ses fonctions de manipulation de données.  Elle ne nécessite aucune configuration de serveur, ni aucune dépendance externe autre que Lodash.\n\nVoici un exemple d'utilisation en JavaScript :\n\n```javascript\nconst low = require('lowdb')\nconst FileSync = require('lowdb/adapters/FileSync')\n\nconst adapter = new FileSync('db.json')\nconst db = low(adapter)\n\n// Set some defaults (optional)\ndb.defaults({ users: [], posts: [] })\n  .write()\n\n// Add a user\ndb.get('users').push({ id: 1, name: 'John' }).write()\n\n// Find a user\nconst john = db.get('users').find({ id: 1 }).value()\n\n// Update a user\ndb.get('users').find({ id: 1 }).assign({ age: 30 }).write()\n\n// Remove a user\ndb.get('users').remove({ id: 1 }).write()\n\n// Read all users\nconst users = db.get('users').value()\n\nconsole.log(users)\n```\n\nCet exemple montre comment créer une base de données, ajouter, rechercher, mettre à jour et supprimer des utilisateurs.  La méthode `.write()` sauvegarde les modifications dans le fichier `db.json`.\n\n---\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Simplicité:**  Extrêmement facile à installer et à utiliser, avec une API intuitive.\n* **Léger:**  Très petite taille, ne surcharge pas l'application.\n* **Facile à déployer:**  Ne nécessite aucune configuration de serveur.\n* **Persistant:**  Stocke les données dans un fichier JSON, garantissant la persistance des données.\n* **Basé sur Lodash:**  Bénéficie de la puissance et de la flexibilité de Lodash pour la manipulation des données.\n\n---\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Scalabilité limitée:**  N'est pas conçue pour les applications à très grande échelle.  La performance peut dégrader avec des jeux de données importants.\n* **Transactions non supportées:**  Ne supporte pas les transactions, ce qui peut être un problème pour les applications nécessitant une cohérence forte des données.\n* **Concurrence limitée:**  La gestion de la concurrence n'est pas optimisée.  L'utilisation simultanée par plusieurs processus peut nécessiter des mécanismes de verrouillage externes.\n* **Fonctionnalités limitées:**  Ne propose pas autant de fonctionnalités qu'une base de données relationnelle ou un système de base de données NoSQL plus complet.\n\n---\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "2dd2c605-ae74-4ae6-8c67-dfd4a2df88ec",
        "title": "MQTT",
        "shortDescription": "",
        "description": "---\nid: 7b1fe336-18e3-4bbc-a2d1-4f869db47e43\n---\n# Rapidement c'est quoi❓\n\nMQTT (Message Queuing Telemetry Transport) est un protocole de messagerie léger, publié-abonné, utilisé principalement pour l'Internet des objets (IoT).  Il permet aux appareils de publier des messages sur des sujets spécifiques, et aux autres appareils abonnés à ces sujets de recevoir ces messages.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nMQTT est un protocole de communication machine-à-machine (M2M) basé sur le paradigme de publication-abonnement.  Il fonctionne sur le principe de \"sujets\" (topics) auxquels les clients (publishers et subscribers) s'abonnent.  Un éditeur (publisher) publie un message sur un sujet spécifique.  Tous les abonnés (subscribers) à ce sujet reçoivent alors une copie de ce message.  Ceci permet une communication unidirectionnelle efficace, idéale pour les applications à faible bande passante et à forte latence comme l'IoT.\n\nContrairement à d'autres protocoles de messagerie plus lourds, MQTT est conçu pour être léger et efficace en termes de bande passante et d'énergie.  Il utilise un format de message compact et gère les connexions intermittentes et les déconnexions.  Il offre différents niveaux de qualité de service (QoS) pour garantir la fiabilité de la livraison des messages :\n\n* **QoS 0 (At most once):** Le message est envoyé une seule fois, sans garantie de livraison.\n* **QoS 1 (At least once):** Le message est envoyé au moins une fois, le serveur envoie un accusé de réception.  Il est possible de recevoir le message plusieurs fois en cas de perte du message d'accusé de réception.\n* **QoS 2 (Exactly once):** Le message est envoyé exactement une fois, garantie de livraison et d'unicité.  C'est le niveau le plus robuste, mais aussi le plus coûteux en ressources.\n\nUn broker MQTT agit comme un intermédiaire centralisé, gérant les abonnements et la diffusion des messages entre les éditeurs et les abonnés.  Le publisher peut spécifier s'il attend une confirmation de réception (QoS 1 et 2) ou non (QoS 0).\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Léger et efficace:**  Idéal pour les appareils à faible puissance et bande passante limitée.\n* **Simple à implémenter:**  Protocole relativement simple à comprendre et à utiliser.\n* **Publication-abonnement efficace:**  Permet une communication unidirectionnelle scalable.\n* **Gestion des connexions intermittentes:**  Robuste face aux déconnexions et aux réseaux instables.\n* **Plusieurs niveaux de QoS:**  Offre des options de fiabilité pour adapter la communication aux besoins de l'application.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Pas adapté à toutes les applications:**  Moins approprié pour les applications nécessitant des transactions complexes ou une communication bidirectionnelle très réactive.\n* **Sécurité:**  Nécessite une attention particulière à la sécurité, surtout dans les environnements sensibles.  Des mécanismes d'authentification et de chiffrement sont importants.\n* **Complexité du Broker:** La gestion d'un broker MQTT peut devenir complexe pour un grand nombre d'appareils et de messages.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "2ac4eb26-18a4-4910-80a6-380bdeef9ae0",
        "title": "Macaron",
        "shortDescription": "",
        "description": "---\nid: 4ca900d5-f49d-4a08-8a97-35a6683ef57f\n---\n# Rapidement, c'est quoi ? ❓\n\nUn macaron est un jeton cryptographique utilisé pour l'authentification.  Il représente une alternative aux mécanismes d'authentification traditionnels, offrant une approche plus sécurisée et flexible.  On peut le voir comme une version plus simple et moins complexe d'un biscuit (développé par Clever Cloud).\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUn macaron est un jeton numérique, généralement encodé en base64, qui contient des informations chiffrées sur l'identité d'un utilisateur et ses autorisations.  Contrairement à un cookie HTTP classique, un macaron n'est pas directement stocké par le navigateur.  Son utilisation implique généralement un mécanisme d'échange entre le client (application, navigateur) et le serveur, souvent via un en-tête HTTP.\n\nLe serveur crée le macaron en incluant des données pertinentes (identifiant utilisateur, timestamp, rôles, etc.) et en les chiffrant symétriquement avec une clé secrète connue uniquement du serveur.  Le client reçoit et conserve le macaron.  Chaque requête subsequente au serveur inclut le macaron, qui est alors vérifié et déchiffré par le serveur pour authentifier l'utilisateur et valider ses autorisations.  Ceci évite de devoir transmettre des informations sensibles comme mots de passe à chaque requête.\n\nL'architecture précise de l'intégration des macarons peut varier, mais le principe central reste la génération, transmission et vérification sécurisée du jeton chiffré.\n\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Sécurité améliorée:** Le chiffrement du macaron protège les informations sensibles de l'utilisateur.  Le caractère éphémère du macaron (durée de vie limitée) renforce la sécurité.\n* **Simplicité (comparé aux systèmes plus complexes):**  Par rapport à des solutions d'authentification plus sophistiquées, le concept est relativement simple à mettre en œuvre.\n* **Flexibilité:** Les macarons peuvent être adaptés à divers contextes et protocoles.\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Gestion de la clé secrète:**  La sécurité du système dépend entièrement de la protection de la clé secrète utilisée pour chiffrer/déchiffrer les macarons.  Une compromission de cette clé compromet la sécurité de tout le système.\n* **Complexité d'implémentation (par rapport aux cookies simples):**  L'implémentation nécessite une gestion plus complexe que des cookies HTTP simples.\n* **Dépendance au serveur:**  La validité du macaron dépend entièrement du serveur.  Des problèmes de connectivité ou des pannes du serveur peuvent empêcher l'accès.\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "31d7445a-110f-47ad-b006-c15034db4caf",
        "title": "Mockoon",
        "shortDescription": "",
        "description": "---\nid: 6fbdf1a5-224a-40eb-8d39-f3a7b21e6fe8\n---\n# **Rapidement, c'est quoi ? ❓**\n\nMockoon est une application open-source permettant de créer et de gérer facilement des mocks d'API.  Elle permet de simuler des réponses HTTP pour des besoins de test et de développement, sans avoir besoin d'un serveur backend fonctionnel.\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nMockoon est un outil qui permet de définir des routes API, chacune associée à une réponse HTTP spécifique.  Ces réponses peuvent être configurées pour simuler différents statuts HTTP (200 OK, 404 Not Found, etc.), des en-têtes personnalisés, et des corps de réponse au format JSON, XML, ou texte brut.  L'application embarque un serveur qui rend ces mocks accessibles via une URL locale.  Les développeurs peuvent ainsi tester leurs applications front-end ou leurs intégrations sans dépendre d'un serveur backend en cours de développement ou indisponible.\n\nMockoon offre des fonctionnalités avancées telles que :\n\n* **Gestion des requêtes:**  Possibilité de définir des requêtes spécifiques (méthodes HTTP, headers, paramètres, corps de la requête) pour déclencher des réponses différentes.\n* **Mocks dynamiques:**  Les réponses peuvent être générées dynamiquement grâce à des fonctionnalités de templating (ex: utilisant des variables).\n* **Délai de réponse:**  Simulation de latence réseau pour des tests plus réalistes.\n* **Import/Export:**  Import et export de configurations au format JSON pour faciliter le partage et la sauvegarde.\n* **Environnements:**  Possibilité de gérer plusieurs environnements (développement, test, production) avec des configurations différentes.\n\n**Exemple simple (JSON):**\n\nImaginons une route `/users` qui doit retourner une liste d'utilisateurs.  Dans Mockoon, on définirait une route avec la méthode `GET`, l'URL `/users`, et un corps de réponse JSON comme suit :\n\n```json\n[\n  {\"id\": 1, \"name\": \"John Doe\"},\n  {\"id\": 2, \"name\": \"Jane Smith\"}\n]\n```\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Facilité d'utilisation:**  Interface utilisateur intuitive et facile à prendre en main.\n* **Open-source:**  Gratuit, et le code source est disponible pour un audit ou des contributions.\n* **Fonctionnalités complètes:**  Offre un ensemble complet de fonctionnalités pour la simulation d'API.\n* **Interface graphique:**  Permet une configuration visuelle et simple des mocks.\n* **Multiplateforme:**  Disponible pour Windows, macOS et Linux.\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Limitations pour les mocks complexes:**  Pour les cas d'utilisation très complexes nécessitant des interactions sophistiquées avec le serveur (authentification avancée, gestion d'état, etc.), Mockoon pourrait s'avérer moins adapté que des solutions plus spécialisées.\n* **Dépendance à une application:**  Contrairement à des solutions basées sur un script ou un fichier de configuration, Mockoon nécessite l'exécution de l'application.\n\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "3e904263-df71-47ca-a67f-c0e3adcd11bd",
        "title": "Nexus OSS",
        "shortDescription": "",
        "description": "---\nid: e34dad01-51d0-4b44-b981-ab5d072436c6\n---\n# Nexus OSS : Rapidement c'est quoi❓\n\nNexus OSS est un gestionnaire d'artefacts open-source.  Il permet de stocker et de gérer des paquets logiciels de différents types (Java, Python, Node.js, Docker, etc.) centralisant ainsi la distribution et la versioning de ces éléments au sein d'un projet.\n\n---\n# Nexus OSS : Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nNexus OSS est un serveur de gestion d'artefacts qui fournit un référentiel centralisé pour les dépendances de logiciels.  Il prend en charge une large variété de formats de paquets, incluant mais sans s'y limiter : Maven, npm, NuGet, Bower, PyPI, Docker, et beaucoup d'autres.  Son rôle principal est de faciliter la gestion du cycle de vie des artefacts, de leur création à leur déploiement.\n\nPlus concrètement, Nexus OSS permet :\n\n* **Stockage centralisé:**  Tous les artefacts d'un projet sont stockés dans un emplacement unique, facilitant l'accès et la gestion.\n* **Gestion de versions:** Nexus gère efficacement les différentes versions des artefacts, permettant de revenir à des versions précédentes si nécessaire.\n* **Proxy de référentiels:** Il peut agir comme un proxy pour des référentiels externes (comme Maven Central), réduisant la charge sur les réseaux et améliorant les performances.\n* **Création de référentiels privés:**  Permet de créer des référentiels privés pour héberger des artefacts internes, avant leur éventuelle publication publique.\n* **Contrôle d'accès:**  Offre des mécanismes de contrôle d'accès pour restreindre l'accès aux artefacts en fonction des rôles utilisateurs.\n* **Recherche et navigation:**  Fournit une interface utilisateur intuitive pour rechercher et naviguer parmi les artefacts stockés.\n* **Intégration CI/CD:**  S'intègre facilement aux pipelines CI/CD pour automatiser le processus de déploiement.\n\n\n---\n# Nexus OSS : Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Open-source et gratuit:**  Nexus OSS est disponible gratuitement et son code source est accessible.\n* **Large support de formats:**  Il gère un très grand nombre de types d'artefacts.\n* **Interface utilisateur conviviale:**  Navigation et recherche faciles.\n* **Fonctionnalités avancées:**  Gestion des versions, proxy, référentiels privés, contrôle d'accès.\n* **Communauté active:**  Une communauté importante fournit un support et contribue au développement.\n\n\n---\n# Nexus OSS : Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité de configuration:** La configuration initiale peut être complexe pour les utilisateurs débutants.\n* **Ressources serveur:**  Peut nécessiter des ressources serveur importantes pour gérer un grand nombre d'artefacts.\n* **Courbe d'apprentissage:**  Nécessite une certaine familiarisation avec les concepts de gestion d'artefacts.\n* **Dépendances Java:** Nécessite une machine virtuelle Java pour fonctionner.\n\n\n---\n# Nexus OSS : A quoi c'est lié ? \uD83E\uDEA2\n\n(à compléter)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "0e88d3df-da53-4647-8099-8872358acab6",
        "title": "NuxtHub",
        "shortDescription": "",
        "description": "---\nid: afb4d2a0-248c-4f80-9886-88258531a052\n---\n# Rapidement c'est quoi❓\n\nNuxtHub est une plateforme en ligne qui simplifie la gestion et le déploiement d'applications Nuxt.js sur le cloud Cloudflare.  Elle fournit une interface utilisateur intuitive pour gérer les projets, automatisant plusieurs tâches complexes.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nNuxtHub est un service de plateforme comme service (PaaS) spécifiquement conçu pour les applications web construites avec le framework JavaScript Nuxt.js.  Il offre une interface centralisée pour gérer tout le cycle de vie d'un projet Nuxt, du développement au déploiement.  Les fonctionnalités clés incluent :\n\n* **Gestion de projet:**  Création, organisation et suivi de multiples projets Nuxt.js depuis une seule interface.\n* **Déploiement automatisé:**  NuxtHub intègre directement le cloud Cloudflare, automatisant le processus de déploiement et rendant la mise en production simple et rapide.  Cela inclut la configuration du serveur, la gestion des certificats SSL et la mise à jour automatique.\n* **Environnements multiples:**  Possibilité de gérer différents environnements (développement, staging, production) pour chaque projet.\n* **Collaboration:**  Facilite la collaboration entre développeurs grâce à un système de contrôle d'accès et de gestion des utilisateurs.\n* **Supervision et monitoring:**  Outils de monitoring permettant de surveiller les performances et la stabilité des applications déployées.  (La nature précise de ces outils dépend de l'intégration avec Cloudflare.)\n* **Intégration CI/CD (potentielle):**  Bien que non explicitement mentionné, une plateforme comme NuxtHub est susceptible d'offrir ou de s'intégrer facilement à des pipelines CI/CD pour automatiser davantage le processus de développement et de déploiement.\n\n\nEn résumé, NuxtHub vise à simplifier le workflow des développeurs Nuxt.js en centralisant et en automatisant les tâches fastidieuses liées à la gestion et au déploiement d'applications.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Simplification du déploiement:** Le déploiement sur Cloudflare est grandement simplifié grâce à l'interface utilisateur intuitive.\n* **Centralisation de la gestion:** Gestion multi-projets facilitée.\n* **Automatisation des tâches:**  Réduction du temps et de l'effort nécessaires pour le déploiement et la maintenance.\n* **Intégration Cloudflare:** Bénéficie de l'infrastructure robuste et performante de Cloudflare.\n\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Dépendance à Cloudflare:**  Le déploiement est limité à Cloudflare.  Les développeurs souhaitant utiliser d'autres fournisseurs de cloud pourraient être limités.\n* **Potentielles limitations des fonctionnalités:** L'étendue exacte des fonctionnalités de monitoring et d'intégration CI/CD n'est pas toujours clairement définie.  Une évaluation approfondie est nécessaire.\n* **Coût:**  Le modèle de tarification peut constituer un inconvénient pour certains utilisateurs, nécessitant une analyse des coûts avant utilisation.\n* **Manque de contrôle (potentiel):**  Le niveau de contrôle sur l'infrastructure sous-jacente pourrait être inférieur à une configuration manuelle.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "42b53c23-df81-462b-94cb-78777ddbe672",
        "title": "Objet du testing",
        "shortDescription": "",
        "description": "---\nid: 2f7853dd-9d03-467b-99ae-804dd65e0865\n---\n## Rapidement, c'est quoi ? ❓\n\nLes objets de test (dummy, stub, mock, fake, spy) sont des outils utilisés dans le développement logiciel pour simuler le comportement de parties d'un système lors de tests unitaires ou d'intégration.  Ils permettent d'isoler le code testé et de contrôler son environnement, facilitant ainsi la détection de bugs et la validation du comportement attendu.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nVoici une description plus détaillée des différents types d'objets de test :\n\n* **Dummy:** Un objet simple servant à compléter une liste de paramètres. Il ne possède généralement aucune implémentation concrète et sert principalement à satisfaire les contraintes de signature d'une fonction ou d'une méthode sans avoir d'impact réel sur le test.\n\n    * **Exemple:** Un constructeur nécessitant trois paramètres, mais dont un seul est pertinent pour le test.  On utilise un `dummy` pour les deux autres.\n\n* **Stub:** Un objet qui remplace une dépendance et renvoie des valeurs prédéfinies.  Il simule un comportement spécifique sans exécuter le code réel de la dépendance.\n\n    * **Exemple:** Une fonction appelant une base de données.  Un `stub` simule la réponse de la base de données sans réellement interagir avec elle.  Cela permet de tester la fonction sans dépendre de l'état de la base de données.\n\n* **Mock:** Un objet plus sophistiqué qui vérifie non seulement les appels à des méthodes mais aussi leurs arguments.  Il permet de s'assurer que les interactions avec les dépendances se produisent comme prévu.  Il est généralement utilisé pour valider les interactions, pas juste les résultats.\n\n    * **Exemple:** Vérifier si une méthode `envoyerEmail` a été appelée avec les bons paramètres (adresse email, sujet, corps du message).\n\n* **Fake:** Un objet qui fournit une implémentation simplifiée d'une dépendance.  Il est souvent plus complet qu'un `stub` car il peut avoir une certaine logique interne, mais cette logique est plus simple et plus rapide que l'implémentation réelle.\n\n    * **Exemple:** Utiliser une liste en mémoire comme `fake` pour une base de données lors d'un test,  ce qui est plus rapide qu'une véritable connexion à une base de données.\n\n\n* **Spy:** Un objet qui enregistre les appels à une fonction ou une méthode sans modifier leur comportement.  Il permet d'observer les appels et de vérifier qu'ils ont eu lieu avec les paramètres attendus, sans influencer le comportement de la fonction espionnée.  Il sert souvent de complément à un `mock` ou un `stub`.\n\n    * **Exemple:** Utiliser un `spy` pour compter le nombre d'appels à une méthode spécifique.\n\n**Exemple (Python avec `unittest.mock`):**\n\n```python\nimport unittest\nfrom unittest.mock import patch, Mock\n\nclass MyClass:\n    def ma_methode(self, param1, param2):\n        return param1 + param2\n\nclass MyTests(unittest.TestCase):\n    @patch('__main__.MyClass.ma_methode')  # Mock de la méthode ma_methode\n    def test_ma_methode(self, mock_ma_methode):\n        mock_ma_methode.return_value = 10  # Stub : retourne une valeur fixe\n        obj = MyClass()\n        resultat = obj.ma_methode(5, 5)  # L'appel réel ne se produit pas\n        self.assertEqual(resultat, 10)  # Vérification du résultat stubbé\n\n        mock_ma_methode.assert_called_once_with(5, 5) # Mock : vérification des arguments\n```\n\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Isolation:** Permet de tester des unités de code de manière indépendante de leurs dépendances.\n* **Fiabilité:** Réduit les erreurs liées aux dépendances externes (bases de données, réseaux, etc.).\n* **Rapidité:** Les tests sont plus rapides car ils n'ont pas à interagir avec des systèmes externes lents.\n* **Répétabilité:**  Les tests sont toujours reproductibles car l'environnement de test est contrôlé.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La mise en place de mocks et stubs peut ajouter de la complexité aux tests.\n* **Maintenance:**  Les tests utilisant des mocks et stubs peuvent nécessiter une maintenance accrue si l'API des dépendances évolue.\n* **Sur-mocking:** Un excès de mocking peut masquer des problèmes d'intégration.\n* **Difficulté de debug:** Des tests trop isolés peuvent rendre le debugging plus difficile si le problème vient d'une interaction inattendue entre les différentes parties du système.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e938662b-f332-4f3b-b8fd-b3729a7b352f",
        "title": "Optimisation",
        "shortDescription": "",
        "description": "---\nid: 3ee82aac-362e-40bd-96ee-8c9734e0d8b9\n---\n# Rapidement, c'est quoi ? ❓\n\nL'optimisation consiste à améliorer les performances d'un système, dans ce cas précis, d'une base de données et de la gestion des logs.  Cela vise à réduire les temps de réponse, à augmenter le débit et à améliorer l'utilisation des ressources.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCette note décrit deux techniques d'optimisation : l'augmentation de la pool de connexions pour la base de données et la bufferisation des logs.\n\n**1. Augmentation de la pool de connexions de la base de données:**\n\nUne pool de connexions est un ensemble de connexions pré-établies à la base de données.  Au lieu d'établir une nouvelle connexion pour chaque requête, l'application utilise les connexions disponibles dans la pool.  Augmenter la taille de cette pool permet de gérer un plus grand nombre de requêtes concurrentes, réduisant ainsi les temps d'attente et améliorant les performances.  Cependant, il est crucial de vérifier la configuration du paramètre `max_connections` (ou un paramètre équivalent) au niveau de la base de données elle-même.  Dépasser cette limite peut mener à des erreurs et à une dégradation des performances.\n\n**Exemple (concept, pas de code spécifique à une base de données):**\n\nImaginons une application web avec 10 utilisateurs concurrents.  Si la pool de connexions est de taille 5, 5 utilisateurs devront attendre qu'une connexion devienne disponible avant de pouvoir interagir avec la base de données.  En augmentant la taille de la pool à 20, plus d'utilisateurs pourront accéder simultanément à la base de données sans attente.\n\n**2. Bufferisation des logs:**\n\nLa journalisation (logging) peut être une opération coûteuse en termes de ressources, surtout avec un volume important de logs.  La bufferisation consiste à accumuler les logs dans une mémoire tampon (buffer) avant de les écrire physiquement sur le disque ou de les envoyer à un système de logging distant.  Cela permet de rendre l'écriture des logs plus asynchrone, évitant ainsi de bloquer le thread principal de l'application et de surcharger la sortie standard.  Une fois le buffer plein (ou après un certain délai), son contenu est écrit en bloc, ce qui est plus efficace que l'écriture de chaque log individuellement.\n\n**Exemple (concept):**\n\nAu lieu d'écrire chaque message de log directement sur le disque, on les accumule dans un buffer de taille 1000 messages.  Une fois le buffer plein, on écrit les 1000 messages en une seule opération.  Cela réduit le nombre d'opérations d'écriture sur le disque, ce qui améliore les performances.  Divers frameworks de logging offrent des mécanismes de bufferisation.\n\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Augmentation de la pool de connexions:**  Amélioration significative des performances pour les applications avec un fort trafic concurrent.\n* **Bufferisation des logs:**  Réduction de la charge sur le système et amélioration de la réactivité de l'application, en particulier sous forte charge de logging.\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Augmentation de la pool de connexions:**  Risque de saturation de la base de données si la taille de la pool dépasse la limite `max_connections` définie par le serveur de base de données.  Cela peut entraîner des erreurs et une dégradation des performances. Nécessite une bonne compréhension des limites de la base de données.\n* **Bufferisation des logs:**  Peut introduire une latence dans la journalisation, ce qui peut compliquer le débogage en temps réel si un problème survient.  La gestion de la taille du buffer et de la fréquence d'écriture est critique pour trouver le bon équilibre entre performance et temps de réponse.  En cas de crash de l'application avant l'écriture du buffer, les logs seront perdus.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "dda6a9ab-f010-41f6-9158-b779fa0e1bd6",
        "title": "Plugin Oauth2 Proxy Nexus",
        "shortDescription": "",
        "description": "---\nid: 2fa8fce2-e236-4f36-b969-556a3f001603\n---\n# Rapidement, c'est quoi ? ❓\n\nLe plugin OAuth2Proxy pour Nexus est une extension qui ajoute une couche d'authentification basée sur OAuth 2.0.  Il permet aux utilisateurs de se connecter à Nexus via un fournisseur d'identité (IdP) comme Keycloak, Okta, etc., au lieu d'utiliser les mécanismes d'authentification intégrés de Nexus.  Une fois authentifié, l'utilisateur reçoit un token permettant l'accès aux ressources de Nexus (comme les dépôts Maven) sans avoir besoin de fournir de nouveau ses identifiants.\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nCe plugin agit comme un proxy inverse devant Nexus.  Au lieu d'accéder directement à Nexus, les requêtes passent d'abord par OAuth2Proxy.  OAuth2Proxy intercepte la requête, redirige l'utilisateur vers son IdP pour l'authentification. Une fois l'authentification réussie auprès de l'IdP, OAuth2Proxy vérifie le token reçu et, s'il est valide, redirige la requête vers Nexus en ajoutant des informations d'authentification au header de la requête (souvent un `Authorization: Bearer <token>`).  Cela permet à Nexus d'identifier l'utilisateur sans avoir besoin d'une authentification directe.  L'utilisateur peut ainsi accéder aux ressources de Nexus uniquement si le token OAuth 2.0 est valide.\n\nLe plugin se configure généralement en définissant l'URL de l'IdP, les identifiants de l'application enregistrée dans l'IdP, et les scopes nécessaires.  La configuration peut inclure des options avancées comme la gestion des rôles et des autorisations.\n\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Sécurité améliorée:** Délégue l'authentification à un système d'identité centralisé et plus robuste, réduisant le risque d'attaques directes sur Nexus.\n* **Centralisation de l'authentification:** Gestion unique des utilisateurs et des mots de passe via l'IdP.\n* **Intégration avec différents IdP:** Compatible avec de nombreux fournisseurs d'identité populaires (Keycloak, Okta, Google, etc.).\n* **Accès headless:** Permet aux outils automatisés (ex: scripts Maven, CI/CD) d'accéder à Nexus en utilisant le token OAuth 2.0, sans intervention manuelle.\n* **Amélioration de l'expérience utilisateur:**  Authentification unique (SSO) possible si l'IdP est déjà utilisé pour d'autres applications.\n\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité de configuration:** La configuration initiale peut être complexe, nécessitant une bonne compréhension d'OAuth 2.0 et de la configuration de l'IdP.\n* **Dépendance à un IdP:**  Nécessite un IdP fonctionnel et correctement configuré.\n* **Surcoût de performance:** L'ajout d'un proxy intermédiaire peut introduire une légère latence.  Cependant, cela est généralement négligeable.\n* **Débogage:** Le débogage des problèmes d'authentification peut être difficile, nécessitant une analyse des logs de l'IdP et d'OAuth2Proxy.\n\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d3ab7db6-fa95-43cb-acc9-4f7113eadee8",
        "title": "PouchDB",
        "shortDescription": "",
        "description": "---\nid: 11870a2a-4362-4192-bc6e-f4b4c92ff908\n---\n# Rapidement, c'est quoi ? ❓\n\nPouchDB est une base de données NoSQL JavaScript open-source qui fonctionne comme une base de données client-side, imitant l'API de CouchDB.  Elle permet de stocker des données localement dans le navigateur ou un environnement Node.js, offrant des fonctionnalités de synchronisation avec une base de données distante (comme CouchDB ou Cloudant).\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nPouchDB est une base de données JavaScript orientée document, ce qui signifie qu'elle stocke les données sous forme de documents JSON.  Elle implémente une API similaire à celle de CouchDB, facilitant la migration entre les deux.  Le principal avantage est la capacité de fonctionner hors connexion.  Les données sont stockées localement, et une fois la connexion rétablie, PouchDB se synchronise avec la base de données distante en utilisant des mécanismes de réplication bidirectionnelle.  Cela permet aux applications web et mobiles de fonctionner même sans accès à internet, les modifications étant sauvegardées localement et synchronisées ultérieurement.\n\nPouchDB utilise un système de versionnement des documents pour gérer les conflits lors de la synchronisation.  Si des modifications sont effectuées à la fois localement et à distance sur le même document, PouchDB utilise un algorithme pour résoudre les conflits et fusionner les changements.  L'utilisateur peut personnaliser la gestion des conflits.\n\n**Exemple d'utilisation (ajout d'un document):**\n\n```javascript\nconst db = new PouchDB('mydb');\n\ndb.put({\n  _id: 'mydoc',\n  name: 'Example Document'\n}).then(() => {\n  console.log('Document added successfully!');\n}).catch((err) => {\n  console.log('Error adding document:', err);\n});\n```\n\n**Exemple de synchronisation avec une base de données distante (CouchDB):**\n\n```javascript\nconst remoteCouchDB = 'http://example.com:5984/mydb';\nconst db = new PouchDB('mydb');\n\ndb.sync(remoteCouchDB, {\n  live: true,\n  retry: true\n}).on('change', (info) => {\n    console.log(\"Changes detected, replicating...\");\n}).on('paused', (err) => {\n    console.log('Replication paused.');\n}).on('error', (err) => {\n    console.error('Replication failed.', err);\n});\n\n```\n\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Fonctionnement hors ligne:**  La principale force de PouchDB est sa capacité à fonctionner sans connexion internet.\n* **Synchronisation facile:**  La réplication avec une base de données distante est simple à mettre en œuvre.\n* **API intuitive:** L'API est similaire à celle de CouchDB, facile à apprendre et à utiliser.\n* **Open source et communauté active:**  Bénéficie d'une communauté active et d'une documentation complète.\n* **Léger et performant:**  PouchDB est relativement léger et performant, même sur des appareils mobiles.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Gestion des conflits:** Bien que PouchDB gère les conflits,  la résolution automatique peut parfois être complexe et nécessiter une intervention manuelle.\n* **Limites de taille des données:**  Pour des applications à très grande échelle avec des volumes importants de données, PouchDB peut avoir ses limites.  Il est plus adapté aux applications nécessitant une persistance locale et une synchronisation régulière.\n* **Dépendance à JavaScript:**  Son utilisation est intrinsèquement liée à JavaScript et ne peut pas être utilisée directement dans d'autres langages.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a7f557fc-7458-4115-81c0-b3b481a4b64b",
        "title": "R2DBC",
        "shortDescription": "",
        "description": "---\nid: bfc84f55-fe42-4506-951b-7f9edd1ac060\n---\n# Rapidement, c'est quoi ? ❓\n\nR2DBC (Reactive Relational Database Connectivity) est une spécification pour accéder de manière réactive aux bases de données relationnelles depuis Java.  Il fournit une API asynchrone et non-bloquante, contrastant avec l'approche synchrone et bloquante de JDBC.\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nR2DBC définit une API pour interagir avec les bases de données relationnelles en utilisant un modèle réactif.  Au lieu de bloquer le thread d'exécution en attendant la réponse de la base de données, R2DBC utilise des mécanismes asynchrones, permettant au thread de continuer à traiter d'autres tâches pendant que la requête est exécutée. Cela améliore l'efficacité et les performances, surtout dans les applications à haute concurrence.\n\nContrairement à JDBC, qui utilise des objets `Statement`, `ResultSet`, etc., R2DBC utilise un modèle basé sur `Flux` (de la librairie Reactor) pour les requêtes et les résultats.  Cela permet de traiter les données de manière asynchrone et réactive, en utilisant des opérateurs comme `map`, `filter`, `flatMap`, etc.  L'API R2DBC est plus déclarative que JDBC, laissant la gestion de la concurrence et de l'asynchronisme au framework.\n\nVoici un exemple simplifié d'utilisation de R2DBC avec Spring Data R2DBC (Note:  Ce code est simplifié pour illustrer le concept.  Une implémentation réelle nécessiterait plus de détails):\n\n```kotlin\n@Repository\ninterface UserRepository : ReactiveCrudRepository<User, Long> {\n    // Méthodes CRUD générées automatiquement\n}\n\n//Entité User\ndata class User(val id: Long?, val name: String)\n\n//Dans un service\n@Service\nclass UserService(private val userRepository: UserRepository){\n    fun getAllUsers(): Flux<User> = userRepository.findAll()\n}\n```\n\nCet exemple montre comment Spring Data R2DBC simplifie l'interaction avec la base de données en fournissant une implémentation de `ReactiveCrudRepository`. Les opérations CRUD sont effectuées de manière réactive et asynchrone grâce à l'utilisation de `Flux`.  Notez qu'il est nécessaire de gérer soi-même les jointures avec R2DBC, contrairement à certains ORM qui les gèrent automatiquement.\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Performances:** L'approche asynchrone et non-bloquante améliore considérablement les performances, surtout pour les applications à forte charge.\n* **Scalabilité:**  R2DBC est mieux adapté à la gestion de la concurrence et permet une meilleure scalabilité que JDBC.\n* **Intégration avec Spring:** L'intégration avec Spring Data R2DBC simplifie l'utilisation de R2DBC et permet de bénéficier des fonctionnalités de Spring.\n* **Réactivité:** L'utilisation de `Flux` permet un traitement réactif des données.\n\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La programmation réactive peut être plus complexe que la programmation synchrone traditionnelle.  Comprendre les concepts de `Flux`, `Mono`, et les opérateurs réactifs est crucial.\n* **Maturation:**  Bien que mature, R2DBC est une technologie plus récente que JDBC, et certaines bases de données et outils peuvent avoir un support moins complet que pour JDBC.\n* **Gestion des jointures:**  R2DBC ne gère pas les jointures automatiquement, demandant une gestion explicite dans le code, ce qui peut complexifier les requêtes plus sophistiquées.\n* **Debugging:** Le débogage de code réactif peut être plus difficile que le débogage de code synchrone.\n\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\nJDBC, Spring Data R2DBC, Project Reactor, bases de données relationnelles, programmation réactive.\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e0f385b0-ed98-4b3c-a1bf-b859880071c0",
        "title": "RGAA",
        "shortDescription": "",
        "description": "---\nid: dd5ba0ba-bc56-46d7-8c93-631e4758609a\n---\n## Rapidement, c'est quoi ? ❓\n\nLe RGAA (Référentiel Général d'Accessibilité pour les Administrations) est un référentiel français qui définit les critères d'accessibilité numérique pour les sites web et applications des administrations publiques. Il s'appuie sur les WCAG (Web Content Accessibility Guidelines) internationales, mais les adapte au contexte français et fournit des critères plus précis et concrets.\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLe RGAA vise à garantir que les services numériques publics soient accessibles à tous, y compris les personnes handicapées.  Il définit des critères d'accessibilité regroupés en quatre principes :\n\n* **Percevable:** L'information et les composants de l'interface utilisateur doivent être présentés aux utilisateurs de manière qu'ils puissent les percevoir.  Cela inclut des aspects comme le contraste des couleurs, les alternatives textuelles aux images, la transcription des contenus audio et vidéo, etc.\n* **Opérable:** L'interface utilisateur doit être opérable.  Cela signifie que les utilisateurs doivent pouvoir utiliser l'interface avec une variété de dispositifs d'entrée, comme une souris, un clavier, un écran tactile, etc.  Cela comprend aussi des aspects comme la navigation au clavier, l'évitement des pièges à souris, etc.\n* **Compréhensible:** L'information et le fonctionnement de l'interface utilisateur doivent être compréhensibles.  Cela implique une rédaction claire et concise, une navigation intuitive, l'utilisation d'un langage simple, etc.\n* **Robuste:** Le contenu doit être robuste, c'est-à-dire compatible avec un large éventail de technologies d'assistance et d'appareils.\n\nChaque principe est ensuite décliné en critères plus spécifiques, avec des niveaux de conformité (A, AA, AAA).  La version actuelle du RGAA est la version 4.0.  L'évaluation de la conformité au RGAA se fait généralement via des audits, manuels ou automatisés, qui permettent d'identifier les points d'amélioration pour rendre un site web ou une application plus accessible.\n\n**Exemple concret:** Un critère du RGAA pourrait être \"Le texte doit avoir un contraste suffisant avec l'arrière-plan\".  Cela signifie que la différence de luminosité entre le texte et l'arrière-plan doit être suffisamment importante pour être perçue par les personnes malvoyantes.\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Cadre clair et précis:**  Le RGAA fournit des critères concrets et mesurables pour l'accessibilité, ce qui facilite l'évaluation et l'amélioration de l'accessibilité des sites web et applications.\n* **Adaptation au contexte français:**  Il adapte les WCAG au contexte français, ce qui le rend plus pertinent pour les administrations publiques françaises.\n* **Amélioration de l'inclusion:**  Il contribue à améliorer l'inclusion numérique et permet à un plus grand nombre de personnes d'accéder aux services en ligne.\n\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:**  Le RGAA est un référentiel complexe avec de nombreux critères et niveaux de conformité, ce qui peut rendre sa mise en œuvre difficile.\n* **Coût:**  L'audit et la mise en conformité avec le RGAA peuvent engendrer des coûts importants, notamment pour les sites web complexes.\n* **Évolution constante:**  Les technologies et les besoins des personnes handicapées évoluent, ce qui nécessite une mise à jour régulière du RGAA.\n\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "d460347c-b86a-4170-ad92-1f2f8cf350ab",
        "title": "Resource et RxResource (Angular)",
        "shortDescription": "",
        "description": "---\nid: 5114a4ec-5c32-4fb5-bfd6-2d475c4cbb42\n---\n# Rapidement c'est quoi❓\n\n`Resource` et `RxResource` (Angular) sont des mécanismes facilitant la gestion des appels API dans les applications Angular. Ils encapsulent la logique de requête HTTP et fournissent une interface réactive pour suivre l'état de la requête (chargement, succès, erreur).  `RxResource` utilise RxJS pour une gestion asynchrone plus avancée.\n\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\n`Resource` et `RxResource` sont des abstractions conçues pour simplifier l'interaction avec des API RESTful dans Angular.  Ils permettent d'éviter la répétition de code pour les appels HTTP courants (GET, POST, PUT, DELETE).  Au lieu d'écrire manuellement des appels `HttpClient`, vous utilisez une instance `Resource` ou `RxResource` configurée avec l'URL de votre API et les méthodes HTTP appropriées.\n\n**`Resource`:**  Cette approche plus basique utilise les promesses JavaScript pour gérer les réponses asynchrones.  Elle fournit des propriétés pour suivre l'état de la requête (par exemple, `isLoading`, `data`, `error`).  L'accès aux données se fait via ces propriétés une fois la promesse résolue.\n\n**`RxResource`:**  Cette version plus sophistiquée exploite les observables RxJS.  Elle offre une interface plus réactive et plus puissante, permettant de gérer facilement les flux de données et les erreurs.  L'état de la requête (chargement, succès, erreur) est émis sous forme d'événements observables, permettant des mises à jour dynamiques de l'interface utilisateur et une gestion fine des erreurs.  Ceci est particulièrement utile pour les requêtes longues ou multiples.\n\nPour les deux, la configuration se fait généralement via la définition d'une classe qui spécifie l'URL de base et les actions (GET, POST, etc.).  Ces actions sont ensuite appelées pour déclencher les requêtes HTTP.\n\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Réduction de la Boilerplate:**  Réduction significative du code nécessaire pour gérer les appels API.\n* **Gestion centralisée des erreurs:**  Facilite la gestion des erreurs réseau et des erreurs côté serveur.\n* **Amélioration de la lisibilité du code:**  Sépare la logique de gestion des requêtes HTTP du reste du code applicatif.\n* **`RxResource` et la réactivité:**  Avec `RxResource`, une intégration naturelle avec la programmation réactive d'Angular et RxJS, pour une meilleure gestion des flux de données asynchrones.\n* **Testabilité améliorée:**  Les classes `Resource` ou `RxResource` sont plus faciles à tester que des appels `HttpClient` directement intégrés dans les composants.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:**  Nécessite une compréhension des promesses (pour `Resource`) ou des observables RxJS (pour `RxResource`).\n* **Complexité potentielle:**  Pour les applications simples, l'utilisation de `Resource` ou `RxResource` peut ajouter une complexité inutile.\n* **Dépendance:**  Ajoute une dépendance supplémentaire au projet.\n* **Maintenance:**  Nécessite une maintenance à long terme si l'API évolue.  Il faut adapter les définitions des `Resource` ou `RxResource`.\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "7a750faf-40c3-463b-8bab-e6e1e0be4af2",
        "title": "Rio",
        "shortDescription": "",
        "description": "---\nid: bd8cfc04-d694-45ba-b346-084595d3ab27\n---\n## Rapidement, c'est quoi ? ❓\n\nRio est une librairie Python permettant de créer des interfaces web directement en Python, sans nécessiter de connaissances approfondies en HTML, CSS ou JavaScript.  Elle facilite la création d'interfaces utilisateur pour des applications et scripts Python.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nRio utilise un modèle déclaratif pour construire des interfaces utilisateur.  Au lieu d'écrire du HTML et du CSS, vous décrivez la structure et le style de votre page web à l'aide de fonctions Python. Rio gère ensuite la conversion en HTML, CSS et JavaScript nécessaires pour afficher la page dans un navigateur.  Cela permet de créer des applications web interactives en exploitant les capacités de Python, notamment pour le traitement de données et la logique métier.\n\nRio s'appuie sur des composants modulaires et réutilisables pour construire des interfaces complexes.  Il permet de gérer des événements utilisateur (clics, soumissions de formulaires, etc.) directement depuis le code Python.  L'interaction avec le serveur (si nécessaire) se fait également via du code Python.\n\n**Exemple (simplifié):**\n\n```python\nimport rio\n\napp = rio.App()\n\n@app.route(\"/\")\ndef index():\n  return rio.html.div(\"Hello, world!\")\n\napp.run()\n```\n\nCe code simple crée une page web affichant \"Hello, world!\".  La fonction `index` est décorée avec `@app.route(\"/\")` pour indiquer qu'elle gère la requête à la racine du site.  `rio.html.div` crée un élément HTML `<div>`.\n\nDes exemples plus complexes pourraient inclure des formulaires, des tableaux, des graphiques, et une interaction plus sophistiquée avec le serveur.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Développement rapide:**  La programmation en Python permet un développement plus rapide et plus efficace que le développement web traditionnel avec HTML, CSS et JavaScript.\n* **Intégration facile avec les scripts Python:** Rio s'intègre facilement aux applications et scripts Python existants.\n* **Modèle déclaratif:** La déclaration de l'interface utilisateur rend le code plus lisible et plus facile à maintenir.\n* **Abstraction:** Rio masque la complexité sous-jacente du développement web, permettant aux développeurs Python de se concentrer sur la logique métier.\n\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Communauté limitée:**  Comparé à des frameworks web populaires comme Flask ou Django, Rio a une communauté plus petite, ce qui peut impacter le support et la disponibilité des ressources.\n* **Performance potentielle:**  L'interprétation Python pourrait engendrer une performance légèrement inférieure à celle d'applications web construites avec des technologies compilées.  Cependant, pour beaucoup d'applications, cette différence sera négligeable.\n* **Flexibilité limitée (potentielle):**  Bien que Rio permette une grande partie des fonctionnalités web, il pourrait manquer certaines fonctionnalités très spécifiques ou nécessiter des solutions de contournement pour des cas d'utilisation avancés.\n* **Dépendances:** Rio ajoute une dépendance supplémentaire à votre projet.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "7663b49c-a5f3-421b-84ef-262d66c0c6ad",
        "title": "Réflexion (Java)",
        "shortDescription": "",
        "description": "---\nid: 16be4a3f-fb5e-4258-b88a-d8f3bd3f5389\n---\n## Rapidement, c'est quoi ? ❓\n\nLa réflexion en Java est une fonctionnalité puissante qui permet à un programme de manipuler ses propres structures et comportements à l'exécution.  Elle permet d'inspecter et de modifier les classes, les méthodes, les champs, etc., dynamiquement.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLa réflexion en Java s'appuie sur les classes du package `java.lang.reflect`.  Ces classes fournissent des interfaces pour interagir avec les métadonnées des classes et des objets à l'exécution.  On peut, par exemple :\n\n* **Obtenir des informations sur une classe:**  Nom de la classe, ses interfaces implémentées, ses constructeurs, ses méthodes, ses champs (variables d'instance et statiques).  Cela se fait via la classe `Class`.\n* **Créer des instances de classes dynamiquement:**  Invoquer un constructeur d'une classe dont le nom n'est connu qu'à l'exécution.\n* **Invoquer des méthodes dynamiquement:**  Appeler une méthode d'un objet, même si le nom de la méthode n'est pas connu à la compilation.\n* **Accéder aux champs dynamiquement:**  Lire ou modifier la valeur d'un champ d'un objet.\n* **Créer des proxies:**  Générer dynamiquement des classes qui implémentent des interfaces données, interceptant les appels de méthodes pour ajouter du comportement (AOP).\n\n**Exemple:**\n\n```java\nClass<?> myClass = Class.forName(\"com.example.MyClass\"); // Récupère la classe MyClass dynamiquement\nMethod myMethod = myClass.getMethod(\"myMethod\", String.class); // Récupère la méthode myMethod\nObject myObject = myClass.getDeclaredConstructor().newInstance(); // Crée une instance de MyClass\nObject result = myMethod.invoke(myObject, \"Hello\"); // Appelle la méthode myMethod avec l'argument \"Hello\"\nSystem.out.println(result); // Affiche le résultat de l'appel de méthode\n```\n\nCet exemple montre comment récupérer une classe, une méthode, créer une instance et invoquer la méthode dynamiquement.  `Class.forName()` est une méthode clé pour récupérer une référence de classe à partir d'un nom de classe (String).\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Flexibilité:** Permet de créer des applications très dynamiques et configurables, adaptant leur comportement à l'exécution.\n* **Extension du code:**  Facilite la création d'outils de développement tels que les frameworks de test, les outils de monitoring ou les debuggers.\n* **Interopérabilité:**  Permet d'interagir avec des librairies ou des composants dont la structure n'est pas connue à la compilation.\n* **Frameworks puissants:**  Fondamentale pour des frameworks comme Spring qui utilisent la réflexion pour l'injection de dépendances et l'AOP.\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Performances:**  L'utilisation intensive de la réflexion peut impacter les performances, car elle nécessite une recherche et une manipulation dynamiques des métadonnées.\n* **Sécurité:**  Une mauvaise utilisation de la réflexion peut exposer à des failles de sécurité, notamment en permettant l'accès ou la modification non autorisée de données.\n* **Complexité:**  Le code utilisant la réflexion peut être plus complexe à lire, à maintenir et à déboguer que le code traditionnel.\n* **Erreurs à l'exécution:**  Les erreurs liées à la réflexion surviennent souvent à l'exécution plutôt qu'à la compilation, rendant le debugging plus difficile.\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "a4d130be-3eb5-4ee3-8991-f9ca30af1689",
        "title": "Serialisation-Deserialisation",
        "shortDescription": "",
        "description": "---\nid: ea084ff5-b622-4420-b2ee-d8a3d6cb1ea5\n---\n# **Rapidement, c'est quoi ? ❓**\n\nLa sérialisation et la désérialisation sont des processus qui permettent de convertir un objet en une représentation linéaire (généralement un flux de données comme un fichier, une chaîne de caractères ou un flux réseau) et inversement. La sérialisation transforme l'objet en cette représentation, tandis que la désérialisation reconstitue l'objet à partir de cette représentation.\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nLa sérialisation permet de stocker des objets complexes dans un format persistant ou de les transmettre sur un réseau.  Elle implique de convertir l'état d'un objet, incluant ses attributs et éventuellement ses relations avec d'autres objets, en une séquence de bits.  La désérialisation est le processus inverse : à partir de cette séquence de bits, elle reconstitue l'objet dans sa forme originale, avec ses attributs et ses relations.\n\nPlusieurs formats et techniques existent pour la sérialisation/désérialisation :\n\n* **Formats de données:** JSON, XML, Protocol Buffers, Avro, etc.  Chaque format a ses avantages et inconvénients en termes de lisibilité, taille des données, performance et compatibilité.\n* **Techniques de sérialisation:**  La sérialisation peut être implémentée de différentes manières, notamment via la réflexion (Java utilise souvent cette méthode avec des bibliothèques comme Jackson ou Gson), ou via des techniques de génération de code AOT (Ahead-Of-Time) plus performantes.  La réflexion implique d'analyser la structure des classes au runtime, ce qui peut être coûteux en termes de performance.  Les approches AOT génèrent du code spécifique pour chaque classe, optimisant ainsi le processus de sérialisation/désérialisation.\n\n**Exemple (Java avec Jackson):**\n\n```java\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class User {\n    public String name;\n    public int age;\n\n    public User(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n\n    public static void main(String[] args) throws Exception {\n        ObjectMapper mapper = new ObjectMapper();\n        User user = new User(\"John Doe\", 30);\n\n        // Sérialisation en JSON\n        String jsonString = mapper.writeValueAsString(user);\n        System.out.println(\"JSON: \" + jsonString);\n\n        // Désérialisation à partir de JSON\n        User user2 = mapper.readValue(jsonString, User.class);\n        System.out.println(\"Name: \" + user2.name + \", Age: \" + user2.age);\n    }\n}\n```\n\nCet exemple montre comment Jackson sérialise un objet `User` en JSON et le désérialise ensuite.\n\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Persistance des données:**  Possibilité de sauvegarder l'état d'objets dans un stockage persistant (fichiers, bases de données).\n* **Communication réseau:**  Transmission d'objets complexes sur un réseau.\n* **Interopérabilité:**  Utilisation de formats standardisés comme JSON ou XML pour l'échange de données entre différents systèmes et langages de programmation.\n* **Approches AOT (pour certaines technologies):**  Performance significativement améliorée par rapport à la réflexion.\n\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité de l'implémentation:**  La conception d'un système de sérialisation/désérialisation robuste et efficace peut être complexe.\n* **Sécurité:**  Une sérialisation mal conçue peut présenter des failles de sécurité (par exemple, des attaques de désérialisation).\n* **Performances (réflexion):**  L'utilisation de la réflexion peut être coûteuse en termes de performance, surtout pour des objets complexes ou de grands volumes de données.\n* **Gestion des versions:**  La compatibilité entre différentes versions des schémas de données peut être un défi.\n\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "53302f5c-252d-4a66-9511-c7a0262ad123",
        "title": "Spring Batch",
        "shortDescription": "",
        "description": "---\nid: 2c0ef40f-9587-45c4-bef7-b2db691c9065\n---\n# Rapidement, c'est quoi ? ❓\n\nSpring Batch est un framework léger, puissant et complet de traitement par lots pour Java. Il permet de développer des applications robustes et performantes pour traiter de grands volumes de données de manière fiable et efficace. Il s'appuie sur des concepts de base comme la lecture, le traitement et l'écriture de données par lots, en utilisant une approche de type pipeline.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSpring Batch automatise le traitement de grands volumes de données de façon fiable et efficace.  Il est conçu pour des applications qui requièrent des opérations répétitives et volumineuses sur les données, comme le chargement de données, la transformation de données, ou la génération de rapports.  Le framework structurait le processus en **Jobs**, qui sont des tâches globales, divisés en **Steps**.  Chaque Step consiste en trois phases principales :\n\n* **Read (Lecture):**  Lit les données depuis une source (base de données, fichier plat, etc.).  Plusieurs `ItemReader` implémentent des sources variées, telles que `JdbcCursorItemReader` (pour les requêtes SQL), `FlatFileItemReader` (pour les fichiers plats), `RepositoryItemReader` (pour les repositories Spring Data).\n\n* **Process (Traitement):** Transforme les données lues. Un `ItemProcessor` effectue cette transformation.  On peut utiliser des mappers comme MapStruct pour simplifier cette étape.\n\n* **Write (Ecriture):** Enregistre les données traitées dans une destination (base de données, fichier, etc.).  Divers `ItemWriter` sont disponibles, dont `JdbcBatchItemWriter`, `FlatFileItemWriter`, et `RepositoryItemWriter` (pour les repositories Spring Data).\n\nChaque phase utilise des interfaces pour une grande flexibilité.  Spring Batch gère également la gestion des erreurs, le commit/rollback des transactions, le restarting des jobs en cas d'erreur, et la surveillance de l'exécution. La gestion du chunk (traitement de données par blocs) optimise les performances.\n\n**Exemple simplifié (sans code complet):**  Imaginons un job qui importe des données d'un fichier CSV dans une base de données.\n\n1. **Job:** \"ImporterDonnéesCSV\"\n2. **Step:** \"ImporterDonnées\"\n    * **Read:** `FlatFileItemReader` lit les lignes du fichier CSV.\n    * **Process:** `ItemProcessor` transforme chaque ligne en objet Java.\n    * **Write:** `JdbcBatchItemWriter` insère les objets Java dans la base de données.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Fiabilité:** Gestion robuste des erreurs et reprise sur erreur.\n* **Performance:** Traitement par lots optimisé, gestion des transactions et du chunking.\n* **Flexibilité:** Large gamme de lecteurs, processeurs et écrivains pour différentes sources et destinations de données.\n* **Intégration Spring:** S'intègre parfaitement avec d'autres composants Spring.\n* **Débogage et surveillance:** Facilite le suivi et le débogage des jobs.\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** Peut être complexe à mettre en œuvre pour des tâches simples. La courbe d'apprentissage est assez raide.\n* **Configuration XML (ancienne version):** Bien que la configuration basée sur annotations soit privilégiée, la configuration XML peut être complexe à comprendre.\n* **Dépendances:** Nécessite plusieurs dépendances Spring.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "67a33c81-2bce-4911-ae4d-3080d557425e",
        "title": "Spring Cloud Open Feign",
        "shortDescription": "",
        "description": "---\nid: a64c1da0-4ff7-4acc-b305-83aeff5d5079\n---\n# Rapidement, c'est quoi ? ❓\n\nSpring Cloud Open Feign est une librairie Java qui simplifie la création de clients HTTP pour consommer des API REST.  Elle s'intègre parfaitement à l'écosystème Spring Cloud et permet de déclarer des interfaces Java qui sont automatiquement traduites en clients HTTP, éliminant la nécessité d'écrire du code boilerplate pour les appels REST.\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSpring Cloud Open Feign repose sur la librairie Feign, mais l'enrichit avec des fonctionnalités spécifiques à Spring Cloud, notamment l'intégration avec Ribbon pour le load balancing et Hystrix pour la gestion des erreurs et la tolérance aux pannes.  Au lieu d'écrire du code pour chaque appel REST (par exemple, avec RestTemplate), on définit une interface Java annotée avec des annotations Feign (comme `@GetMapping`, `@PostMapping`, etc.).  Feign se charge ensuite de créer un proxy qui implémente cette interface et gère les appels HTTP sous-jacents.\n\n**Exemple:**\n\nImaginons une API REST qui fournit des informations sur les utilisateurs.  On pourrait définir une interface Feign comme suit :\n\n```java\n@FeignClient(name = \"user-service\")\npublic interface UserService {\n\n    @GetMapping(\"/users/{id}\")\n    User getUser(@PathVariable(\"id\") Long id);\n\n    @PostMapping(\"/users\")\n    User createUser(@RequestBody User user);\n}\n```\n\n`@FeignClient(\"user-service\")` indique que cette interface est un client pour un service nommé \"user-service\".  Feign se charge ensuite de trouver ce service (généralement via un registre de services comme Eureka) et de créer un proxy qui implémente `UserService`.  On peut ensuite injecter ce proxy dans d'autres classes et l'utiliser comme n'importe quelle autre classe Java :\n\n```java\n@Autowired\nprivate UserService userService;\n\n// ...\n\nUser user = userService.getUser(1L);\n```\n\nSpring Cloud Open Feign gère automatiquement les détails de l'appel HTTP, y compris la construction de l'URL, la gestion des en-têtes HTTP, la sérialisation/désérialisation des données JSON, et le load balancing si plusieurs instances du \"user-service\" sont disponibles.\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Simplicité et lisibilité:**  Le code est beaucoup plus propre et facile à lire que lorsqu'on utilise `RestTemplate` directement.\n* **Déclaratif:** On définit les appels REST de manière déclarative, ce qui rend le code plus maintenable et moins sujet aux erreurs.\n* **Intégration Spring Cloud:** S'intègre parfaitement avec d'autres composants Spring Cloud comme Ribbon et Hystrix.\n* **Tests facilités:**  Les interfaces Feign sont facilement testables avec des mocks.\n\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:**  Nécessite une compréhension de base de Feign et des annotations Spring.\n* **Débogage:**  Le débogage peut être plus difficile que lorsqu'on utilise `RestTemplate` directement, car la logique HTTP est cachée derrière le proxy Feign.\n* **Complexité pour des cas d'utilisation avancés:** Pour des scénarios HTTP complexes (gestion de plusieurs types de réponses,  gestion fine des erreurs HTTP non gérés par Hystrix, ...), il peut être nécessaire de recourir à des configurations et des intercepteurs plus avancés.\n\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "06c3248f-0cd0-4455-806d-fbc11f2130ae",
        "title": "Spring Cloud Square",
        "shortDescription": "",
        "description": "---\nid: fba146b1-f075-4072-9323-b9af98af76bd\n---\n# Rapidement, c'est quoi ? ❓\n\nSpring Cloud Square est une bibliothèque Java open-source qui simplifie la création et la gestion de microservices basés sur Spring Boot.  Elle utilise un registre de services (comme Eureka ou Consul) pour permettre aux services de se découvrir et de communiquer entre eux.  Elle s'appuie sur le pattern \"sidecar\" pour injecter des fonctionnalités supplémentaires sans modifier le code des microservices.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nSpring Cloud Square n'est pas une bibliothèque existante à ma connaissance. Le lien fourni pointe vers un article de blog Spring de 2021 qui introduit *Spring Cloud 2021*.  Il n'y a pas de mention de \"Spring Cloud Square\".  L'article discute de nouvelles fonctionnalités et améliorations dans Spring Cloud, dont l'amélioration de la gestion des microservices.  Il n'y a pas de nouvelle bibliothèque spécifique nommée \"Spring Cloud Square\".\n\nPour clarifier, Spring Cloud (sans \"Square\") fournit des outils pour construire des applications distribuées basées sur des microservices.  Ces outils incluent :\n\n* **Découverte de services:**  Permet aux microservices de se trouver les uns les autres via un serveur de registre.\n* **Gestion de la configuration:**  Centralise la gestion des paramètres de configuration.\n* **Gestion de circuit breakers:**  Protège les applications contre les pannes de services dépendants.\n* **Routage intelligent:**  Distribue le trafic entre les instances d'un service.\n\n\nIl est possible que \"Spring Cloud Square\" soit un nom interne, un projet non-officiel, ou une interprétation erronée.  Sans plus d'informations, il est impossible de fournir une description précise de son fonctionnement.  L'intégration avec OkHttp et Retrofit est également impossible à détailler sans une définition claire de \"Spring Cloud Square\".\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n(Impossible à répondre sans une description claire de \"Spring Cloud Square\")\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n(Impossible à répondre sans une description claire de \"Spring Cloud Square\")\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Si \"Spring Cloud Square\" existait, il serait probablement lié à d'autres projets Spring Cloud comme Spring Boot, Eureka, Consul, Ribbon, Hystrix, etc.)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c2ae4899-2bd6-4b4b-ae74-f143bf33dfa6",
        "title": "Spring Cloud Stream",
        "shortDescription": "",
        "description": "---\nid: f64ebe55-d2d7-479a-b490-91a369e08354\n---\n# **Rapidement, c'est quoi ? ❓**\n\nSpring Cloud Stream est un framework basé sur Spring Boot qui simplifie la création d'applications microservices qui communiquent de manière asynchrone via des messages.  Il fournit une abstraction au-dessus de différentes technologies de messagerie comme Kafka, RabbitMQ, etc., permettant de changer de technologie sans modifier le code applicatif.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nSpring Cloud Stream fournit un modèle de programmation basé sur des flux de données (streams) et des liaisons (bindings).  Les applications utilisent des interfaces `@Input` et `@Output` pour définir des points d'entrée et de sortie pour les messages.  Spring Cloud Stream gère la configuration et la connexion à la technologie de messagerie sous-jacente.\n\nLe framework s'appuie sur les concepts suivants:\n\n* **Bindings:**  Des liens entre l'application et le broker de messages. Ils définissent comment les messages sont envoyés et reçus.  On peut les configurer à l'aide de propriétés.\n* **Destinations:**  Des files d'attente ou des topics (selon la technologie de messagerie) où les messages sont envoyés et reçus.  Le nom de la destination est configuré via les propriétés.\n* **Processors:** Composants qui consomment les messages d'une destination et les envoient vers une autre.\n* **Sources:** Composants qui envoient des messages vers une destination.\n* **Sinks:** Composants qui consomment des messages d'une destination.\n\n**Exemple (Kafka):**\n\n```java\nimport org.springframework.cloud.stream.annotation.EnableBinding;\nimport org.springframework.cloud.stream.annotation.StreamListener;\nimport org.springframework.cloud.stream.messaging.Sink;\nimport org.springframework.messaging.Message;\n\n@EnableBinding(Sink.class) // Utilise l'interface Sink fournie par Spring Cloud Stream\npublic class MessageConsumer {\n\n    @StreamListener(Sink.INPUT) // Écoute les messages sur la destination \"input\"\n    public void receive(Message<String> message) {\n        String payload = message.getPayload();\n        System.out.println(\"Received message: \" + payload);\n        // Traitement du message...\n    }\n}\n```\n\nCe code définit un consommateur de messages qui écoute sur la destination `input` (définie par défaut par `Sink`).  La configuration de Kafka sera gérée automatiquement par Spring Cloud Stream via les propriétés d'application.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Abstraction:**  Simplifie l'interaction avec les brokers de messages. Le changement de technologie est facile grâce à la configuration.\n* **Simplicité:**  Modèle de programmation déclaratif et facile à utiliser grâce aux annotations.\n* **Intégration Spring Boot:**  Intégration transparente avec l'écosystème Spring.\n* **Évolutivité:**  Conçu pour des applications distribuées et évolutives.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité (potentielle):** La configuration peut devenir complexe pour des scénarios avancés.\n* **Dépendances:**  Nécessite des dépendances supplémentaires pour les différentes technologies de messagerie.\n* **Courbe d'apprentissage:**  Nécessite une compréhension de base des concepts de messagerie asynchrone.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "14875961-7083-4170-b55a-5fcc5c10d848",
        "title": "Spring_ApplicationEvent",
        "shortDescription": "",
        "description": "---\nid: 9d4a3b37-f1cd-4e24-a3ea-7c477784e113\n---\n# Spring ApplicationEvent\n\n---\n\n# **Rapidement, c'est quoi ? ❓**\n\nUn `ApplicationEvent` dans Spring est un mécanisme permettant de publier et de gérer des événements au sein d'une application.  Il permet de dé-coupler différentes parties du code et de réagir à des événements spécifiques sans avoir besoin d'une connaissance directe des autres composants.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\n`ApplicationEvent` est une classe abstraite dans Spring qui sert de base pour tous les événements de l'application.  Pour créer un événement personnalisé, on hérite de cette classe et on fournit les données nécessaires.  Spring fournit un mécanisme d'écoute (listeners) basé sur le pattern \"Observer\".  Lorsqu'un événement est publié (`ApplicationEventPublisher.publishEvent()`), tous les listeners enregistrés qui s'intéressent à ce type d'événement sont notifiés et peuvent y réagir.\n\nLe fonctionnement repose sur :\n\n* **`ApplicationEvent`:**  Classe abstraite représentant un événement.  Contient un champ `source` qui représente l'objet qui a déclenché l'événement.\n* **`ApplicationEventPublisher`:** Interface permettant de publier des événements.  L'implémentation la plus courante est `ApplicationContext`.\n* **`ApplicationListener<T extends ApplicationEvent>`:** Interface pour les listeners.  On implémente la méthode `onApplicationEvent(T event)` qui sera appelée lorsque l'événement est publié.  Le paramètre `T` spécifie le type d'événement auquel le listener s'abonne.\n* **`@EventListener` annotation:** An annotation based approach that simplifies the definition of listeners. This approach is preferred over explicitly implementing `ApplicationListener`.\n\n**Exemple concret avec annotation `@EventListener`:**\n\n```java\nimport org.springframework.context.event.EventListener;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class MyEventListener {\n\n    @EventListener\n    public void handleMyEvent(MyCustomEvent event) {\n        System.out.println(\"MyCustomEvent received: \" + event.getMessage());\n    }\n}\n\n// Définition d'un événement personnalisé\npublic class MyCustomEvent extends ApplicationEvent {\n    private final String message;\n\n    public MyCustomEvent(Object source, String message) {\n        super(source);\n        this.message = message;\n    }\n\n    public String getMessage() {\n        return message;\n    }\n}\n\n//Publication de l'évènement :\n// ApplicationContext applicationContext;\n// applicationContext.publishEvent(new MyCustomEvent(this, \"Hello from event\"));\n```\n\nCet exemple montre comment créer un listener qui écoute un événement personnalisé (`MyCustomEvent`).  L'annotation `@EventListener` indique à Spring qu'il faut l'enregistrer comme listener pour ce type d'événement.\n\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Découplage:**  Permet de dé-coupler les différents composants de l'application.  Les émetteurs d'événements n'ont pas besoin de connaître les listeners.\n* **Flexibilité:**  Facile à étendre et à adapter à de nouveaux types d'événements.\n* **Simplicité:** L'utilisation de l'annotation `@EventListener` rend la déclaration des listeners très concise.\n* **Asynchrone (avec conditions):**  L'utilisation de `@Async` sur la méthode de l'écoute permet un traitement asynchrone.\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité potentielle:**  Pour des applications très complexes avec de nombreux événements et listeners, la gestion peut devenir difficile.\n* **Débogage:**  Le débogage d'événements peut être complexe si les listeners ne sont pas correctement configurés.\n* **Ordre de traitement non garanti:** Le traitement des événements par les listeners n'est pas garanti dans un ordre précis, sauf si une stratégie particulière est mise en place.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "40cef7bb-7d89-483d-91f3-6beec18bfd04",
        "title": "Streamlit",
        "shortDescription": "",
        "description": "---\nid: 43c514bb-6740-4553-bb6a-8a2186187deb\n---\n# Rapidement, c'est quoi ? ❓\n\nStreamlit est une librairie Python open-source qui permet de créer rapidement et facilement des applications web interactives pour visualiser et partager des données.  Elle simplifie le processus de développement en réduisant le besoin de connaissances approfondies en développement web frontal.\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nStreamlit fournit un framework permettant de construire des applications web à partir de code Python.  L'interface utilisateur est générée automatiquement à partir du code Python, qui est exécuté de manière incrémentale.  Chaque modification dans le script Python est instantanément reflétée dans l'application web, permettant un développement itératif rapide.\n\nStreamlit utilise des décorateurs pour définir les différents composants de l'application (ex: `@st.cache_data` pour le cache, `@st.cache_resource` pour les ressources, etc.).  Il offre une large gamme de widgets interactifs (boutons, curseurs, sélecteurs, etc.) pour interagir avec les données et des fonctions pour afficher des données sous différentes formes (graphiques, tableaux, cartes, etc.) via des librairies comme Matplotlib, Seaborn, Plotly, etc.\n\nVoici un exemple simple :\n\n```python\nimport streamlit as st\nimport numpy as np\nimport pandas as pd\n\nst.title(\"Mon Application Streamlit\")\n\n# Générer des données aléatoires\ndata = np.random.randn(20, 3)\ndf = pd.DataFrame(data, columns=['A', 'B', 'C'])\n\n# Afficher le dataframe\nst.dataframe(df)\n\n# Afficher un graphique\nst.line_chart(df)\n\n# Ajouter un curseur\nx = st.slider('Sélectionner une valeur', 0, 100, 50)\nst.write(f\"La valeur sélectionnée est : {x}\")\n```\n\nCe code crée une application Streamlit simple avec un titre, un tableau de données, un graphique linéaire et un curseur interactif.\n\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Rapidité de développement:** Streamlit permet de créer des applications web fonctionnelles très rapidement, même sans expérience en développement web.\n* **Facilité d'utilisation:** La syntaxe est intuitive et simple à apprendre pour les utilisateurs Python.\n* **Mise à jour en temps réel:** Les modifications de code sont instantanément reflétées dans l'application web.\n* **Intégration avec les librairies de visualisation de données:** Streamlit s'intègre facilement avec des librairies populaires comme Matplotlib, Seaborn, Plotly et Altair.\n* **Partage facile:**  Le déploiement et le partage d'applications sont simplifiés grâce à Streamlit Cloud.\n\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Moins flexible que les frameworks web complets:** Pour des applications web complexes et personnalisées, Streamlit peut avoir des limites par rapport à des frameworks comme React, Angular ou Vue.js.\n* **Performances potentielles:**  Pour les applications traitant des ensembles de données très volumineux, les performances peuvent être un problème. L'utilisation de `@st.cache_data` ou de techniques d'optimisation est alors nécessaire.\n* **Débogage:** Le débogage peut être plus difficile que dans des frameworks web traditionnels car le code est exécuté de manière incrémentale.\n* **Sécurité:** Comme pour toute application web, il faut prendre des précautions pour sécuriser l'application, surtout si elle est exposée publiquement.\n\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "9c6f2d70-5161-4aff-bcc4-a4e7ff073819",
        "title": "Tanstack",
        "shortDescription": "",
        "description": "---\nid: 721dcca9-837e-464d-be3d-d7676e23332b\n---\n# **Rapidement, c'est quoi ? ❓**\n\nTanstack est une collection de bibliothèques JavaScript open-source de haute qualité, principalement axées sur la création d'interfaces utilisateur performantes et robustes.  Elle est connue pour ses performances exceptionnelles, sa facilité d'utilisation et son approche axée sur les développeurs.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nTanstack n'est pas une seule bibliothèque, mais plutôt un écosystème de projets interconnectés, dont les plus connus sont :\n\n* **`@tanstack/react-query`:**  Une bibliothèque pour gérer facilement l'état de l'application, notamment la récupération et la mise à jour des données provenant d'API. Elle gère la mise en cache, la pagination, l'optimisation des requêtes, et la gestion des erreurs de manière transparente.  Elle permet de simplifier considérablement le développement d'applications qui interagissent avec des sources de données externes.\n\n* **`@tanstack/react-table`:** Une bibliothèque pour créer des tableaux de données interactifs et hautement personnalisables. Elle offre des fonctionnalités avancées de tri, de filtrage, de pagination et d'édition, tout en maintenant des performances élevées, même avec des ensembles de données volumineux.\n\n* **`@tanstack/virtual`:**  Une solution pour le rendu virtuel de listes et de tableaux, permettant de gérer efficacement de très grands ensembles de données sans compromettre les performances.  Elle est souvent utilisée en conjonction avec `react-table`.\n\n* **`@tanstack/router`:** Un routeur client pour React offrant des performances exceptionnelles et une grande flexibilité. Il se caractérise par son approche déclarative et sa capacité à gérer efficacement les transitions et la navigation dans une application complexe.\n\n\nCes bibliothèques partagent une philosophie commune de performance, de simplicité et d'extensibilité. Elles sont conçues pour être utilisées ensemble, mais peuvent également fonctionner indépendamment.  L'utilisation de TypeScript est omniprésente dans l'écosystème Tanstack, ce qui contribue à la robustesse et à la maintenabilité du code.\n\n\n**Exemple (react-query):**\n\n```javascript\nimport { useQuery } from '@tanstack/react-query';\n\nfunction MyComponent() {\n  const { data, isLoading, error } = useQuery(['todos'], () =>\n    fetch('/api/todos').then((res) => res.json())\n  );\n\n  if (isLoading) return 'Loading...';\n  if (error) return 'Error: ' + error.message;\n\n  return (\n    <ul>\n      {data.map((todo) => (\n        <li key={todo.id}>{todo.text}</li>\n      ))}\n    </ul>\n  );\n}\n```\n\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Performances exceptionnelles:** Tanstack est réputé pour sa vitesse et son efficacité, particulièrement pour les applications à grande échelle et celles qui manipulent de grands ensembles de données.\n* **Facilité d'utilisation:** Les API sont généralement intuitives et bien documentées, ce qui facilite l'apprentissage et l'intégration.\n* **Extensibilité:** Les bibliothèques sont conçues pour être facilement personnalisées et étendues pour répondre aux besoins spécifiques des applications.\n* **Bonne communauté et support:**  Une communauté active et un support efficace contribuent à la résolution rapide des problèmes et à l'amélioration continue des bibliothèques.\n* **TypeScript:** L'utilisation intensive de TypeScript améliore la qualité du code et réduit les erreurs.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage (légèrement plus raide pour certains):** Bien que généralement faciles à utiliser, certaines fonctionnalités plus avancées de `react-table` ou de `react-query` peuvent nécessiter un peu plus d'apprentissage.\n* **Écosystème spécifique à React (principalement):** Bien que certaines bibliothèques aient des adaptations pour d'autres frameworks, l'écosystème Tanstack est principalement centré sur React.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c8e1bc04-e275-4998-8f37-1250113c36a0",
        "title": "Terragrunt",
        "shortDescription": "",
        "description": "---\nid: 7d944ee8-6e62-4068-a425-0eae01d821c8\n---\n## Rapidement, c'est quoi ? ❓\n\nTerragrunt est un outil open-source qui étend Terraform pour gérer des infrastructures complexes et répétitives.  Il simplifie le déploiement et la gestion de plusieurs environnements Terraform en fournissant des fonctionnalités de modularité, de réutilisation de code et de gestion de configuration plus avancées que Terraform seul.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nTerragrunt n'est pas un remplacement de Terraform, mais un wrapper autour de lui. Il ajoute des fonctionnalités pour :\n\n* **Réutilisation de code:**  Permet de créer des modules réutilisables et de les appliquer à différents endroits, évitant la duplication de code.  Cela se fait par l'inclusion de modules dans un répertoire centralisé et leur inclusion dans plusieurs projets.\n* **Gestion de configurations multiples:** Facilite la gestion d'environnements distincts (développement, staging, production) en utilisant des configurations distinctes avec des variables appropriées pour chaque environnement.\n* **Gestion des dépendances:**  Permet de définir et de gérer les dépendances entre différents blocs Terraform, assurant que les ressources sont créées dans l'ordre correct.\n* **Inclusion de fichiers de configuration externes:**  Permet d'externaliser des parties de la configuration dans des fichiers séparés, améliorant la lisibilité et la maintenabilité.\n* **Gestion des secrets:**  Intègre plus facilement la gestion des secrets en permettant de les importer depuis des sources externes.\n\nTerragrunt utilise des fichiers `.hcl` (HashiCorp Configuration Language) pour définir ses configurations.  Un fichier `terragrunt.hcl` est généralement placé à la racine de chaque projet Terraform. Ce fichier spécifie les paramètres de configuration de Terragrunt, comme les variables, les modules à inclure et les options d'exécution.\n\n**Exemple de `terragrunt.hcl`:**\n\n```hcl\nterraform {\n  source = \"github.com/gruntwork-io/terragrunt-example-aws-ecs\"\n}\n\n# Cette ligne inclut une configuration externe\ninclude {\n  path = \"config.hcl\"\n}\n\nlocals {\n  environment = \"dev\"\n}\n```\n\nTerragrunt exécute ensuite Terraform en arrière-plan, utilisant les configurations définies dans le fichier `terragrunt.hcl` et les fichiers Terraform standard.\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Modularité et Réutilisation du Code:**  Améliore considérablement la maintenabilité et la cohérence des infrastructures Terraform.\n* **Gestion simplifiée des environnements multiples:**  Facilite le déploiement dans plusieurs environnements avec des configurations spécifiques à chaque environnement.\n* **Amélioration de la collaboration:**  Permet une meilleure organisation et collaboration pour les équipes travaillant sur de grands projets Terraform.\n* **Gestion des dépendances:**  Assure l'exécution des ressources dans l'ordre correct, ce qui est crucial pour éviter les erreurs.\n* **Intégration aisée avec les pipelines CI/CD:**  Peut être facilement intégré dans des pipelines CI/CD pour automatiser les déploiements.\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Courbe d'apprentissage:**  Nécessite d'apprendre une nouvelle couche d'abstraction au-dessus de Terraform.\n* **Complexité additionnelle:**  Pour les projets Terraform simples, l'ajout de Terragrunt peut ajouter une complexité inutile.\n* **Dépendance à un autre outil:**  Ajoute une dépendance à un autre outil, ce qui peut complexifier le processus de maintenance.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "75b5181a-1176-4e8a-b37e-8e2b57659aaa",
        "title": "TinyDb",
        "shortDescription": "",
        "description": "---\nid: b7cee06e-93fe-4f42-b117-225f172d8611\n---\n## **Rapidement, c'est quoi ? ❓**\n\nTinyDB est une petite base de données NoSQL orientée document pour Python.  Elle stocke les données dans un simple fichier JSON, ce qui la rend facile à utiliser et à intégrer dans des projets Python.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nTinyDB est une base de données embarquée, ce qui signifie qu'elle ne nécessite pas de serveur séparé. Elle utilise un fichier JSON pour stocker les données, ce qui facilite son utilisation et son déploiement.  Elle supporte les opérations CRUD (Créer, Lire, Mettre à jour, Supprimer) sur des documents JSON.  Contrairement aux bases de données relationnelles, TinyDB ne repose pas sur un schéma fixe ; vous pouvez stocker des documents JSON de structures différentes dans la même collection.\n\nTinyDB offre des fonctionnalités de requête puissantes via une API intuitive. Vous pouvez effectuer des recherches sur des champs spécifiques, utiliser des opérateurs de comparaison (>, <, >=, <=, ==, !=), et combiner plusieurs critères de recherche.\n\n**Exemple:**\n\n```python\nfrom tinydb import TinyDB, Query\n\n# Créer une instance de TinyDB (crée le fichier si inexistant)\ndb = TinyDB('mydb.json')\n\n# Créer une table (collection)\ntable = db.table('users')\n\n# Insérer des données\ntable.insert({'name': 'Alice', 'age': 30})\ntable.insert({'name': 'Bob', 'age': 25})\n\n# Requête: trouver un utilisateur avec l'age > 25\nUser = Query()\nresult = table.search(User.age > 25)\nprint(result)\n\n# Mettre à jour un document\ntable.update({'age': 31}, User.name == 'Alice')\n\n# Supprimer un document\ntable.remove(User.name == 'Bob')\n\n# Fermer la connection\ndb.close()\n```\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Simplicité:**  Extrêmement facile à utiliser et à apprendre, idéale pour les petits projets ou les prototypes.\n* **Lightweight:**  N'a pas besoin d'un serveur, ce qui la rend portable et facile à déployer.\n* **Intégration facile avec Python:** S'intègre parfaitement dans les applications Python.\n* **Stockage persistant:**  Les données sont persistées dans un fichier JSON, facile à sauvegarder et à restaurer.\n* **API intuitive:** Les requêtes sont faciles à écrire et à comprendre.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Performance:**  Peut devenir lente avec de très grandes quantités de données car elle est basée sur un fichier JSON.  Non adaptée aux applications haute performance ou à forte charge.\n* **Fonctionnalités limitées:**  Ne propose pas toutes les fonctionnalités d'une base de données NoSQL complète (par exemple, indexation complexe, transactions atomiques robustes).\n* **Scalabilité:**  Difficulté à gérer la croissance importante des données et des utilisateurs.  Non adaptée aux applications distribuées.\n* **Sécurité:**  La sécurité dépend de la sécurité du système de fichiers.  Pas de mécanismes de sécurité intégrés sophistiqués.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "448d0047-a90c-4db7-b45a-835e4bad9237",
        "title": "Uv",
        "shortDescription": "",
        "description": "---\nid: c1b3650e-bf9c-41f9-9ec6-bde23e8c5732\n---\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nUv est un outil en ligne de commande qui gère les dépendances des projets Python.  Contrairement à pip, qui est écrit en Python, Uv est implémenté en Rust, ce qui lui confère une vitesse d'exécution et une robustesse accrues. Il utilise un système de résolution de dépendances pour identifier et installer les packages nécessaires, en tenant compte des versions et des conflits possibles.  Il gère également la création d'environnements virtuels isolés pour chaque projet, permettant ainsi une meilleure gestion des dépendances spécifiques à chaque projet.  L'utilisation d'Uv se fait généralement via des fichiers de configuration (comme `pyproject.toml`), qui spécifient les dépendances du projet.  Uv lit ces fichiers, télécharge les paquets depuis des référentiels (comme PyPI), et les installe dans l'environnement virtuel approprié.\n\n\n**Exemple d'utilisation (hypothétique):**\n\nSupposons un `pyproject.toml` contenant :\n\n```toml\n[tool.uv.dependencies]\nrequests = \"2.28.2\"\nnumpy = \">=1.24.0\"\n```\n\nLa commande `uv install` analyserait ce fichier, téléchargerait `requests` version 2.28.2 et une version compatible de `numpy` (au moins 1.24.0), et les installerait dans l'environnement virtuel actif.\n\n\n---\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Rapidité:** Étant écrit en Rust, Uv est potentiellement beaucoup plus rapide que pip pour l'installation et la résolution de dépendances.\n* **Fiabilité:** Rust offre une meilleure gestion des erreurs et une sécurité mémoire accrue par rapport à Python, ce qui peut rendre Uv plus robuste et moins sujet aux plantages.\n* **Gestion des dépendances améliorée:**  Uv pourrait offrir des fonctionnalités de gestion des dépendances plus avancées (bien que cela dépende de son implémentation).\n* **Intégration avec `pyproject.toml`:** L'utilisation de `pyproject.toml` est une pratique courante et permet une meilleure gestion du projet.\n\n\n---\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Maturité:**  En tant que nouvel outil, Uv pourrait manquer de fonctionnalités ou de stabilité par rapport à un outil mature comme pip.\n* **Adoption:**  Le manque d'adoption pourrait limiter la communauté de soutien et la disponibilité des ressources.\n* **Compatibilité:** Il pourrait exister des incompatibilités avec certains packages ou outils existants.\n* **Dépendances:**  Uv lui-même a des dépendances, ce qui peut introduire une complexité supplémentaire.\n\n\n---\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "e8deee3f-007b-48f4-a9de-78ab0e076b6d",
        "title": "WCAG",
        "shortDescription": "",
        "description": "---\nid: f10ac51f-8930-4fe5-81f1-99355f3e8d4d\n---\n## **Rapidement, c'est quoi ? ❓**\n\nLes WCAG (Web Content Accessibility Guidelines) sont un ensemble de lignes directrices internationales pour rendre les sites web et le contenu web accessibles à tous, y compris les personnes handicapées.  Elles visent à assurer que le web soit utilisable par le plus grand nombre possible de personnes, indépendamment de leurs capacités.\n\n---\n\n# Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nLes WCAG définissent des critères de réussite pour l'accessibilité web, regroupés en quatre principes fondamentaux :\n\n* **Percevable (Perceivable):**  L'information et les composants de l'interface utilisateur doivent être présentés aux utilisateurs de manière qu'ils puissent les percevoir.  Cela inclut des critères sur le texte alternatif pour les images, les légendes pour les vidéos, le contraste des couleurs, etc.\n\n* **Opérable (Operable):** L'interface utilisateur doit être opérable.  Cela signifie que les utilisateurs doivent pouvoir utiliser l'interface utilisateur.  Des critères concernent la navigation au clavier, le temps de saisie, les saisies inappropriées, etc.\n\n* **Compréhensible (Understandable):** L'information et l'utilisation de l'interface utilisateur doivent être compréhensibles.  Cela implique des critères sur la lisibilité, la prévisibilité et la cohérence du site.\n\n* **Robuste (Robust):** Le contenu doit être robuste, c'est-à-dire compatible avec une large gamme de technologies d'assistance.\n\nChaque principe est décliné en plusieurs critères de réussite, classés par niveaux de sévérité (A, AA, AAA).  Le niveau AA est généralement considéré comme le minimum pour une bonne accessibilité.\n\n**Exemple concret :** Une image d'un chat sans texte alternatif (\"alt text\") viole le principe de perceptibilité. Un utilisateur utilisant un lecteur d'écran ne pourra pas comprendre ce que représente l'image.  L'ajout d'un texte alternatif (\"alt text\" = \"Un chat mignon\") rend l'image accessible.\n\n**Exemple de code (HTML) illustrant un bon contraste:**\n\n```html\n<p style=\"color: white; background-color: #000080;\">Ce texte a un bon contraste.</p>\n```\n\n```html\n<p style=\"color: black; background-color: #FFFFE0;\">Ce texte a un contraste insuffisant</p>\n```\n\nL'utilisation de vérificateurs d'accessibilité (outils automatisés) peut aider à identifier les problèmes d'accessibilité. Cependant, ils ne détectent pas tous les problèmes, une revue manuelle est essentielle.\n\n\n---\n\n# Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Standard internationalement reconnu:** Les WCAG sont largement acceptées comme la norme pour l'accessibilité web.\n* **Cadre complet:** Elles couvrent un large éventail de problèmes d'accessibilité.\n* **Niveaux de conformité:**  Permettent d'adapter le niveau d'accessibilité aux ressources disponibles.\n* **Améliore l'expérience utilisateur pour tous:**  Un site web accessible est généralement plus facile à utiliser pour tout le monde, même les utilisateurs sans handicap.\n\n\n---\n\n# Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité:** La compréhension et la mise en œuvre complète des WCAG peuvent être complexes, nécessitant des compétences spécifiques.\n* **Coût:** Rendre un site web pleinement accessible peut nécessiter des efforts importants et des coûts de développement supplémentaires.\n* **Tests manuels nécessaires:** Les outils automatisés ne suffisent pas à garantir une accessibilité complète. Des tests manuels approfondis sont indispensables.\n* **Evolution constante:** Les WCAG évoluent régulièrement, nécessitant une mise à jour continue des connaissances et des pratiques.\n\n\n---\n\n# À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "6a27445d-5e3c-4435-9e55-9dd9103a5d81",
        "title": "Watch Tower Docker",
        "shortDescription": "",
        "description": "---\nid: ba859634-f672-4bdf-92fa-d8a6e6ceec08\n---\n# Rapidement c'est quoi❓\n\nWatch Tower est un outil Docker qui automatise les mises à jour des conteneurs. Il surveille régulièrement les nouvelles versions d'images sur un registre (Docker Hub par défaut, ou un registre privé) et met à jour les conteneurs en cours d'exécution lorsqu'une nouvelle version est disponible.  Idéal pour les environnements de test et les homelabs.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nWatch Tower est un conteneur Docker léger qui fonctionne comme un agent de surveillance.  Il est configuré pour surveiller un ou plusieurs autres conteneurs.  Pour chaque conteneur surveillé, Watch Tower vérifie périodiquement la disponibilité de nouvelles images sur un registre Docker spécifié (Docker Hub par défaut, mais configurable pour des registres privés, nécessitant alors des identifiants).  Cette vérification se fait en comparant l'ID de l'image courante du conteneur avec la dernière version disponible sur le registre.\n\nSi une nouvelle version est détectée, Watch Tower télécharge automatiquement la nouvelle image.  Puis, il arrête proprement l'ancien conteneur, démarre un nouveau conteneur basé sur la nouvelle image, et conserve les données du conteneur précédent grâce à des volumes persistants s'ils sont définis.  Le processus est transparent pour l'utilisateur, qui ne devrait pas remarquer d'interruption de service (à condition d'avoir configuré correctement les volumes de données).  La configuration se fait principalement via des variables d'environnement, ce qui simplifie son déploiement et sa customisation.\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Automatisation des mises à jour:** Élimine le besoin de mises à jour manuelles des conteneurs, réduisant le risque d'erreur et le travail manuel.\n* **Facilité d'utilisation:**  Simple à configurer et à déployer grâce à son architecture en conteneur et à sa configuration par variables d'environnement.\n* **Support des registres privés:** Permet de gérer les mises à jour d'images hébergées sur des registres privés, crucial pour les environnements professionnels ou les configurations plus sécurisées.\n* **Mise à jour transparente (en théorie):**  Les mises à jour se font avec une interruption minimale, grâce à l'arrêt et le redémarrage automatisé du conteneur.\n* **Léger et peu gourmand en ressources:**  N'affecte pas significativement les performances du système hôte.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Dépendances:** Nécessite Docker et un accès à un registre Docker (public ou privé).\n* **Complexité potentielle pour des configurations avancées:** Bien que simple à utiliser de base, la gestion de scénarios complexes (dépendances entre conteneurs, configurations de volumes complexes) peut demander plus d'attention.\n* **Potentiel de problèmes en cas de mauvaise configuration des volumes:**  Une mauvaise configuration des volumes de données peut entraîner la perte de données lors d'une mise à jour.  Il est crucial de bien définir et de tester la persistance des données.\n* **Pas de gestion des configurations internes du conteneur:**  Watchtower met à jour uniquement l'image du conteneur.  Les configurations internes au conteneur doivent être gérées séparément (par exemple, via des fichiers de configuration persistants).\n\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "5ce536ee-9346-4042-888f-3641480236b6",
        "title": "Wiremock",
        "shortDescription": "",
        "description": "---\nid: 31caea1a-0cb7-434b-89d8-ba31405f704b\n---\n# Rapidement, c'est quoi ? ❓\n\nWireMock est un outil open-source permettant de créer facilement des mocks d'API.  Il simule des services web pour les tests, renvoyant des réponses pré-définies à des requêtes spécifiques.  Cela permet de déboucler les tests des applications qui dépendent d'autres services sans avoir à les démarrer ou à les utiliser en production.\n\n## Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nWireMock est un serveur indépendant qui écoute sur un port donné.  On le configure pour répondre à des requêtes HTTP (GET, POST, PUT, DELETE, etc.) avec des réponses spécifiées.  Ces réponses peuvent être statiques (un fichier JSON, XML, etc.) ou dynamiques (générées à la volée en fonction de la requête).  La configuration se fait généralement via des fichiers JSON ou YAML, définissant des mappings entre des requêtes et des réponses.\n\nVoici un exemple de configuration YAML simple :\n\n```yaml\n---\nrequest:\n  method: GET\n  url: /users\nresponse:\n  status: 200\n  body:\n    - id: 1\n      name: John Doe\n    - id: 2\n      name: Jane Doe\n```\n\nCe mapping indique à WireMock de répondre à une requête GET sur `/users` avec un code de statut 200 et un corps JSON contenant une liste de deux utilisateurs.\n\nWireMock offre des fonctionnalités avancées telles que :\n\n* **Gestion des retards:** Simuler des temps de réponse lents.\n* **Validation des requêtes:** Vérifier que les requêtes envoyées par l'application sont conformes aux attentes.\n* **Stubbing:** Fournir des réponses prédéfinies pour des requêtes spécifiques.\n* **Mocking:** Simuler le comportement d'un service distant.\n* **Intégration avec des frameworks de test:**  WireMock s'intègre facilement avec de nombreux frameworks de test (JUnit, pytest, etc.).\n\n## Qu'est-ce qui est top ? \uD83D\uDC4D\n\n* **Facile à utiliser:** La configuration est simple et intuitive, même pour des cas d'utilisation complexes.\n* **Flexible:**  Permet de simuler un large éventail de scénarios de tests.\n* **Open-source:**  Gratuit et la communauté contribue à son amélioration constante.\n* **Large choix de langages et d'intégrations:**  Disponible pour différents langages et frameworks.\n* **Gestion des dépendances:** Découple les tests de l'infrastructure et des services externes.\n\n## Qu'est-ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Complexité pour les cas très complexes:**  Pour des simulations extrêmement sophistiquées, la configuration peut devenir complexe.\n* **Courbe d'apprentissage légère:** Bien que simple à utiliser de base, la maîtrise de toutes ses fonctionnalités peut demander un certain temps.\n* **Maintenance des mocks:**  Le maintien des mocks à jour avec l'évolution de l'API peut demander de l'effort.\n\n\n## À quoi c'est lié ? \uD83E\uDEA2\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "27e9c2f4-bd91-4a4d-be4e-f01ce1f058f8",
        "title": "io_uring",
        "shortDescription": "",
        "description": "---\nid: 68a5471b-4061-46f5-b990-d0851a73aaf7\n---\n# **Rapidement, c'est quoi ? ❓**\n\nio_uring est une interface système Linux permettant d'effectuer des opérations d'E/S (entrée/sortie) de manière asynchrone et très performante.  Elle améliore considérablement l'efficacité du traitement des requêtes d'E/S par rapport aux méthodes traditionnelles comme les appels système `read()` et `write()`.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nio_uring est une interface basée sur des anneaux (rings) pour la communication entre l'espace utilisateur et le noyau.  Au lieu d'effectuer des appels système individuels pour chaque opération d'E/S,  l'application soumet un ensemble de requêtes en bloc à un anneau de soumission (submission queue). Le noyau traite ces requêtes et renvoie les résultats dans un anneau de complétion (completion queue). Cette approche réduit considérablement le contexte switching et la surcharge liée aux appels système.\n\nio_uring supporte un large éventail d'opérations, notamment :\n\n* **Opérations de fichiers:** `read`, `write`, `open`, `close`, `fsync`, `fdatasync`, etc.\n* **Opérations de sockets:** `accept`, `connect`, `recv`, `send`, etc.\n* **Opérations de gestion de fichiers:** `stat`, `ftruncate`, `rename`, etc.\n* **Opérations de timers:**  Permet de gérer des timers de manière asynchrone.\n* **Opérations de signalisation:**  Permet de gérer les signaux de manière asynchrone.\n\n\n**Fonctionnement interne (simplifié):**\n\n1. **Soumission des requêtes:** L'application remplit une structure de données représentant les requêtes d'E/S et les place dans l'anneau de soumission.\n2. **Traitement par le noyau:** Le noyau récupère les requêtes de l'anneau de soumission et les traite concurremment.\n3. **Complétion des requêtes:**  Une fois les requêtes traitées, le noyau place les résultats (codes de retour, données, etc.) dans l'anneau de complétion.\n4. **Récupération des résultats:** L'application lit l'anneau de complétion pour récupérer les résultats des opérations d'E/S.\n\n**Exemple (concept simplifié en C):**\n\n```c\n// ... (Initialisation io_uring) ...\n\nstruct io_uring_sqe *sqe = io_uring_get_sqe(&ring);\nio_uring_prep_read(sqe, fd, buffer, size, offset);\nio_uring_submit(&ring); // Envoie les requêtes au noyau\n\n// ... (Attente de la complétion des requêtes via io_uring_wait_cqe) ...\n\n// ... (Récupération des résultats depuis l'anneau de complétion) ...\n```\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Performances exceptionnelles:** io_uring offre des performances bien supérieures à celles des appels systèmes traditionnels, notamment pour les applications à forte intensité d'E/S.\n* **Faible latence:** La réduction du contexte switching et la gestion asynchrone permettent de réduire la latence des opérations d'E/S.\n* **Scalabilité:** io_uring est conçu pour être scalable et capable de gérer un grand nombre de requêtes simultanées.\n* **Flexibilité:**  Supporte une grande variété d'opérations d'E/S.\n* **Efficacité énergétique:** La réduction des appels système diminue la consommation d'énergie.\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Complexité:**  L'implémentation d'applications utilisant io_uring est plus complexe que l'utilisation d'appels système classiques.  Nécessite une bonne compréhension de la programmation asynchrone.\n* **Spécifique à Linux:** io_uring est une fonctionnalité spécifique au noyau Linux, et n'est donc pas portable vers d'autres systèmes d'exploitation.\n* **Débogage:** Le débogage des applications utilisant io_uring peut être plus difficile que celui des applications utilisant des appels système synchrones.\n* **Support limité dans certaines bibliothèques:**  Certaines bibliothèques ne supportent pas encore nativement io_uring, nécessitant une implémentation manuelle.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "7c30816c-6780-447e-972e-751ecdd9187d",
        "title": "n8n",
        "shortDescription": "",
        "description": "---\nid: 97286cb2-9836-4dd2-b5f6-0885a22ca5c7\n---\n# **Rapidement, c'est quoi ? ❓**\n\nn8n est une plateforme d'automatisation open-source, basée sur le workflow, permettant de connecter différents services et applications entre eux sans écrire de code.  Elle fonctionne via une interface visuelle intuitive où l'on peut créer des flux de travail (workflows) pour automatiser des tâches répétitives.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nn8n est un outil de \"low-code/no-code\" qui permet de construire des workflows complexes en connectant divers services web grâce à des \"nodes\".  Chaque node représente une action spécifique, comme envoyer un email, télécharger un fichier, ou interagir avec une base de données.  Ces nodes sont connectées entre elles pour former un flux de travail.  n8n prend en charge un large éventail de protocoles et de services via des intégrations (connecteurs) prédéfinies, et il est extensible grâce à la création de nodes personnalisées.\n\nLe fonctionnement se base sur un système d'exécution asynchrone.  Les workflows ne sont pas exécutés de manière linéaire, mais plutôt de manière parallèle et asynchrone.  Chaque node s'exécute de manière indépendante, ce qui permet une grande flexibilité et une meilleure gestion des erreurs.\n\n**Exemple concret : Automatisation de la gestion des leads**\n\nImaginez un workflow n8n qui collecte des leads depuis un formulaire sur un site web (node \"HTTP Request\").  Ces données sont ensuite envoyées à une base de données (node \"Database\").  Si le lead correspond à certains critères, un email est envoyé à l'équipe de vente (node \"Email\").  En cas d'échec, une notification est envoyée via Slack (node \"Slack\").  Tout cela sans écrire une seule ligne de code, en reliant simplement des nodes préexistantes.\n\n\n**Fonctionnement interne (simplifié):**\n\nn8n est une application Node.js qui utilise une base de données pour stocker les workflows et leurs exécutions.  L'interface utilisateur est une application web qui permet de créer, éditer et exécuter les workflows.  L'exécution des nodes est gérée par un moteur d'exécution interne qui utilise des workers pour traiter les tâches en parallèle.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Open-source et gratuit:**  n8n est open-source, ce qui permet une grande transparence et une communauté active pour le support et le développement.  Il est gratuit à utiliser, même pour les déploiements en production.\n* **Flexibilité et extensibilité:**  Le large choix de nodes et la possibilité de créer des nodes personnalisées offrent une grande flexibilité pour automatiser presque toutes les tâches.\n* **Interface utilisateur intuitive:** L'interface visuelle facilite la création et la gestion des workflows, même pour les utilisateurs sans expérience en programmation.\n* **Scalabilité:** n8n peut être déployé sur différentes infrastructures, des machines locales aux solutions cloud, pour gérer des workflows de toutes tailles.\n* **Grande variété d'intégrations:**  Une vaste bibliothèque de nodes permet de se connecter à de nombreux services populaires.\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage initiale (légère):**  Bien que l'interface soit intuitive, la compréhension du fonctionnement des workflows et des nodes peut prendre un peu de temps au début.\n* **Débogage complexe (pour workflows avancés):** Le débogage des workflows complexes peut être difficile, surtout pour les utilisateurs non-familiers avec le concept de workflow asynchrone.\n* **Gestion de la sécurité:**  La sécurité dépend de la configuration du serveur et des intégrations utilisées. Une mauvaise configuration peut exposer des données sensibles.\n* **Dépendance à la disponibilité d'internet:** n8n nécessite une connexion internet pour fonctionner correctement, car la plupart des nodes interagissent avec des services externes.\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "c1ff4ce7-6316-4843-bcbe-8ebfc06c2c34",
        "title": "protobuf",
        "shortDescription": "",
        "description": "---\nid: 8ef8f16f-6955-49c9-858e-e5c803104b27\n---\n# **Rapidement, c'est quoi ? ❓**\n\nProtocol Buffers (protobuf) est un système de sérialisation de données open source développé par Google.  Il permet de définir des structures de données (messages) dans un langage descriptif simple (`.proto`), puis de générer automatiquement du code dans différents langages (Java, C++, Python, Go, etc.) pour encoder et décoder ces structures.  Cela permet une communication efficace et interopérable entre différents systèmes.\n\n---\n\n# **Plus précisément, c'est quoi/ça fait quoi ? \uD83D\uDD0D**\n\nProtobuf définit un langage de description d'interface (IDL) pour spécifier les structures de données.  Un fichier `.proto` décrit les messages, contenant des champs de différents types (entier, chaîne de caractères, booléen, nombres à virgule flottante, tableaux, structures imbriquées, etc.).  Le compilateur Protobuf (`protoc`) lit ce fichier et génère du code source pour le langage cible. Ce code fournit des fonctions pour:\n\n* **Sérialiser (encoder):** Convertir une structure de données en un flux d'octets.  Ce flux est compact et efficace en termes d'espace mémoire.\n* **Désérialiser (décoder):** Convertir un flux d'octets en une structure de données.\n\n**Exemple de fichier `.proto`:**\n\n```protobuf\nsyntax = \"proto3\";\n\nmessage Person {\n  string name = 1;\n  int32 id = 2;\n  string email = 3;\n}\n```\n\nCe fichier définit un message `Person` avec trois champs : `name`, `id`, et `email`.  Après compilation, le code généré fournira des classes ou des structures pour manipuler des objets `Person` et les encoder/décoder en octets.\n\n**Avantages de la sérialisation:**\n\n* **Efficacité:** Protobuf génère des formats binaires compacts, plus petits et plus rapides à traiter que les formats textuels comme le JSON ou le XML.\n* **Interopérabilité:** Le même fichier `.proto` peut être utilisé pour générer du code dans différents langages, facilitant la communication entre des systèmes hétérogènes.\n* **Évolutivité:**  Il est possible d'ajouter de nouveaux champs à un message sans casser la compatibilité avec les anciens clients.  Le système gère les champs inconnus.\n* **Performances:** La sérialisation et la désérialisation sont rapides et optimisées.\n\n---\n\n# **Qu'est-ce qui est top ? \uD83D\uDC4D**\n\n* **Efficacité et performance:**  Format compact et rapidité de sérialisation/désérialisation.\n* **Interopérabilité multi-langage:**  Support d'un large éventail de langages de programmation.\n* **Évolutivité et compatibilité ascendante:**  Ajout facile de nouveaux champs sans rupture de compatibilité.\n* **Bonne documentation et communauté active:**  Ressources et support disponibles.\n\n\n---\n\n# **Qu'est-ce qui est pas ouf ? \uD83D\uDC4E**\n\n* **Courbe d'apprentissage:** Nécessite de comprendre le système de définition de messages et l'utilisation du compilateur `protoc`.\n* **Format binaire non humainement lisible:**  Le format sérialisé est binaire, rendant le débogage plus difficile que pour les formats textuels.\n* **Dépendance au compilateur:**  Nécessite l'utilisation du compilateur `protoc` pour générer le code.\n\n\n---\n\n# **À quoi c'est lié ? \uD83E\uDEA2**\n\n(Laisser vide)\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    },
    {
        "id": "86ee259a-4013-4a03-b42b-95410d80f8fe",
        "title": "Fuzzing",
        "shortDescription": "",
        "description": "# Fuzzing\n\nLe fuzzing est une technique de test logiciel qui consiste à fournir en entrée d'un programme des données aléatoires ou malformées afin de détecter des vulnérabilités ou des comportements inattendus.  On peut l'imaginer comme un \"test de résistance\" poussé à l'extrême, visant à casser le logiciel.  L'objectif n'est pas de trouver une utilisation \"normale\" du logiciel, mais plutôt d'explorer ses limites et de révéler des failles de sécurité ou des bugs.\n\n## Exemples de Fuzzing\n\nVoici des exemples de fuzzing en Go et en Java illustrant des approches différentes:\n\n### Fuzzing en Go avec la librairie standard\n\nGo propose des outils facilitant le fuzzing via son package `testing`.  Voici un exemple simple:\n\n```go\npackage mypackage\n\nimport (\n\t\"testing\"\n)\n\nfunc MyFunction(input string) int {\n\t// Fonction à tester\n\tif len(input) > 10 {\n\t\treturn -1 // Erreur potentielle si la longueur dépasse 10\n\t}\n\treturn len(input)\n}\n\nfunc FuzzMyFunction(f *testing.F) {\n\tf.Add(\"abc\")\n\tf.Add(\"abcdefghijklmnopqrstuvwxyz\")\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tresult := MyFunction(input)\n\t\tif len(input) > 10 && result != -1 {\n\t\t\tt.Errorf(\"Erreur : input trop long, attendu -1, obtenu %d\", result)\n\t\t}\n\n\t})\n}\n```\n\nCet exemple définit une fonction `MyFunction` simple, puis utilise `FuzzMyFunction` pour tester cette fonction avec des données aléatoires générées par `f.Fuzz`.  `f.Add` permet d'ajouter des cas de test initiaux, garantissant une certaine couverture.\n\n\nPour exécuter ce test de fuzzing : `go test -fuzz=FuzzMyFunction`\n\nIl est crucial de comprendre que ce n'est qu'un exemple très simplifié.  Dans un scénario réel, le fuzzing nécessite une analyse approfondie des entrées possibles et une stratégie pour générer des données pertinentes et diversifiées.  Des outils plus avancés comme `go-fuzz` peuvent être nécessaires pour un fuzzing efficace.\n\n\n### Fuzzing en Java\n\nEn Java, il n'existe pas de fonctionnalité intégrée aussi directe que celle de Go.  Néanmoins, des librairies telles que JQF (Java Quickfuzz) permettent de réaliser du fuzzing. JQF génère des cas de test aléatoires et les exécute en surveillant les exceptions et les comportements anormaux.  Son utilisation requiert une configuration plus complexe qu'en Go, impliquant une instrumentation du code à tester.  \n\n\nPour comprendre l'utilisation de JQF, il est conseillé de se référer à sa documentation officielle.  [Certification Java 17 - Programmation Orientée Objet (OOP)] et [Certification Java 17 - Gestion des Exceptions] peuvent aider à comprendre les bases nécessaires à l'implémentation d'un fuzzer avec JQF.\n\n\n## Limitations et Considérations\n\nLe fuzzing n'est pas une solution miracle. Il ne peut pas détecter toutes les vulnérabilités, notamment celles liées à la logique métier complexe ou à des conditions de course. De plus, il peut générer un grand nombre de faux positifs.  Une analyse manuelle des résultats est donc indispensable.\n\n\n## Conclusion\n\nLe fuzzing est une technique puissante pour améliorer la robustesse et la sécurité des logiciels. Cependant, il doit être utilisé avec discernement et en complément d'autres techniques de test ([Test Driven Developpement (TDD)], [Test de mutation]).  Le choix de l'outil et la stratégie de fuzzing doivent être adaptés au contexte et à la complexité du logiciel.\n",
        "linkedConcepts": [
            {
                "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                "title": "Racine",
                "shortDescription": "Racine de l'abre des connaissances",
                "description": "",
                "linkedConcepts": [],
                "flashcards": [],
                "base": true,
                "atomic": false
            }
        ],
        "flashcards": [
            {
                "id": "260d377b-2940-4f2b-be62-7cebac503b05",
                "front": "Quel est le but principal du fuzzing dans le développement logiciel ?",
                "back": "Détecter les vulnérabilités et les comportements inattendus d'un programme en lui fournissant des données aléatoires ou malformées.",
                "easeFactor": 2.5,
                "interval": 10,
                "repetitions": 1,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-03T19:58:50.387",
                "nextReviewDate": "2025-04-03T20:11:47.736",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            },
            {
                "id": "ea1393b7-1ba8-4898-895d-6e4859be268b",
                "front": "Expliquez la différence entre l'approche du fuzzing en Go et en Java, en mentionnant les outils ou librairies utilisés dans chaque langage.",
                "back": "Go propose des outils intégrés dans son package `testing`, simplifiant le fuzzing.  Java nécessite l'utilisation de librairies tierces comme JQF (Java Quickfuzz) car il n'y a pas de fonctionnalité intégrée équivalente.",
                "easeFactor": 2.65,
                "interval": 1,
                "repetitions": 0,
                "lapses": 0,
                "state": "GRADUATED",
                "createdDate": "2025-04-03T19:58:50.387",
                "nextReviewDate": "2025-04-04T20:01:57.252",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            },
            {
                "id": "04a9a995-ea22-4510-b0a7-00f41a6b17a7",
                "front": "Donnez un exemple de code Go illustrant un test de fuzzing simple utilisant la librairie standard, incluant la méthode pour exécuter ce test.",
                "back": "```go\npackage mypackage\n\nimport (\n\t\"testing\"\n)\n\nfunc MyFunction(input string) int {\n\t// Fonction à tester\n\tif len(input) > 10 {\n\t\treturn -1 // Erreur potentielle si la longueur dépasse 10\n\t}\n\treturn len(input)\n}\n\nfunc FuzzMyFunction(f *testing.F) {\n\tf.Add(\"abc\")\n\tf.Add(\"abcdefghijklmnopqrstuvwxyz\")\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tresult := MyFunction(input)\n\t\tif len(input) > 10 && result != -1 {\n\t\t\tt.Errorf(\"Erreur : input trop long, attendu -1, obtenu %d\", result)\n\t\t}\n\n\t})\n}\n```\nPour exécuter : `go test -fuzz=FuzzMyFunction`",
                "easeFactor": 2.5,
                "interval": 1,
                "repetitions": 0,
                "lapses": 0,
                "state": "NEW",
                "createdDate": "2025-04-03T19:58:50.387",
                "nextReviewDate": "2025-04-03T20:03:57.047",
                "graduationInterval": 1,
                "learningSteps": [
                    1,
                    10
                ],
                "readyForReview": true,
                "timeUntilReview": "PT0S"
            }
        ],
        "base": false,
        "atomic": false
    },
    {
        "id": "853f7ea2-d6b9-476c-8e65-33d2ca2fdc8a",
        "title": "Langchain4j",
        "shortDescription": "",
        "description": "# Langchain4j : Une Introduction à la Librairie Java\n\nCette note fournit une introduction à Langchain4j, une librairie Java facilitant le développement d'applications basées sur les grands modèles de langage (LLM).  Elle se concentre sur les aspects fondamentaux et fournit des exemples de code pour illustrer son utilisation.  Pour une compréhension plus approfondie des concepts liés aux LLM, veuillez consulter la note sur les [vLLM].\n\n## Qu'est-ce que Langchain4j ?\n\nLangchain4j est une librairie Java qui simplifie l'interaction avec les LLM.  Elle fournit des outils pour :\n\n* **Chaîner plusieurs appels à un LLM:**  Permet de créer des applications plus complexes en combinant plusieurs appels à un modèle, par exemple pour la génération de texte à partir de plusieurs sources d'information.\n* **Gérer les prompts (instructions) efficacement:**  Fournit des mécanismes pour la création, la gestion et l'optimisation des prompts.\n* **Intégrer des LLM à des applications existantes:**  Facilite l'intégration des LLM dans des projets Java existants.\n* **Utiliser différents modèles de LLM:**  Langchain4j est conçu pour être compatible avec une variété de fournisseurs de LLM.\n\n\n## Installation\n\nPour utiliser Langchain4j dans votre projet Java, vous devez ajouter la dépendance Maven suivante à votre fichier `pom.xml` :\n\n```xml\n<dependency>\n  <groupId>com.github.langchain4j</groupId>\n  <artifactId>langchain4j</artifactId>\n  <version>...</version> <!-- Remplacer par la dernière version -->\n</dependency>\n```\n\nRemplacez `...` par la dernière version disponible. Vous pouvez trouver la dernière version sur le dépôt Maven central.\n\n## Exemple Simple : Génération de Texte\n\nVoici un exemple simple illustrant la génération de texte à l'aide de Langchain4j.  Cet exemple suppose que vous avez configuré un client pour un fournisseur de LLM (par exemple, OpenAI) et que vous avez les clés d'API nécessaires.  [Certification Java 17 - Concepts de Base en Java] sera utile pour comprendre la syntaxe Java.\n\n```java\nimport com.github.langchain4j.model.llm.openai.OpenAI;\nimport com.github.langchain4j.model.llm.openai.OpenAIConfig;\nimport com.github.langchain4j.prompt.Prompt;\n\npublic class Langchain4jExample {\n\n    public static void main(String[] args) throws Exception {\n        // Configuration OpenAI (remplacez par vos clés API)\n        OpenAIConfig openAIConfig = OpenAIConfig.builder()\n                .apiKey(\"YOUR_OPENAI_API_KEY\")\n                .build();\n\n        // Création d'une instance de OpenAI\n        OpenAI openAI = new OpenAI(openAIConfig);\n\n        // Prompt\n        Prompt prompt = Prompt.builder()\n                .text(\"Écrire un court poème sur un chat.\")\n                .build();\n\n        // Génération de texte\n        String generatedText = openAI.generateText(prompt);\n\n        System.out.println(generatedText);\n    }\n}\n```\n\n**Points importants:**  Cet exemple est très simplifié.  En pratique, la gestion des erreurs et la configuration plus avancée sont essentielles.  De plus, il est important de choisir le bon modèle LLM en fonction de vos besoins.\n\n\n## Conclusion\n\nLangchain4j simplifie considérablement le développement d'applications basées sur les LLM en Java.  Cette note a fourni une introduction de base.  Une exploration plus approfondie de la documentation officielle de Langchain4j est recommandée pour maîtriser pleinement ses fonctionnalités avancées. Pour une gestion avancée des exceptions, référez-vous à la note [Certification Java 17 - Gestion des Exceptions].\n",
        "linkedConcepts": [
            {
                "id": "a1786998-f5b9-49ba-95c3-fa9c14e40413",
                "title": "AWS Lambda",
                "shortDescription": "",
                "description": "---\nid: 574373b1-97bf-4179-87b9-88dc8fc613cf\n---\n# Rapidement c'est quoi❓\n\nAWS Lambda est un service [[Function as a Service (FaaS)]] d'[[AWS]].  Il permet d'exécuter du code sans gérer d'infrastructure serveur.  Vous fournissez le code, et [[AWS]] s'occupe du reste.\n\n---\n# Plus précisément c'est quoi/ça fait quoi ? \uD83D\uDD0D\n\nAWS Lambda est un service de calcul sans serveur qui permet aux développeurs d'exécuter du code en réponse à des événements sans provisionner ou gérer des serveurs.  Vous écrivez votre code (fonctions) dans plusieurs langages supportés ([[Node.js]], [[Python]], [[Java]], [[C#]], [[Go]], [[Ruby]], etc.), le déployez sur [[AWS]], et Lambda s'occupe de l'exécution, du scaling automatique et de la facturation uniquement en fonction de l'utilisation effective.  Chaque fonction est déclenchée par un événement, tel qu'une modification dans un [[Bucket S3]] , une requête [[API Gateway]], une entrée dans une file [[SQS]], ou un évènement planifié avec [[CloudWatch Events]].\n\nLambda gère automatiquement le scaling : si plusieurs événements se produisent simultanément, Lambda lance plusieurs instances de votre fonction pour gérer la charge.  L'inverse est également vrai : si aucune requête n'est effectuée, aucune ressource n'est consommée et vous ne payez rien.  La gestion des ressources (mémoire, temps d'exécution, etc.) est définie lors de la configuration de la fonction.  Lambda propose également des fonctionnalités avancées comme les versions, les alias, les couches (pour partager du code commun entre plusieurs fonctions) et l'intégration avec d'autres services [[AWS]].  Le monitoring et le logging sont intégrés via [[CloudWatch]].\n\n---\n# Qu'est ce qui est top ? \uD83D\uDC4D\n\n* **Sans serveur (Serverless):** Pas besoin de gérer d'infrastructure, ce qui réduit considérablement le coût et la complexité.\n* **Scaling automatique:** Lambda s'adapte automatiquement à la demande, garantissant la disponibilité et la performance.\n* **Facturation à l'utilisation:** Vous ne payez que pour le temps d'exécution effectif de votre code.\n* **Intégration avec l'écosystème [[AWS]]:**  S'intègre facilement avec de nombreux autres services [[AWS]], permettant de créer des applications complexes et robustes.\n* **Langages multiples supportés:** Large choix de langages de programmation pour développer vos fonctions.\n\n---\n# Qu'est ce qui est pas ouf ? \uD83D\uDC4E\n\n* **Durée d'exécution limitée:**  Les fonctions Lambda ont une durée d'exécution maximale (variable selon la configuration).  Les tâches longues doivent être traitées différemment (par exemple, en utilisant des files d'attente et des fonctions plus courtes).\n* **Débogage plus complexe:** Le débogage peut être plus difficile que dans une application traditionnelle, nécessitant des outils et des techniques spécifiques.\n* **Cold starts:** La première exécution d'une fonction peut prendre un peu plus de temps (cold start), ce qui peut affecter les performances pour les requêtes occasionnelles.\n* **Verrouillage fournisseur:**  Le code est exécuté sur l'infrastructure AWS, ce qui crée une dépendance envers ce fournisseur.\n* **Gestion des états:** La persistance des données entre les exécutions de fonctions nécessite l'utilisation de services externes comme [[DynamoDB]].\n\n---\n# A quoi c'est lié ? \uD83E\uDEA2\n\n[[MOC_Dev]] [[MOC_DevSecOps]]",
                "linkedConcepts": [
                    {
                        "id": "3cba1234-4473-42ca-81cb-131e4e4bca73",
                        "title": "Racine",
                        "shortDescription": "Racine de l'abre des connaissances",
                        "description": "",
                        "linkedConcepts": [],
                        "flashcards": [],
                        "base": true,
                        "atomic": false
                    }
                ],
                "flashcards": [],
                "base": false,
                "atomic": false
            }
        ],
        "flashcards": [],
        "base": false,
        "atomic": false
    }
]